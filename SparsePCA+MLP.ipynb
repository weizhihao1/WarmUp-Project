{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "class MoannaDataset(Dataset):\n",
    "    def __init__(self, data_file, label_file, n_components=500):\n",
    "        self.data = pd.read_csv(data_file, sep=',', header=0, index_col=0).values\n",
    "        self.label = pd.read_csv(label_file, header=0, index_col=0).values[:,1]\n",
    "        \n",
    "        # Use variance threshold to select features\n",
    "        # selector = VarianceThreshold(threshold=var_threshold)\n",
    "        # self.data = selector.fit_transform(self.data)\n",
    "        \n",
    "        # Use PCA to reduce the number of features\n",
    "        # pca = PCA(n_components=n_components)\n",
    "        # self.data = pca.fit_transform(self.data)\n",
    "        \n",
    "        # Use Sparse PCA to reduce the number of features\n",
    "        spca = SparsePCA(n_components=n_components)\n",
    "        self.data = spca.fit_transform(self.data)\n",
    "        \n",
    "        self.data = torch.from_numpy(self.data).float().to(device)\n",
    "        self.label = self.label.astype(int)\n",
    "        self.label = torch.from_numpy(self.label).long().to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_568011/2035665090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/intern/WarmUpProject/pp-TCGA-clinical.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoannaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_568011/4174767474.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_file, label_file, n_components)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Use Sparse PCA to reduce the number of features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mspca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparsePCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_sparse_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcode_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mdict_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         Vt, _, E, self.n_iter_ = dict_learning(X.T, n_components,\n\u001b[0m\u001b[1;32m    159\u001b[0m                                                \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                                                \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    606\u001b[0m                              max_iter=method_max_iter, verbose=verbose)\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m# Update dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,\n\u001b[0m\u001b[1;32m    609\u001b[0m                                              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_r2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                                              \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36m_update_dict\u001b[0;34m(dictionary, Y, code, verbose, return_r2, random_state, positive)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;31m# R <- 1.0 * U_k * V_k^T + R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data_file = '/home/intern/WarmUpProject/p-tcga_binary_mutation.csv'\n",
    "label_file = '/home/intern/WarmUpProject/pp-TCGA-clinical.csv'\n",
    "\n",
    "dataset = MoannaDataset(data_file, label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randperm(len(dataset))\n",
    "\n",
    "split_point = int(0.7 * len(idx))\n",
    "\n",
    "train_idx = list(idx[:split_point])\n",
    "test_idx = list(idx[split_point:])\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7028"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5774, -1.5362, -0.8292, -0.1962, -0.0307, -0.0799,  1.0026,  0.3972,\n",
       "         0.0265, -0.1900, -0.2261,  0.0070, -0.1681, -0.2100,  0.1456, -0.2873,\n",
       "        -0.0631, -0.2383, -0.0434,  0.1374, -0.0667, -0.0924,  0.0576,  0.2267,\n",
       "        -0.0817, -0.0371, -0.1763, -0.1175, -0.0472,  0.2944,  0.1797,  0.0432,\n",
       "         0.0557,  0.1162, -0.0256, -0.1339, -0.0628, -0.0957, -0.2400, -0.0206,\n",
       "         0.0953,  0.0955, -0.1862, -0.1780, -0.1120,  0.0264, -0.2347,  0.0746,\n",
       "        -0.1843, -0.1724, -0.1823,  0.0714, -0.2220,  0.3265, -0.2704, -0.2280,\n",
       "        -0.0609, -0.1205, -0.4110,  0.3222, -0.2742, -0.0537,  0.1143,  0.1610,\n",
       "        -0.1083, -0.0176, -0.0041,  0.0060, -0.4773, -0.3896, -0.3012,  0.0259,\n",
       "        -0.0283, -0.1396, -0.1469, -0.2429, -0.2982, -0.3624, -0.6604,  0.1643,\n",
       "        -0.0290, -0.2780,  0.2889, -0.0856, -0.0991, -0.0242, -0.5785, -0.0028,\n",
       "        -0.0752, -0.0445, -0.1680,  0.0064,  0.0195, -0.5078, -0.2763,  0.1050,\n",
       "         0.2114,  0.2529,  0.1286, -0.0272,  0.1415, -0.2304, -0.2951,  0.0648,\n",
       "        -0.2706,  0.0554,  0.0988,  0.1734, -0.2310,  0.1644, -0.2542,  0.0459,\n",
       "         0.2103, -0.1549, -0.0866,  0.1057, -0.2210,  0.0537,  0.1991, -0.1459,\n",
       "         0.6413, -0.4040,  0.5074, -0.0583, -0.0769,  0.2391,  0.0849,  0.1744,\n",
       "        -0.1876, -0.2592,  0.3030, -0.5412, -0.3668,  0.2337, -0.3805, -0.3192,\n",
       "        -0.1822, -0.2380,  0.1476,  0.2426, -0.1735, -0.6512, -0.0964, -0.3436,\n",
       "        -0.4375,  0.1712,  0.2869, -0.3777, -0.0960,  0.0446, -0.6620, -0.1518,\n",
       "         0.0783, -0.1395, -0.1295, -0.0672,  0.0447, -0.1665, -0.1681, -0.0594,\n",
       "        -0.0520,  0.0940,  0.3197, -0.7485,  0.3350, -0.3304,  0.7277,  0.1559,\n",
       "        -0.1835, -0.2122, -0.0307, -0.1035, -0.5887, -0.1010, -0.1849,  0.1241,\n",
       "        -0.2730,  0.3260,  0.4460,  0.0047,  0.5569,  0.1412, -0.0704, -0.6714,\n",
       "        -0.3937,  0.4620,  0.6007,  0.0634,  0.2843, -0.1148, -0.1682,  0.2435,\n",
       "        -0.0477, -0.5928,  0.1887,  0.1618, -0.2216, -0.1277,  0.3214,  0.1153,\n",
       "        -0.0776, -0.0512,  0.2159, -0.4572, -0.1724, -0.4550, -0.4511,  0.0078,\n",
       "         0.0656, -0.0973, -0.2052, -0.1723, -0.1829,  0.1668,  0.2151,  0.1195,\n",
       "        -0.1292, -0.4050,  0.3979, -0.2471, -0.0125,  0.3857, -0.0373,  0.3409,\n",
       "         0.2663, -0.3130,  0.1326, -0.1713, -0.0518, -0.1344, -0.8802,  0.0900,\n",
       "        -0.3903, -0.5632, -0.0326, -0.0548,  0.1888,  0.1297,  0.1333,  0.2802,\n",
       "         0.0621,  0.0459,  0.3939,  0.4589, -0.1342,  0.5173,  0.9171,  0.1268,\n",
       "        -0.0906, -0.3013, -0.2560,  0.2175,  0.1148,  0.3377, -0.0190,  0.3317,\n",
       "         0.3925, -0.0142, -0.1809, -0.3273,  0.0753,  0.3583, -0.0312,  0.3345,\n",
       "         0.1479, -0.6696,  0.0016, -0.6577, -0.2457, -0.1673, -0.1115, -0.0066,\n",
       "        -0.3491, -0.1551,  0.4782, -0.1987,  0.5116, -0.1055, -0.5115,  0.2525,\n",
       "         0.1361, -0.2452, -0.3320,  0.0358,  0.0669, -0.1128, -0.4096, -0.4952,\n",
       "         0.2182, -0.1166,  0.0056,  0.5244, -0.0368,  0.2326, -0.3944, -0.0221,\n",
       "        -0.0164, -0.4505,  0.0471, -0.3283, -0.2765,  0.2297, -0.2044, -0.0899,\n",
       "         0.3866,  0.2967, -0.0593, -0.9200,  0.0621,  0.0746, -0.0032, -0.5278,\n",
       "         0.6354,  0.2706, -0.3148, -0.2034, -0.0897,  0.0837,  0.0737, -0.0714,\n",
       "        -0.1244,  0.0917, -0.7353,  0.0067, -0.0381, -0.0194,  0.2383,  0.0722,\n",
       "         0.0625,  0.3819, -0.4605, -0.7379, -0.2331,  0.1523, -0.1406, -0.3066,\n",
       "        -0.3875, -0.2325, -0.1381, -0.4022, -0.0410,  0.0252, -0.3077, -0.6046,\n",
       "        -0.0775, -0.3509,  0.1834, -0.1602, -0.3916, -0.1413, -0.2520, -0.6807,\n",
       "         0.2732, -0.1031, -0.4802, -0.4552,  0.5487, -0.2016, -0.0905,  0.4519,\n",
       "        -0.0333, -0.3870, -0.0351, -0.3050,  0.2156,  0.2910, -0.0990,  0.2881,\n",
       "        -0.0363,  0.0758,  0.3884,  0.0195, -0.2481,  0.4388, -0.2722, -0.1530,\n",
       "         0.0750,  0.1153, -0.3267, -0.1437, -0.1451,  0.2331, -0.2424, -0.0992,\n",
       "         0.5766, -0.0707, -0.3373,  0.2790, -0.3374, -0.1242,  0.5963, -0.7624,\n",
       "         0.3728,  0.0600,  0.7939,  0.1195, -0.2676, -0.1686,  0.1282, -0.3003,\n",
       "         0.5647, -0.1912,  0.6726,  0.5918, -0.2902, -0.5115, -0.0372,  0.0385,\n",
       "         0.0755, -0.4212, -0.2448, -0.0876,  0.1749,  0.0373, -0.4126,  0.2272,\n",
       "         0.0729, -0.5435, -0.4953,  0.3095, -0.2222,  0.4869,  0.0361, -0.1579,\n",
       "        -0.4914,  0.1938,  0.1019,  0.1077,  0.0319,  0.0678, -0.1602, -0.0934,\n",
       "        -0.0470, -0.8298,  0.2237,  0.2575,  0.7284, -0.3418, -0.3032,  0.3073,\n",
       "        -0.2790, -0.0770, -0.3180,  0.3372, -0.0358,  0.1011, -0.0200,  0.1478,\n",
       "         0.3784, -0.5022,  0.0069, -0.2537,  0.5314,  0.0189, -0.1766,  0.4524,\n",
       "         0.0458,  0.2786,  0.1858, -0.1759,  0.0392, -0.3449,  0.4008,  0.3647,\n",
       "         0.0255, -0.3479,  0.0961,  0.1325, -0.4899, -0.2081, -0.0909,  0.1764,\n",
       "        -0.0779,  0.0426,  0.5097,  0.0900,  0.2023,  0.6477, -0.4675, -0.0099,\n",
       "         0.0544,  0.3847, -0.3736, -0.4956, -0.0998, -0.1932, -0.0740,  0.2583,\n",
       "        -0.2762, -0.7657, -0.0153,  0.1118, -0.4626, -0.5777,  0.7027, -0.1474,\n",
       "        -0.0652, -0.1240,  0.3505,  0.5040], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoannaModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0):\n",
    "        super(MoannaModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # self.batchnorm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.t = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        # self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        # out = self.batchnorm(out)\n",
    "        out = self.relu(out)\n",
    "        # out = self.t(out)\n",
    "        out = self.dropout(out)\n",
    "        # out = self.fc3(out)\n",
    "        # out = self.relu1(out)\n",
    "        # out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(train_dataset, test_loader, k, num_epochs, batch_size, learning_rate, hidden_dim, device, shuffle=True):\n",
    "    \n",
    "    n_samples = len(train_dataset)\n",
    "    fold_size = n_samples // k\n",
    "    indices = np.random.permutation(n_samples)\n",
    "\n",
    "    Model = []\n",
    "    Train_acc = []\n",
    "    Val_acc = []\n",
    "    Test_acc = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(f\"Processing fold {i+1}/{k}...\")\n",
    "        \n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "        \n",
    "        traintrain_indices = list(np.concatenate([indices[:start], indices[end:]]))\n",
    "        trainval_indices = list(indices[start:end])\n",
    "        \n",
    "        # Create data loaders for training and validation\n",
    "        traintrain_dataset = Subset(train_dataset, traintrain_indices)\n",
    "        trainval_dataset = Subset(train_dataset, trainval_indices)\n",
    "        traintrain_loader = DataLoader(traintrain_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        trainval_loader = DataLoader(trainval_dataset, batch_size=batch_size, shuffle=False)    \n",
    "        \n",
    "        # Hyperparameters\n",
    "        # learning_rate = 0.1\n",
    "        # hidden_dim = 512\n",
    "\n",
    "        # Initialize model and transfer to GPU\n",
    "        model = MoannaModel(len(train_dataset[0][0]), hidden_dim, 33).to(device)\n",
    "        \n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        test_accs = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Train\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "            for j, (inputs, labels) in enumerate(traintrain_loader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_acc += accuracy_score(torch.argmax(outputs, dim=1).cpu(), labels.cpu())\n",
    "\n",
    "            train_loss /= len(traintrain_loader)\n",
    "            train_acc /= len(traintrain_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "            # Validate\n",
    "            model.eval()\n",
    "            val_acc = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in trainval_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    val_acc += accuracy_score(torch.argmax(outputs, dim=1).cpu(), labels.cpu())\n",
    "                val_acc /= len(trainval_loader)\n",
    "                val_accs.append(val_acc)\n",
    "\n",
    "            # # Check if this is the best model so far\n",
    "            # if val_acc > best_accuracy:\n",
    "            #     best_accuracy = val_acc\n",
    "            #     best_model = model.__class__(train_dataset.data.shape[1], hidden_dim, 33).to(device)\n",
    "            #     best_model.load_state_dict(model.state_dict())\n",
    "                \n",
    "            # Test\n",
    "            model.eval()\n",
    "            test_acc = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    test_acc += accuracy_score(torch.argmax(outputs, dim=1).cpu(), labels.cpu())\n",
    "                test_acc /= len(test_loader)\n",
    "                test_accs.append(test_acc)\n",
    "                \n",
    "            print(f\"Fold {i+1}/{k}, Epoch {epoch+1}: Train Loss={train_loss:.4f}, \"\n",
    "                  f\"Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "            \n",
    "        MModel = model.__class__(len(train_dataset[0][0]), hidden_dim, 33).to(device)\n",
    "        MModel.load_state_dict(model.state_dict())\n",
    "        Model.append(MModel)\n",
    "        \n",
    "        Train_acc.append(train_accs[-1])\n",
    "        Val_acc.append(val_accs[-1])\n",
    "        Test_acc.append(test_accs[-1])\n",
    "        \n",
    "        # Plot loss and accuracy for this fold\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Fold {i+1} Loss\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_accs, label='Train Acc')\n",
    "        plt.plot(val_accs, label='Val Acc')\n",
    "        plt.plot(test_accs, label='Test Acc')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Fold {i+1} Accuracy\")\n",
    "        plt.show()\n",
    "\n",
    "    return Model, Train_acc, Val_acc, Test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1/5...\n",
      "Fold 1/5, Epoch 1: Train Loss=3.4174, Train Acc=0.1134, Val Acc=0.1472, Test Acc=0.1335\n",
      "Fold 1/5, Epoch 2: Train Loss=3.3042, Train Acc=0.1464, Val Acc=0.1531, Test Acc=0.1454\n",
      "Fold 1/5, Epoch 3: Train Loss=3.2245, Train Acc=0.1568, Val Acc=0.1583, Test Acc=0.1536\n",
      "Fold 1/5, Epoch 4: Train Loss=3.1574, Train Acc=0.1687, Val Acc=0.1635, Test Acc=0.1616\n",
      "Fold 1/5, Epoch 5: Train Loss=3.0990, Train Acc=0.1762, Val Acc=0.1668, Test Acc=0.1665\n",
      "Fold 1/5, Epoch 6: Train Loss=3.0473, Train Acc=0.1842, Val Acc=0.1707, Test Acc=0.1695\n",
      "Fold 1/5, Epoch 7: Train Loss=2.9996, Train Acc=0.1924, Val Acc=0.1845, Test Acc=0.1763\n",
      "Fold 1/5, Epoch 8: Train Loss=2.9545, Train Acc=0.2009, Val Acc=0.1957, Test Acc=0.1851\n",
      "Fold 1/5, Epoch 9: Train Loss=2.9106, Train Acc=0.2124, Val Acc=0.2126, Test Acc=0.2022\n",
      "Fold 1/5, Epoch 10: Train Loss=2.8678, Train Acc=0.2386, Val Acc=0.2270, Test Acc=0.2139\n",
      "Fold 1/5, Epoch 11: Train Loss=2.8260, Train Acc=0.2520, Val Acc=0.2395, Test Acc=0.2240\n",
      "Fold 1/5, Epoch 12: Train Loss=2.7845, Train Acc=0.2666, Val Acc=0.2590, Test Acc=0.2427\n",
      "Fold 1/5, Epoch 13: Train Loss=2.7438, Train Acc=0.2868, Val Acc=0.2800, Test Acc=0.2583\n",
      "Fold 1/5, Epoch 14: Train Loss=2.7039, Train Acc=0.3010, Val Acc=0.2918, Test Acc=0.2628\n",
      "Fold 1/5, Epoch 15: Train Loss=2.6642, Train Acc=0.3095, Val Acc=0.2983, Test Acc=0.2685\n",
      "Fold 1/5, Epoch 16: Train Loss=2.6258, Train Acc=0.3152, Val Acc=0.3094, Test Acc=0.2736\n",
      "Fold 1/5, Epoch 17: Train Loss=2.5882, Train Acc=0.3223, Val Acc=0.3101, Test Acc=0.2771\n",
      "Fold 1/5, Epoch 18: Train Loss=2.5522, Train Acc=0.3265, Val Acc=0.3192, Test Acc=0.2859\n",
      "Fold 1/5, Epoch 19: Train Loss=2.5178, Train Acc=0.3400, Val Acc=0.3395, Test Acc=0.3014\n",
      "Fold 1/5, Epoch 20: Train Loss=2.4844, Train Acc=0.3600, Val Acc=0.3480, Test Acc=0.3097\n",
      "Fold 1/5, Epoch 21: Train Loss=2.4530, Train Acc=0.3680, Val Acc=0.3565, Test Acc=0.3158\n",
      "Fold 1/5, Epoch 22: Train Loss=2.4233, Train Acc=0.3708, Val Acc=0.3572, Test Acc=0.3174\n",
      "Fold 1/5, Epoch 23: Train Loss=2.3955, Train Acc=0.3759, Val Acc=0.3611, Test Acc=0.3204\n",
      "Fold 1/5, Epoch 24: Train Loss=2.3689, Train Acc=0.3798, Val Acc=0.3571, Test Acc=0.3244\n",
      "Fold 1/5, Epoch 25: Train Loss=2.3445, Train Acc=0.3828, Val Acc=0.3591, Test Acc=0.3255\n",
      "Fold 1/5, Epoch 26: Train Loss=2.3208, Train Acc=0.3864, Val Acc=0.3643, Test Acc=0.3268\n",
      "Fold 1/5, Epoch 27: Train Loss=2.2989, Train Acc=0.3875, Val Acc=0.3676, Test Acc=0.3324\n",
      "Fold 1/5, Epoch 28: Train Loss=2.2777, Train Acc=0.3923, Val Acc=0.3630, Test Acc=0.3333\n",
      "Fold 1/5, Epoch 29: Train Loss=2.2581, Train Acc=0.3970, Val Acc=0.3617, Test Acc=0.3376\n",
      "Fold 1/5, Epoch 30: Train Loss=2.2392, Train Acc=0.4026, Val Acc=0.3663, Test Acc=0.3368\n",
      "Fold 1/5, Epoch 31: Train Loss=2.2216, Train Acc=0.4013, Val Acc=0.3689, Test Acc=0.3424\n",
      "Fold 1/5, Epoch 32: Train Loss=2.2042, Train Acc=0.4063, Val Acc=0.3670, Test Acc=0.3431\n",
      "Fold 1/5, Epoch 33: Train Loss=2.1879, Train Acc=0.4099, Val Acc=0.3741, Test Acc=0.3506\n",
      "Fold 1/5, Epoch 34: Train Loss=2.1722, Train Acc=0.4158, Val Acc=0.3716, Test Acc=0.3501\n",
      "Fold 1/5, Epoch 35: Train Loss=2.1572, Train Acc=0.4147, Val Acc=0.3782, Test Acc=0.3543\n",
      "Fold 1/5, Epoch 36: Train Loss=2.1424, Train Acc=0.4213, Val Acc=0.3827, Test Acc=0.3567\n",
      "Fold 1/5, Epoch 37: Train Loss=2.1286, Train Acc=0.4289, Val Acc=0.3788, Test Acc=0.3546\n",
      "Fold 1/5, Epoch 38: Train Loss=2.1154, Train Acc=0.4241, Val Acc=0.3827, Test Acc=0.3605\n",
      "Fold 1/5, Epoch 39: Train Loss=2.1019, Train Acc=0.4302, Val Acc=0.3866, Test Acc=0.3626\n",
      "Fold 1/5, Epoch 40: Train Loss=2.0891, Train Acc=0.4322, Val Acc=0.3905, Test Acc=0.3679\n",
      "Fold 1/5, Epoch 41: Train Loss=2.0769, Train Acc=0.4370, Val Acc=0.3885, Test Acc=0.3698\n",
      "Fold 1/5, Epoch 42: Train Loss=2.0647, Train Acc=0.4406, Val Acc=0.3865, Test Acc=0.3681\n",
      "Fold 1/5, Epoch 43: Train Loss=2.0533, Train Acc=0.4376, Val Acc=0.3911, Test Acc=0.3738\n",
      "Fold 1/5, Epoch 44: Train Loss=2.0414, Train Acc=0.4475, Val Acc=0.3905, Test Acc=0.3717\n",
      "Fold 1/5, Epoch 45: Train Loss=2.0305, Train Acc=0.4449, Val Acc=0.3924, Test Acc=0.3818\n",
      "Fold 1/5, Epoch 46: Train Loss=2.0193, Train Acc=0.4537, Val Acc=0.3917, Test Acc=0.3784\n",
      "Fold 1/5, Epoch 47: Train Loss=2.0091, Train Acc=0.4549, Val Acc=0.3957, Test Acc=0.3828\n",
      "Fold 1/5, Epoch 48: Train Loss=1.9986, Train Acc=0.4610, Val Acc=0.3937, Test Acc=0.3828\n",
      "Fold 1/5, Epoch 49: Train Loss=1.9882, Train Acc=0.4636, Val Acc=0.3950, Test Acc=0.3838\n",
      "Fold 1/5, Epoch 50: Train Loss=1.9782, Train Acc=0.4656, Val Acc=0.3970, Test Acc=0.3873\n",
      "Fold 1/5, Epoch 51: Train Loss=1.9689, Train Acc=0.4691, Val Acc=0.3983, Test Acc=0.3866\n",
      "Fold 1/5, Epoch 52: Train Loss=1.9591, Train Acc=0.4706, Val Acc=0.4022, Test Acc=0.3885\n",
      "Fold 1/5, Epoch 53: Train Loss=1.9499, Train Acc=0.4762, Val Acc=0.4002, Test Acc=0.3928\n",
      "Fold 1/5, Epoch 54: Train Loss=1.9404, Train Acc=0.4785, Val Acc=0.4002, Test Acc=0.3927\n",
      "Fold 1/5, Epoch 55: Train Loss=1.9315, Train Acc=0.4821, Val Acc=0.4009, Test Acc=0.3924\n",
      "Fold 1/5, Epoch 56: Train Loss=1.9227, Train Acc=0.4816, Val Acc=0.3995, Test Acc=0.3904\n",
      "Fold 1/5, Epoch 57: Train Loss=1.9137, Train Acc=0.4869, Val Acc=0.4008, Test Acc=0.3910\n",
      "Fold 1/5, Epoch 58: Train Loss=1.9055, Train Acc=0.4871, Val Acc=0.4041, Test Acc=0.3957\n",
      "Fold 1/5, Epoch 59: Train Loss=1.8969, Train Acc=0.4860, Val Acc=0.4002, Test Acc=0.3993\n",
      "Fold 1/5, Epoch 60: Train Loss=1.8883, Train Acc=0.4897, Val Acc=0.4107, Test Acc=0.3967\n",
      "Fold 1/5, Epoch 61: Train Loss=1.8809, Train Acc=0.4920, Val Acc=0.4107, Test Acc=0.3990\n",
      "Fold 1/5, Epoch 62: Train Loss=1.8724, Train Acc=0.4956, Val Acc=0.4055, Test Acc=0.3980\n",
      "Fold 1/5, Epoch 63: Train Loss=1.8641, Train Acc=0.4983, Val Acc=0.4042, Test Acc=0.3971\n",
      "Fold 1/5, Epoch 64: Train Loss=1.8566, Train Acc=0.4976, Val Acc=0.4081, Test Acc=0.3981\n",
      "Fold 1/5, Epoch 65: Train Loss=1.8491, Train Acc=0.5021, Val Acc=0.4061, Test Acc=0.3965\n",
      "Fold 1/5, Epoch 66: Train Loss=1.8414, Train Acc=0.4988, Val Acc=0.4107, Test Acc=0.4045\n",
      "Fold 1/5, Epoch 67: Train Loss=1.8339, Train Acc=0.5077, Val Acc=0.4074, Test Acc=0.4034\n",
      "Fold 1/5, Epoch 68: Train Loss=1.8267, Train Acc=0.5109, Val Acc=0.4113, Test Acc=0.4042\n",
      "Fold 1/5, Epoch 69: Train Loss=1.8194, Train Acc=0.5091, Val Acc=0.4100, Test Acc=0.4028\n",
      "Fold 1/5, Epoch 70: Train Loss=1.8121, Train Acc=0.5109, Val Acc=0.4074, Test Acc=0.4042\n",
      "Fold 1/5, Epoch 71: Train Loss=1.8046, Train Acc=0.5148, Val Acc=0.4107, Test Acc=0.4058\n",
      "Fold 1/5, Epoch 72: Train Loss=1.7973, Train Acc=0.5150, Val Acc=0.4047, Test Acc=0.4015\n",
      "Fold 1/5, Epoch 73: Train Loss=1.7911, Train Acc=0.5146, Val Acc=0.4100, Test Acc=0.4075\n",
      "Fold 1/5, Epoch 74: Train Loss=1.7841, Train Acc=0.5186, Val Acc=0.4146, Test Acc=0.4050\n",
      "Fold 1/5, Epoch 75: Train Loss=1.7776, Train Acc=0.5208, Val Acc=0.4152, Test Acc=0.4094\n",
      "Fold 1/5, Epoch 76: Train Loss=1.7702, Train Acc=0.5230, Val Acc=0.4152, Test Acc=0.4127\n",
      "Fold 1/5, Epoch 77: Train Loss=1.7639, Train Acc=0.5240, Val Acc=0.4159, Test Acc=0.4128\n",
      "Fold 1/5, Epoch 78: Train Loss=1.7566, Train Acc=0.5250, Val Acc=0.4132, Test Acc=0.4101\n",
      "Fold 1/5, Epoch 79: Train Loss=1.7502, Train Acc=0.5265, Val Acc=0.4158, Test Acc=0.4111\n",
      "Fold 1/5, Epoch 80: Train Loss=1.7442, Train Acc=0.5277, Val Acc=0.4198, Test Acc=0.4134\n",
      "Fold 1/5, Epoch 81: Train Loss=1.7374, Train Acc=0.5279, Val Acc=0.4159, Test Acc=0.4114\n",
      "Fold 1/5, Epoch 82: Train Loss=1.7311, Train Acc=0.5326, Val Acc=0.4237, Test Acc=0.4140\n",
      "Fold 1/5, Epoch 83: Train Loss=1.7245, Train Acc=0.5337, Val Acc=0.4172, Test Acc=0.4104\n",
      "Fold 1/5, Epoch 84: Train Loss=1.7182, Train Acc=0.5384, Val Acc=0.4250, Test Acc=0.4150\n",
      "Fold 1/5, Epoch 85: Train Loss=1.7114, Train Acc=0.5378, Val Acc=0.4237, Test Acc=0.4187\n",
      "Fold 1/5, Epoch 86: Train Loss=1.7055, Train Acc=0.5378, Val Acc=0.4237, Test Acc=0.4175\n",
      "Fold 1/5, Epoch 87: Train Loss=1.6995, Train Acc=0.5405, Val Acc=0.4191, Test Acc=0.4112\n",
      "Fold 1/5, Epoch 88: Train Loss=1.6935, Train Acc=0.5412, Val Acc=0.4237, Test Acc=0.4142\n",
      "Fold 1/5, Epoch 89: Train Loss=1.6879, Train Acc=0.5443, Val Acc=0.4198, Test Acc=0.4155\n",
      "Fold 1/5, Epoch 90: Train Loss=1.6821, Train Acc=0.5429, Val Acc=0.4217, Test Acc=0.4155\n",
      "Fold 1/5, Epoch 91: Train Loss=1.6761, Train Acc=0.5457, Val Acc=0.4217, Test Acc=0.4197\n",
      "Fold 1/5, Epoch 92: Train Loss=1.6700, Train Acc=0.5458, Val Acc=0.4237, Test Acc=0.4168\n",
      "Fold 1/5, Epoch 93: Train Loss=1.6641, Train Acc=0.5459, Val Acc=0.4250, Test Acc=0.4168\n",
      "Fold 1/5, Epoch 94: Train Loss=1.6580, Train Acc=0.5532, Val Acc=0.4204, Test Acc=0.4171\n",
      "Fold 1/5, Epoch 95: Train Loss=1.6522, Train Acc=0.5525, Val Acc=0.4204, Test Acc=0.4138\n",
      "Fold 1/5, Epoch 96: Train Loss=1.6464, Train Acc=0.5529, Val Acc=0.4171, Test Acc=0.4112\n",
      "Fold 1/5, Epoch 97: Train Loss=1.6409, Train Acc=0.5523, Val Acc=0.4256, Test Acc=0.4176\n",
      "Fold 1/5, Epoch 98: Train Loss=1.6360, Train Acc=0.5573, Val Acc=0.4256, Test Acc=0.4184\n",
      "Fold 1/5, Epoch 99: Train Loss=1.6299, Train Acc=0.5572, Val Acc=0.4224, Test Acc=0.4141\n",
      "Fold 1/5, Epoch 100: Train Loss=1.6247, Train Acc=0.5603, Val Acc=0.4282, Test Acc=0.4185\n",
      "Fold 1/5, Epoch 101: Train Loss=1.6189, Train Acc=0.5601, Val Acc=0.4282, Test Acc=0.4169\n",
      "Fold 1/5, Epoch 102: Train Loss=1.6133, Train Acc=0.5620, Val Acc=0.4302, Test Acc=0.4200\n",
      "Fold 1/5, Epoch 103: Train Loss=1.6084, Train Acc=0.5603, Val Acc=0.4256, Test Acc=0.4163\n",
      "Fold 1/5, Epoch 104: Train Loss=1.6029, Train Acc=0.5635, Val Acc=0.4263, Test Acc=0.4175\n",
      "Fold 1/5, Epoch 105: Train Loss=1.5971, Train Acc=0.5645, Val Acc=0.4302, Test Acc=0.4205\n",
      "Fold 1/5, Epoch 106: Train Loss=1.5923, Train Acc=0.5659, Val Acc=0.4276, Test Acc=0.4186\n",
      "Fold 1/5, Epoch 107: Train Loss=1.5869, Train Acc=0.5698, Val Acc=0.4262, Test Acc=0.4171\n",
      "Fold 1/5, Epoch 108: Train Loss=1.5812, Train Acc=0.5671, Val Acc=0.4243, Test Acc=0.4142\n",
      "Fold 1/5, Epoch 109: Train Loss=1.5764, Train Acc=0.5709, Val Acc=0.4250, Test Acc=0.4182\n",
      "Fold 1/5, Epoch 110: Train Loss=1.5713, Train Acc=0.5713, Val Acc=0.4289, Test Acc=0.4175\n",
      "Fold 1/5, Epoch 111: Train Loss=1.5655, Train Acc=0.5766, Val Acc=0.4250, Test Acc=0.4195\n",
      "Fold 1/5, Epoch 112: Train Loss=1.5614, Train Acc=0.5759, Val Acc=0.4276, Test Acc=0.4159\n",
      "Fold 1/5, Epoch 113: Train Loss=1.5560, Train Acc=0.5753, Val Acc=0.4282, Test Acc=0.4210\n",
      "Fold 1/5, Epoch 114: Train Loss=1.5508, Train Acc=0.5768, Val Acc=0.4276, Test Acc=0.4178\n",
      "Fold 1/5, Epoch 115: Train Loss=1.5461, Train Acc=0.5753, Val Acc=0.4282, Test Acc=0.4153\n",
      "Fold 1/5, Epoch 116: Train Loss=1.5408, Train Acc=0.5826, Val Acc=0.4295, Test Acc=0.4169\n",
      "Fold 1/5, Epoch 117: Train Loss=1.5360, Train Acc=0.5808, Val Acc=0.4262, Test Acc=0.4159\n",
      "Fold 1/5, Epoch 118: Train Loss=1.5309, Train Acc=0.5841, Val Acc=0.4263, Test Acc=0.4218\n",
      "Fold 1/5, Epoch 119: Train Loss=1.5261, Train Acc=0.5853, Val Acc=0.4243, Test Acc=0.4155\n",
      "Fold 1/5, Epoch 120: Train Loss=1.5213, Train Acc=0.5861, Val Acc=0.4269, Test Acc=0.4213\n",
      "Fold 1/5, Epoch 121: Train Loss=1.5169, Train Acc=0.5887, Val Acc=0.4243, Test Acc=0.4130\n",
      "Fold 1/5, Epoch 122: Train Loss=1.5121, Train Acc=0.5879, Val Acc=0.4243, Test Acc=0.4145\n",
      "Fold 1/5, Epoch 123: Train Loss=1.5070, Train Acc=0.5906, Val Acc=0.4282, Test Acc=0.4206\n",
      "Fold 1/5, Epoch 124: Train Loss=1.5020, Train Acc=0.5929, Val Acc=0.4184, Test Acc=0.4103\n",
      "Fold 1/5, Epoch 125: Train Loss=1.4979, Train Acc=0.5928, Val Acc=0.4229, Test Acc=0.4160\n",
      "Fold 1/5, Epoch 126: Train Loss=1.4932, Train Acc=0.5959, Val Acc=0.4230, Test Acc=0.4131\n",
      "Fold 1/5, Epoch 127: Train Loss=1.4885, Train Acc=0.5972, Val Acc=0.4229, Test Acc=0.4123\n",
      "Fold 1/5, Epoch 128: Train Loss=1.4837, Train Acc=0.5997, Val Acc=0.4210, Test Acc=0.4184\n",
      "Fold 1/5, Epoch 129: Train Loss=1.4791, Train Acc=0.6018, Val Acc=0.4178, Test Acc=0.4113\n",
      "Fold 1/5, Epoch 130: Train Loss=1.4748, Train Acc=0.6019, Val Acc=0.4243, Test Acc=0.4122\n",
      "Fold 1/5, Epoch 131: Train Loss=1.4706, Train Acc=0.6018, Val Acc=0.4249, Test Acc=0.4145\n",
      "Fold 1/5, Epoch 132: Train Loss=1.4649, Train Acc=0.6045, Val Acc=0.4282, Test Acc=0.4193\n",
      "Fold 1/5, Epoch 133: Train Loss=1.4611, Train Acc=0.6087, Val Acc=0.4243, Test Acc=0.4090\n",
      "Fold 1/5, Epoch 134: Train Loss=1.4570, Train Acc=0.6059, Val Acc=0.4243, Test Acc=0.4187\n",
      "Fold 1/5, Epoch 135: Train Loss=1.4528, Train Acc=0.6094, Val Acc=0.4249, Test Acc=0.4126\n",
      "Fold 1/5, Epoch 136: Train Loss=1.4484, Train Acc=0.6084, Val Acc=0.4242, Test Acc=0.4148\n",
      "Fold 1/5, Epoch 137: Train Loss=1.4437, Train Acc=0.6102, Val Acc=0.4249, Test Acc=0.4126\n",
      "Fold 1/5, Epoch 138: Train Loss=1.4396, Train Acc=0.6118, Val Acc=0.4242, Test Acc=0.4165\n",
      "Fold 1/5, Epoch 139: Train Loss=1.4350, Train Acc=0.6148, Val Acc=0.4223, Test Acc=0.4178\n",
      "Fold 1/5, Epoch 140: Train Loss=1.4308, Train Acc=0.6136, Val Acc=0.4210, Test Acc=0.4151\n",
      "Fold 1/5, Epoch 141: Train Loss=1.4266, Train Acc=0.6159, Val Acc=0.4230, Test Acc=0.4118\n",
      "Fold 1/5, Epoch 142: Train Loss=1.4226, Train Acc=0.6169, Val Acc=0.4184, Test Acc=0.4151\n",
      "Fold 1/5, Epoch 143: Train Loss=1.4173, Train Acc=0.6155, Val Acc=0.4242, Test Acc=0.4160\n",
      "Fold 1/5, Epoch 144: Train Loss=1.4146, Train Acc=0.6155, Val Acc=0.4210, Test Acc=0.4159\n",
      "Fold 1/5, Epoch 145: Train Loss=1.4095, Train Acc=0.6177, Val Acc=0.4216, Test Acc=0.4144\n",
      "Fold 1/5, Epoch 146: Train Loss=1.4060, Train Acc=0.6188, Val Acc=0.4217, Test Acc=0.4157\n",
      "Fold 1/5, Epoch 147: Train Loss=1.4022, Train Acc=0.6217, Val Acc=0.4203, Test Acc=0.4166\n",
      "Fold 1/5, Epoch 148: Train Loss=1.3975, Train Acc=0.6231, Val Acc=0.4210, Test Acc=0.4144\n",
      "Fold 1/5, Epoch 149: Train Loss=1.3938, Train Acc=0.6236, Val Acc=0.4210, Test Acc=0.4180\n",
      "Fold 1/5, Epoch 150: Train Loss=1.3895, Train Acc=0.6233, Val Acc=0.4184, Test Acc=0.4130\n",
      "Fold 1/5, Epoch 151: Train Loss=1.3851, Train Acc=0.6276, Val Acc=0.4197, Test Acc=0.4140\n",
      "Fold 1/5, Epoch 152: Train Loss=1.3811, Train Acc=0.6278, Val Acc=0.4171, Test Acc=0.4171\n",
      "Fold 1/5, Epoch 153: Train Loss=1.3769, Train Acc=0.6294, Val Acc=0.4190, Test Acc=0.4151\n",
      "Fold 1/5, Epoch 154: Train Loss=1.3733, Train Acc=0.6284, Val Acc=0.4177, Test Acc=0.4173\n",
      "Fold 1/5, Epoch 155: Train Loss=1.3700, Train Acc=0.6286, Val Acc=0.4203, Test Acc=0.4176\n",
      "Fold 1/5, Epoch 156: Train Loss=1.3656, Train Acc=0.6315, Val Acc=0.4197, Test Acc=0.4160\n",
      "Fold 1/5, Epoch 157: Train Loss=1.3619, Train Acc=0.6347, Val Acc=0.4197, Test Acc=0.4192\n",
      "Fold 1/5, Epoch 158: Train Loss=1.3579, Train Acc=0.6362, Val Acc=0.4177, Test Acc=0.4134\n",
      "Fold 1/5, Epoch 159: Train Loss=1.3544, Train Acc=0.6334, Val Acc=0.4171, Test Acc=0.4159\n",
      "Fold 1/5, Epoch 160: Train Loss=1.3503, Train Acc=0.6365, Val Acc=0.4197, Test Acc=0.4157\n",
      "Fold 1/5, Epoch 161: Train Loss=1.3470, Train Acc=0.6341, Val Acc=0.4197, Test Acc=0.4143\n",
      "Fold 1/5, Epoch 162: Train Loss=1.3425, Train Acc=0.6381, Val Acc=0.4171, Test Acc=0.4142\n",
      "Fold 1/5, Epoch 163: Train Loss=1.3386, Train Acc=0.6402, Val Acc=0.4230, Test Acc=0.4175\n",
      "Fold 1/5, Epoch 164: Train Loss=1.3347, Train Acc=0.6415, Val Acc=0.4145, Test Acc=0.4108\n",
      "Fold 1/5, Epoch 165: Train Loss=1.3310, Train Acc=0.6392, Val Acc=0.4197, Test Acc=0.4175\n",
      "Fold 1/5, Epoch 166: Train Loss=1.3279, Train Acc=0.6398, Val Acc=0.4204, Test Acc=0.4137\n",
      "Fold 1/5, Epoch 167: Train Loss=1.3232, Train Acc=0.6438, Val Acc=0.4230, Test Acc=0.4194\n",
      "Fold 1/5, Epoch 168: Train Loss=1.3200, Train Acc=0.6433, Val Acc=0.4178, Test Acc=0.4145\n",
      "Fold 1/5, Epoch 169: Train Loss=1.3164, Train Acc=0.6447, Val Acc=0.4204, Test Acc=0.4158\n",
      "Fold 1/5, Epoch 170: Train Loss=1.3128, Train Acc=0.6452, Val Acc=0.4230, Test Acc=0.4161\n",
      "Fold 1/5, Epoch 171: Train Loss=1.3099, Train Acc=0.6484, Val Acc=0.4171, Test Acc=0.4151\n",
      "Fold 1/5, Epoch 172: Train Loss=1.3059, Train Acc=0.6478, Val Acc=0.4184, Test Acc=0.4162\n",
      "Fold 1/5, Epoch 173: Train Loss=1.3022, Train Acc=0.6496, Val Acc=0.4171, Test Acc=0.4154\n",
      "Fold 1/5, Epoch 174: Train Loss=1.2986, Train Acc=0.6516, Val Acc=0.4191, Test Acc=0.4128\n",
      "Fold 1/5, Epoch 175: Train Loss=1.2954, Train Acc=0.6502, Val Acc=0.4178, Test Acc=0.4154\n",
      "Fold 1/5, Epoch 176: Train Loss=1.2918, Train Acc=0.6545, Val Acc=0.4191, Test Acc=0.4136\n",
      "Fold 1/5, Epoch 177: Train Loss=1.2875, Train Acc=0.6551, Val Acc=0.4184, Test Acc=0.4149\n",
      "Fold 1/5, Epoch 178: Train Loss=1.2841, Train Acc=0.6575, Val Acc=0.4191, Test Acc=0.4139\n",
      "Fold 1/5, Epoch 179: Train Loss=1.2813, Train Acc=0.6559, Val Acc=0.4217, Test Acc=0.4142\n",
      "Fold 1/5, Epoch 180: Train Loss=1.2775, Train Acc=0.6575, Val Acc=0.4171, Test Acc=0.4134\n",
      "Fold 1/5, Epoch 181: Train Loss=1.2737, Train Acc=0.6601, Val Acc=0.4198, Test Acc=0.4136\n",
      "Fold 1/5, Epoch 182: Train Loss=1.2699, Train Acc=0.6595, Val Acc=0.4198, Test Acc=0.4142\n",
      "Fold 1/5, Epoch 183: Train Loss=1.2664, Train Acc=0.6615, Val Acc=0.4198, Test Acc=0.4104\n",
      "Fold 1/5, Epoch 184: Train Loss=1.2632, Train Acc=0.6616, Val Acc=0.4171, Test Acc=0.4123\n",
      "Fold 1/5, Epoch 185: Train Loss=1.2599, Train Acc=0.6637, Val Acc=0.4171, Test Acc=0.4156\n",
      "Fold 1/5, Epoch 186: Train Loss=1.2572, Train Acc=0.6630, Val Acc=0.4217, Test Acc=0.4124\n",
      "Fold 1/5, Epoch 187: Train Loss=1.2531, Train Acc=0.6662, Val Acc=0.4250, Test Acc=0.4128\n",
      "Fold 1/5, Epoch 188: Train Loss=1.2504, Train Acc=0.6641, Val Acc=0.4211, Test Acc=0.4138\n",
      "Fold 1/5, Epoch 189: Train Loss=1.2464, Train Acc=0.6668, Val Acc=0.4184, Test Acc=0.4115\n",
      "Fold 1/5, Epoch 190: Train Loss=1.2434, Train Acc=0.6684, Val Acc=0.4230, Test Acc=0.4129\n",
      "Fold 1/5, Epoch 191: Train Loss=1.2394, Train Acc=0.6692, Val Acc=0.4211, Test Acc=0.4095\n",
      "Fold 1/5, Epoch 192: Train Loss=1.2366, Train Acc=0.6694, Val Acc=0.4204, Test Acc=0.4101\n",
      "Fold 1/5, Epoch 193: Train Loss=1.2327, Train Acc=0.6695, Val Acc=0.4184, Test Acc=0.4129\n",
      "Fold 1/5, Epoch 194: Train Loss=1.2300, Train Acc=0.6702, Val Acc=0.4178, Test Acc=0.4143\n",
      "Fold 1/5, Epoch 195: Train Loss=1.2267, Train Acc=0.6721, Val Acc=0.4165, Test Acc=0.4135\n",
      "Fold 1/5, Epoch 196: Train Loss=1.2232, Train Acc=0.6709, Val Acc=0.4217, Test Acc=0.4106\n",
      "Fold 1/5, Epoch 197: Train Loss=1.2206, Train Acc=0.6723, Val Acc=0.4204, Test Acc=0.4129\n",
      "Fold 1/5, Epoch 198: Train Loss=1.2173, Train Acc=0.6756, Val Acc=0.4204, Test Acc=0.4122\n",
      "Fold 1/5, Epoch 199: Train Loss=1.2141, Train Acc=0.6774, Val Acc=0.4218, Test Acc=0.4096\n",
      "Fold 1/5, Epoch 200: Train Loss=1.2106, Train Acc=0.6778, Val Acc=0.4179, Test Acc=0.4115\n",
      "Fold 1/5, Epoch 201: Train Loss=1.2079, Train Acc=0.6792, Val Acc=0.4178, Test Acc=0.4118\n",
      "Fold 1/5, Epoch 202: Train Loss=1.2047, Train Acc=0.6814, Val Acc=0.4178, Test Acc=0.4122\n",
      "Fold 1/5, Epoch 203: Train Loss=1.2012, Train Acc=0.6815, Val Acc=0.4184, Test Acc=0.4096\n",
      "Fold 1/5, Epoch 204: Train Loss=1.1983, Train Acc=0.6836, Val Acc=0.4172, Test Acc=0.4116\n",
      "Fold 1/5, Epoch 205: Train Loss=1.1948, Train Acc=0.6833, Val Acc=0.4191, Test Acc=0.4126\n",
      "Fold 1/5, Epoch 206: Train Loss=1.1921, Train Acc=0.6839, Val Acc=0.4191, Test Acc=0.4125\n",
      "Fold 1/5, Epoch 207: Train Loss=1.1890, Train Acc=0.6875, Val Acc=0.4165, Test Acc=0.4091\n",
      "Fold 1/5, Epoch 208: Train Loss=1.1854, Train Acc=0.6860, Val Acc=0.4158, Test Acc=0.4099\n",
      "Fold 1/5, Epoch 209: Train Loss=1.1819, Train Acc=0.6883, Val Acc=0.4165, Test Acc=0.4102\n",
      "Fold 1/5, Epoch 210: Train Loss=1.1796, Train Acc=0.6887, Val Acc=0.4231, Test Acc=0.4140\n",
      "Fold 1/5, Epoch 211: Train Loss=1.1770, Train Acc=0.6893, Val Acc=0.4185, Test Acc=0.4097\n",
      "Fold 1/5, Epoch 212: Train Loss=1.1737, Train Acc=0.6907, Val Acc=0.4211, Test Acc=0.4080\n",
      "Fold 1/5, Epoch 213: Train Loss=1.1703, Train Acc=0.6919, Val Acc=0.4218, Test Acc=0.4102\n",
      "Fold 1/5, Epoch 214: Train Loss=1.1670, Train Acc=0.6922, Val Acc=0.4158, Test Acc=0.4095\n",
      "Fold 1/5, Epoch 215: Train Loss=1.1646, Train Acc=0.6913, Val Acc=0.4218, Test Acc=0.4093\n",
      "Fold 1/5, Epoch 216: Train Loss=1.1617, Train Acc=0.6930, Val Acc=0.4192, Test Acc=0.4086\n",
      "Fold 1/5, Epoch 217: Train Loss=1.1584, Train Acc=0.6948, Val Acc=0.4191, Test Acc=0.4074\n",
      "Fold 1/5, Epoch 218: Train Loss=1.1553, Train Acc=0.6968, Val Acc=0.4185, Test Acc=0.4081\n",
      "Fold 1/5, Epoch 219: Train Loss=1.1525, Train Acc=0.6964, Val Acc=0.4185, Test Acc=0.4080\n",
      "Fold 1/5, Epoch 220: Train Loss=1.1499, Train Acc=0.6931, Val Acc=0.4198, Test Acc=0.4100\n",
      "Fold 1/5, Epoch 221: Train Loss=1.1470, Train Acc=0.6980, Val Acc=0.4198, Test Acc=0.4069\n",
      "Fold 1/5, Epoch 222: Train Loss=1.1440, Train Acc=0.6993, Val Acc=0.4211, Test Acc=0.4097\n",
      "Fold 1/5, Epoch 223: Train Loss=1.1407, Train Acc=0.6988, Val Acc=0.4218, Test Acc=0.4077\n",
      "Fold 1/5, Epoch 224: Train Loss=1.1383, Train Acc=0.6994, Val Acc=0.4205, Test Acc=0.4061\n",
      "Fold 1/5, Epoch 225: Train Loss=1.1354, Train Acc=0.6995, Val Acc=0.4179, Test Acc=0.4065\n",
      "Fold 1/5, Epoch 226: Train Loss=1.1326, Train Acc=0.7012, Val Acc=0.4185, Test Acc=0.4070\n",
      "Fold 1/5, Epoch 227: Train Loss=1.1295, Train Acc=0.7023, Val Acc=0.4192, Test Acc=0.4054\n",
      "Fold 1/5, Epoch 228: Train Loss=1.1272, Train Acc=0.7029, Val Acc=0.4172, Test Acc=0.4079\n",
      "Fold 1/5, Epoch 229: Train Loss=1.1236, Train Acc=0.7025, Val Acc=0.4185, Test Acc=0.4076\n",
      "Fold 1/5, Epoch 230: Train Loss=1.1211, Train Acc=0.7032, Val Acc=0.4211, Test Acc=0.4068\n",
      "Fold 1/5, Epoch 231: Train Loss=1.1181, Train Acc=0.7034, Val Acc=0.4159, Test Acc=0.4071\n",
      "Fold 1/5, Epoch 232: Train Loss=1.1156, Train Acc=0.7075, Val Acc=0.4211, Test Acc=0.4068\n",
      "Fold 1/5, Epoch 233: Train Loss=1.1130, Train Acc=0.7069, Val Acc=0.4185, Test Acc=0.4062\n",
      "Fold 1/5, Epoch 234: Train Loss=1.1096, Train Acc=0.7073, Val Acc=0.4166, Test Acc=0.4083\n",
      "Fold 1/5, Epoch 235: Train Loss=1.1067, Train Acc=0.7094, Val Acc=0.4205, Test Acc=0.4057\n",
      "Fold 1/5, Epoch 236: Train Loss=1.1041, Train Acc=0.7082, Val Acc=0.4198, Test Acc=0.4073\n",
      "Fold 1/5, Epoch 237: Train Loss=1.1018, Train Acc=0.7087, Val Acc=0.4191, Test Acc=0.4034\n",
      "Fold 1/5, Epoch 238: Train Loss=1.0996, Train Acc=0.7110, Val Acc=0.4165, Test Acc=0.4055\n",
      "Fold 1/5, Epoch 239: Train Loss=1.0957, Train Acc=0.7130, Val Acc=0.4146, Test Acc=0.4050\n",
      "Fold 1/5, Epoch 240: Train Loss=1.0934, Train Acc=0.7110, Val Acc=0.4172, Test Acc=0.4052\n",
      "Fold 1/5, Epoch 241: Train Loss=1.0907, Train Acc=0.7105, Val Acc=0.4179, Test Acc=0.4057\n",
      "Fold 1/5, Epoch 242: Train Loss=1.0881, Train Acc=0.7155, Val Acc=0.4166, Test Acc=0.4049\n",
      "Fold 1/5, Epoch 243: Train Loss=1.0851, Train Acc=0.7126, Val Acc=0.4224, Test Acc=0.4043\n",
      "Fold 1/5, Epoch 244: Train Loss=1.0828, Train Acc=0.7141, Val Acc=0.4198, Test Acc=0.4036\n",
      "Fold 1/5, Epoch 245: Train Loss=1.0796, Train Acc=0.7192, Val Acc=0.4218, Test Acc=0.4023\n",
      "Fold 1/5, Epoch 246: Train Loss=1.0777, Train Acc=0.7165, Val Acc=0.4179, Test Acc=0.4035\n",
      "Fold 1/5, Epoch 247: Train Loss=1.0750, Train Acc=0.7161, Val Acc=0.4205, Test Acc=0.4041\n",
      "Fold 1/5, Epoch 248: Train Loss=1.0720, Train Acc=0.7174, Val Acc=0.4172, Test Acc=0.4035\n",
      "Fold 1/5, Epoch 249: Train Loss=1.0696, Train Acc=0.7204, Val Acc=0.4179, Test Acc=0.4029\n",
      "Fold 1/5, Epoch 250: Train Loss=1.0666, Train Acc=0.7190, Val Acc=0.4205, Test Acc=0.4029\n",
      "Fold 1/5, Epoch 251: Train Loss=1.0641, Train Acc=0.7207, Val Acc=0.4205, Test Acc=0.4032\n",
      "Fold 1/5, Epoch 252: Train Loss=1.0622, Train Acc=0.7209, Val Acc=0.4192, Test Acc=0.4029\n",
      "Fold 1/5, Epoch 253: Train Loss=1.0588, Train Acc=0.7240, Val Acc=0.4139, Test Acc=0.4020\n",
      "Fold 1/5, Epoch 254: Train Loss=1.0563, Train Acc=0.7245, Val Acc=0.4179, Test Acc=0.4037\n",
      "Fold 1/5, Epoch 255: Train Loss=1.0540, Train Acc=0.7234, Val Acc=0.4185, Test Acc=0.4043\n",
      "Fold 1/5, Epoch 256: Train Loss=1.0513, Train Acc=0.7245, Val Acc=0.4178, Test Acc=0.4030\n",
      "Fold 1/5, Epoch 257: Train Loss=1.0490, Train Acc=0.7238, Val Acc=0.4218, Test Acc=0.4036\n",
      "Fold 1/5, Epoch 258: Train Loss=1.0462, Train Acc=0.7251, Val Acc=0.4191, Test Acc=0.4006\n",
      "Fold 1/5, Epoch 259: Train Loss=1.0435, Train Acc=0.7286, Val Acc=0.4218, Test Acc=0.4019\n",
      "Fold 1/5, Epoch 260: Train Loss=1.0412, Train Acc=0.7295, Val Acc=0.4185, Test Acc=0.4034\n",
      "Fold 1/5, Epoch 261: Train Loss=1.0381, Train Acc=0.7286, Val Acc=0.4198, Test Acc=0.4022\n",
      "Fold 1/5, Epoch 262: Train Loss=1.0361, Train Acc=0.7308, Val Acc=0.4185, Test Acc=0.4022\n",
      "Fold 1/5, Epoch 263: Train Loss=1.0340, Train Acc=0.7298, Val Acc=0.4179, Test Acc=0.4025\n",
      "Fold 1/5, Epoch 264: Train Loss=1.0309, Train Acc=0.7318, Val Acc=0.4140, Test Acc=0.4012\n",
      "Fold 1/5, Epoch 265: Train Loss=1.0291, Train Acc=0.7313, Val Acc=0.4218, Test Acc=0.4033\n",
      "Fold 1/5, Epoch 266: Train Loss=1.0268, Train Acc=0.7315, Val Acc=0.4211, Test Acc=0.4018\n",
      "Fold 1/5, Epoch 267: Train Loss=1.0241, Train Acc=0.7346, Val Acc=0.4166, Test Acc=0.4022\n",
      "Fold 1/5, Epoch 268: Train Loss=1.0218, Train Acc=0.7346, Val Acc=0.4185, Test Acc=0.4015\n",
      "Fold 1/5, Epoch 269: Train Loss=1.0188, Train Acc=0.7349, Val Acc=0.4179, Test Acc=0.4025\n",
      "Fold 1/5, Epoch 270: Train Loss=1.0168, Train Acc=0.7373, Val Acc=0.4146, Test Acc=0.4016\n",
      "Fold 1/5, Epoch 271: Train Loss=1.0142, Train Acc=0.7355, Val Acc=0.4178, Test Acc=0.4010\n",
      "Fold 1/5, Epoch 272: Train Loss=1.0117, Train Acc=0.7366, Val Acc=0.4146, Test Acc=0.3996\n",
      "Fold 1/5, Epoch 273: Train Loss=1.0096, Train Acc=0.7373, Val Acc=0.4126, Test Acc=0.3996\n",
      "Fold 1/5, Epoch 274: Train Loss=1.0067, Train Acc=0.7384, Val Acc=0.4139, Test Acc=0.4015\n",
      "Fold 1/5, Epoch 275: Train Loss=1.0048, Train Acc=0.7389, Val Acc=0.4165, Test Acc=0.4042\n",
      "Fold 1/5, Epoch 276: Train Loss=1.0023, Train Acc=0.7400, Val Acc=0.4152, Test Acc=0.4001\n",
      "Fold 1/5, Epoch 277: Train Loss=0.9998, Train Acc=0.7409, Val Acc=0.4159, Test Acc=0.4015\n",
      "Fold 1/5, Epoch 278: Train Loss=0.9979, Train Acc=0.7393, Val Acc=0.4139, Test Acc=0.4017\n",
      "Fold 1/5, Epoch 279: Train Loss=0.9953, Train Acc=0.7418, Val Acc=0.4172, Test Acc=0.4009\n",
      "Fold 1/5, Epoch 280: Train Loss=0.9922, Train Acc=0.7443, Val Acc=0.4172, Test Acc=0.3963\n",
      "Fold 1/5, Epoch 281: Train Loss=0.9902, Train Acc=0.7428, Val Acc=0.4106, Test Acc=0.3990\n",
      "Fold 1/5, Epoch 282: Train Loss=0.9878, Train Acc=0.7434, Val Acc=0.4153, Test Acc=0.3995\n",
      "Fold 1/5, Epoch 283: Train Loss=0.9855, Train Acc=0.7449, Val Acc=0.4126, Test Acc=0.4009\n",
      "Fold 1/5, Epoch 284: Train Loss=0.9835, Train Acc=0.7464, Val Acc=0.4119, Test Acc=0.3979\n",
      "Fold 1/5, Epoch 285: Train Loss=0.9815, Train Acc=0.7462, Val Acc=0.4139, Test Acc=0.3964\n",
      "Fold 1/5, Epoch 286: Train Loss=0.9788, Train Acc=0.7464, Val Acc=0.4132, Test Acc=0.3986\n",
      "Fold 1/5, Epoch 287: Train Loss=0.9762, Train Acc=0.7489, Val Acc=0.4119, Test Acc=0.3980\n",
      "Fold 1/5, Epoch 288: Train Loss=0.9739, Train Acc=0.7498, Val Acc=0.4171, Test Acc=0.3988\n",
      "Fold 1/5, Epoch 289: Train Loss=0.9727, Train Acc=0.7481, Val Acc=0.4126, Test Acc=0.3962\n",
      "Fold 1/5, Epoch 290: Train Loss=0.9703, Train Acc=0.7483, Val Acc=0.4139, Test Acc=0.3987\n",
      "Fold 1/5, Epoch 291: Train Loss=0.9672, Train Acc=0.7513, Val Acc=0.4100, Test Acc=0.3995\n",
      "Fold 1/5, Epoch 292: Train Loss=0.9652, Train Acc=0.7511, Val Acc=0.4113, Test Acc=0.4002\n",
      "Fold 1/5, Epoch 293: Train Loss=0.9630, Train Acc=0.7531, Val Acc=0.4106, Test Acc=0.3982\n",
      "Fold 1/5, Epoch 294: Train Loss=0.9609, Train Acc=0.7533, Val Acc=0.4126, Test Acc=0.3974\n",
      "Fold 1/5, Epoch 295: Train Loss=0.9582, Train Acc=0.7533, Val Acc=0.4126, Test Acc=0.3977\n",
      "Fold 1/5, Epoch 296: Train Loss=0.9562, Train Acc=0.7554, Val Acc=0.4120, Test Acc=0.3957\n",
      "Fold 1/5, Epoch 297: Train Loss=0.9544, Train Acc=0.7533, Val Acc=0.4087, Test Acc=0.3975\n",
      "Fold 1/5, Epoch 298: Train Loss=0.9519, Train Acc=0.7553, Val Acc=0.4074, Test Acc=0.3979\n",
      "Fold 1/5, Epoch 299: Train Loss=0.9497, Train Acc=0.7574, Val Acc=0.4094, Test Acc=0.3953\n",
      "Fold 1/5, Epoch 300: Train Loss=0.9480, Train Acc=0.7574, Val Acc=0.4054, Test Acc=0.3970\n",
      "Fold 1/5, Epoch 301: Train Loss=0.9449, Train Acc=0.7551, Val Acc=0.4080, Test Acc=0.3985\n",
      "Fold 1/5, Epoch 302: Train Loss=0.9428, Train Acc=0.7576, Val Acc=0.4107, Test Acc=0.3954\n",
      "Fold 1/5, Epoch 303: Train Loss=0.9416, Train Acc=0.7592, Val Acc=0.4106, Test Acc=0.3970\n",
      "Fold 1/5, Epoch 304: Train Loss=0.9387, Train Acc=0.7605, Val Acc=0.4133, Test Acc=0.3956\n",
      "Fold 1/5, Epoch 305: Train Loss=0.9367, Train Acc=0.7578, Val Acc=0.4107, Test Acc=0.3949\n",
      "Fold 1/5, Epoch 306: Train Loss=0.9346, Train Acc=0.7622, Val Acc=0.4107, Test Acc=0.3959\n",
      "Fold 1/5, Epoch 307: Train Loss=0.9322, Train Acc=0.7603, Val Acc=0.4094, Test Acc=0.3955\n",
      "Fold 1/5, Epoch 308: Train Loss=0.9297, Train Acc=0.7613, Val Acc=0.4133, Test Acc=0.3961\n",
      "Fold 1/5, Epoch 309: Train Loss=0.9281, Train Acc=0.7628, Val Acc=0.4093, Test Acc=0.3928\n",
      "Fold 1/5, Epoch 310: Train Loss=0.9260, Train Acc=0.7631, Val Acc=0.4087, Test Acc=0.3942\n",
      "Fold 1/5, Epoch 311: Train Loss=0.9234, Train Acc=0.7638, Val Acc=0.4100, Test Acc=0.3938\n",
      "Fold 1/5, Epoch 312: Train Loss=0.9221, Train Acc=0.7650, Val Acc=0.4100, Test Acc=0.3941\n",
      "Fold 1/5, Epoch 313: Train Loss=0.9194, Train Acc=0.7624, Val Acc=0.4087, Test Acc=0.3921\n",
      "Fold 1/5, Epoch 314: Train Loss=0.9179, Train Acc=0.7633, Val Acc=0.4100, Test Acc=0.3918\n",
      "Fold 1/5, Epoch 315: Train Loss=0.9150, Train Acc=0.7683, Val Acc=0.4080, Test Acc=0.3932\n",
      "Fold 1/5, Epoch 316: Train Loss=0.9134, Train Acc=0.7669, Val Acc=0.4119, Test Acc=0.3932\n",
      "Fold 1/5, Epoch 317: Train Loss=0.9108, Train Acc=0.7708, Val Acc=0.4094, Test Acc=0.3926\n",
      "Fold 1/5, Epoch 318: Train Loss=0.9094, Train Acc=0.7687, Val Acc=0.4120, Test Acc=0.3951\n",
      "Fold 1/5, Epoch 319: Train Loss=0.9069, Train Acc=0.7693, Val Acc=0.4139, Test Acc=0.3922\n",
      "Fold 1/5, Epoch 320: Train Loss=0.9056, Train Acc=0.7694, Val Acc=0.4113, Test Acc=0.3925\n",
      "Fold 1/5, Epoch 321: Train Loss=0.9028, Train Acc=0.7694, Val Acc=0.4126, Test Acc=0.3932\n",
      "Fold 1/5, Epoch 322: Train Loss=0.8999, Train Acc=0.7726, Val Acc=0.4113, Test Acc=0.3930\n",
      "Fold 1/5, Epoch 323: Train Loss=0.8988, Train Acc=0.7729, Val Acc=0.4094, Test Acc=0.3917\n",
      "Fold 1/5, Epoch 324: Train Loss=0.8974, Train Acc=0.7725, Val Acc=0.4106, Test Acc=0.3910\n",
      "Fold 1/5, Epoch 325: Train Loss=0.8945, Train Acc=0.7744, Val Acc=0.4107, Test Acc=0.3921\n",
      "Fold 1/5, Epoch 326: Train Loss=0.8926, Train Acc=0.7736, Val Acc=0.4100, Test Acc=0.3899\n",
      "Fold 1/5, Epoch 327: Train Loss=0.8906, Train Acc=0.7758, Val Acc=0.4133, Test Acc=0.3904\n",
      "Fold 1/5, Epoch 328: Train Loss=0.8883, Train Acc=0.7734, Val Acc=0.4120, Test Acc=0.3897\n",
      "Fold 1/5, Epoch 329: Train Loss=0.8863, Train Acc=0.7756, Val Acc=0.4113, Test Acc=0.3891\n",
      "Fold 1/5, Epoch 330: Train Loss=0.8851, Train Acc=0.7764, Val Acc=0.4146, Test Acc=0.3908\n",
      "Fold 1/5, Epoch 331: Train Loss=0.8829, Train Acc=0.7750, Val Acc=0.4100, Test Acc=0.3899\n",
      "Fold 1/5, Epoch 332: Train Loss=0.8814, Train Acc=0.7774, Val Acc=0.4093, Test Acc=0.3897\n",
      "Fold 1/5, Epoch 333: Train Loss=0.8798, Train Acc=0.7777, Val Acc=0.4133, Test Acc=0.3878\n",
      "Fold 1/5, Epoch 334: Train Loss=0.8770, Train Acc=0.7789, Val Acc=0.4120, Test Acc=0.3894\n",
      "Fold 1/5, Epoch 335: Train Loss=0.8748, Train Acc=0.7789, Val Acc=0.4113, Test Acc=0.3889\n",
      "Fold 1/5, Epoch 336: Train Loss=0.8729, Train Acc=0.7810, Val Acc=0.4119, Test Acc=0.3897\n",
      "Fold 1/5, Epoch 337: Train Loss=0.8712, Train Acc=0.7818, Val Acc=0.4074, Test Acc=0.3885\n",
      "Fold 1/5, Epoch 338: Train Loss=0.8700, Train Acc=0.7799, Val Acc=0.4133, Test Acc=0.3882\n",
      "Fold 1/5, Epoch 339: Train Loss=0.8674, Train Acc=0.7826, Val Acc=0.4113, Test Acc=0.3898\n",
      "Fold 1/5, Epoch 340: Train Loss=0.8648, Train Acc=0.7816, Val Acc=0.4100, Test Acc=0.3886\n",
      "Fold 1/5, Epoch 341: Train Loss=0.8630, Train Acc=0.7829, Val Acc=0.4106, Test Acc=0.3895\n",
      "Fold 1/5, Epoch 342: Train Loss=0.8607, Train Acc=0.7847, Val Acc=0.4120, Test Acc=0.3876\n",
      "Fold 1/5, Epoch 343: Train Loss=0.8590, Train Acc=0.7867, Val Acc=0.4120, Test Acc=0.3868\n",
      "Fold 1/5, Epoch 344: Train Loss=0.8572, Train Acc=0.7864, Val Acc=0.4120, Test Acc=0.3851\n",
      "Fold 1/5, Epoch 345: Train Loss=0.8556, Train Acc=0.7857, Val Acc=0.4106, Test Acc=0.3860\n",
      "Fold 1/5, Epoch 346: Train Loss=0.8537, Train Acc=0.7878, Val Acc=0.4093, Test Acc=0.3857\n",
      "Fold 1/5, Epoch 347: Train Loss=0.8517, Train Acc=0.7866, Val Acc=0.4113, Test Acc=0.3882\n",
      "Fold 1/5, Epoch 348: Train Loss=0.8490, Train Acc=0.7905, Val Acc=0.4113, Test Acc=0.3871\n",
      "Fold 1/5, Epoch 349: Train Loss=0.8478, Train Acc=0.7886, Val Acc=0.4100, Test Acc=0.3874\n",
      "Fold 1/5, Epoch 350: Train Loss=0.8455, Train Acc=0.7897, Val Acc=0.4100, Test Acc=0.3868\n",
      "Fold 1/5, Epoch 351: Train Loss=0.8443, Train Acc=0.7912, Val Acc=0.4107, Test Acc=0.3865\n",
      "Fold 1/5, Epoch 352: Train Loss=0.8420, Train Acc=0.7917, Val Acc=0.4041, Test Acc=0.3872\n",
      "Fold 1/5, Epoch 353: Train Loss=0.8406, Train Acc=0.7923, Val Acc=0.4107, Test Acc=0.3866\n",
      "Fold 1/5, Epoch 354: Train Loss=0.8384, Train Acc=0.7924, Val Acc=0.4048, Test Acc=0.3889\n",
      "Fold 1/5, Epoch 355: Train Loss=0.8369, Train Acc=0.7927, Val Acc=0.4081, Test Acc=0.3864\n",
      "Fold 1/5, Epoch 356: Train Loss=0.8348, Train Acc=0.7940, Val Acc=0.4120, Test Acc=0.3857\n",
      "Fold 1/5, Epoch 357: Train Loss=0.8332, Train Acc=0.7937, Val Acc=0.4100, Test Acc=0.3864\n",
      "Fold 1/5, Epoch 358: Train Loss=0.8322, Train Acc=0.7946, Val Acc=0.4087, Test Acc=0.3845\n",
      "Fold 1/5, Epoch 359: Train Loss=0.8295, Train Acc=0.7958, Val Acc=0.4074, Test Acc=0.3829\n",
      "Fold 1/5, Epoch 360: Train Loss=0.8278, Train Acc=0.7967, Val Acc=0.4074, Test Acc=0.3859\n",
      "Fold 1/5, Epoch 361: Train Loss=0.8259, Train Acc=0.7969, Val Acc=0.4080, Test Acc=0.3843\n",
      "Fold 1/5, Epoch 362: Train Loss=0.8238, Train Acc=0.7980, Val Acc=0.4094, Test Acc=0.3834\n",
      "Fold 1/5, Epoch 363: Train Loss=0.8224, Train Acc=0.7978, Val Acc=0.4087, Test Acc=0.3841\n",
      "Fold 1/5, Epoch 364: Train Loss=0.8204, Train Acc=0.7983, Val Acc=0.4074, Test Acc=0.3825\n",
      "Fold 1/5, Epoch 365: Train Loss=0.8184, Train Acc=0.8012, Val Acc=0.4081, Test Acc=0.3856\n",
      "Fold 1/5, Epoch 366: Train Loss=0.8169, Train Acc=0.7997, Val Acc=0.4074, Test Acc=0.3850\n",
      "Fold 1/5, Epoch 367: Train Loss=0.8144, Train Acc=0.8005, Val Acc=0.4094, Test Acc=0.3865\n",
      "Fold 1/5, Epoch 368: Train Loss=0.8126, Train Acc=0.7995, Val Acc=0.4035, Test Acc=0.3839\n",
      "Fold 1/5, Epoch 369: Train Loss=0.8115, Train Acc=0.8004, Val Acc=0.4074, Test Acc=0.3850\n",
      "Fold 1/5, Epoch 370: Train Loss=0.8102, Train Acc=0.8009, Val Acc=0.4048, Test Acc=0.3850\n",
      "Fold 1/5, Epoch 371: Train Loss=0.8079, Train Acc=0.8023, Val Acc=0.4048, Test Acc=0.3849\n",
      "Fold 1/5, Epoch 372: Train Loss=0.8067, Train Acc=0.8022, Val Acc=0.4068, Test Acc=0.3834\n",
      "Fold 1/5, Epoch 373: Train Loss=0.8037, Train Acc=0.8060, Val Acc=0.4028, Test Acc=0.3839\n",
      "Fold 1/5, Epoch 374: Train Loss=0.8022, Train Acc=0.8060, Val Acc=0.4048, Test Acc=0.3839\n",
      "Fold 1/5, Epoch 375: Train Loss=0.8007, Train Acc=0.8050, Val Acc=0.4074, Test Acc=0.3813\n",
      "Fold 1/5, Epoch 376: Train Loss=0.7989, Train Acc=0.8061, Val Acc=0.4048, Test Acc=0.3816\n",
      "Fold 1/5, Epoch 377: Train Loss=0.7975, Train Acc=0.8056, Val Acc=0.4041, Test Acc=0.3837\n",
      "Fold 1/5, Epoch 378: Train Loss=0.7957, Train Acc=0.8067, Val Acc=0.4047, Test Acc=0.3823\n",
      "Fold 1/5, Epoch 379: Train Loss=0.7934, Train Acc=0.8055, Val Acc=0.4035, Test Acc=0.3838\n",
      "Fold 1/5, Epoch 380: Train Loss=0.7919, Train Acc=0.8092, Val Acc=0.4035, Test Acc=0.3822\n",
      "Fold 1/5, Epoch 381: Train Loss=0.7897, Train Acc=0.8099, Val Acc=0.4061, Test Acc=0.3805\n",
      "Fold 1/5, Epoch 382: Train Loss=0.7883, Train Acc=0.8100, Val Acc=0.4041, Test Acc=0.3834\n",
      "Fold 1/5, Epoch 383: Train Loss=0.7862, Train Acc=0.8115, Val Acc=0.4034, Test Acc=0.3811\n",
      "Fold 1/5, Epoch 384: Train Loss=0.7857, Train Acc=0.8095, Val Acc=0.4061, Test Acc=0.3786\n",
      "Fold 1/5, Epoch 385: Train Loss=0.7834, Train Acc=0.8133, Val Acc=0.4035, Test Acc=0.3809\n",
      "Fold 1/5, Epoch 386: Train Loss=0.7817, Train Acc=0.8122, Val Acc=0.4028, Test Acc=0.3819\n",
      "Fold 1/5, Epoch 387: Train Loss=0.7805, Train Acc=0.8113, Val Acc=0.4048, Test Acc=0.3817\n",
      "Fold 1/5, Epoch 388: Train Loss=0.7785, Train Acc=0.8132, Val Acc=0.4021, Test Acc=0.3795\n",
      "Fold 1/5, Epoch 389: Train Loss=0.7757, Train Acc=0.8141, Val Acc=0.4029, Test Acc=0.3793\n",
      "Fold 1/5, Epoch 390: Train Loss=0.7745, Train Acc=0.8160, Val Acc=0.4022, Test Acc=0.3805\n",
      "Fold 1/5, Epoch 391: Train Loss=0.7734, Train Acc=0.8131, Val Acc=0.4035, Test Acc=0.3783\n",
      "Fold 1/5, Epoch 392: Train Loss=0.7714, Train Acc=0.8155, Val Acc=0.4021, Test Acc=0.3792\n",
      "Fold 1/5, Epoch 393: Train Loss=0.7695, Train Acc=0.8155, Val Acc=0.4022, Test Acc=0.3786\n",
      "Fold 1/5, Epoch 394: Train Loss=0.7686, Train Acc=0.8168, Val Acc=0.4008, Test Acc=0.3794\n",
      "Fold 1/5, Epoch 395: Train Loss=0.7662, Train Acc=0.8178, Val Acc=0.4048, Test Acc=0.3796\n",
      "Fold 1/5, Epoch 396: Train Loss=0.7649, Train Acc=0.8182, Val Acc=0.4022, Test Acc=0.3782\n",
      "Fold 1/5, Epoch 397: Train Loss=0.7634, Train Acc=0.8183, Val Acc=0.4041, Test Acc=0.3769\n",
      "Fold 1/5, Epoch 398: Train Loss=0.7612, Train Acc=0.8199, Val Acc=0.4002, Test Acc=0.3773\n",
      "Fold 1/5, Epoch 399: Train Loss=0.7596, Train Acc=0.8195, Val Acc=0.4021, Test Acc=0.3786\n",
      "Fold 1/5, Epoch 400: Train Loss=0.7579, Train Acc=0.8196, Val Acc=0.4009, Test Acc=0.3794\n",
      "Fold 1/5, Epoch 401: Train Loss=0.7567, Train Acc=0.8188, Val Acc=0.4022, Test Acc=0.3782\n",
      "Fold 1/5, Epoch 402: Train Loss=0.7549, Train Acc=0.8212, Val Acc=0.4009, Test Acc=0.3767\n",
      "Fold 1/5, Epoch 403: Train Loss=0.7535, Train Acc=0.8227, Val Acc=0.4015, Test Acc=0.3784\n",
      "Fold 1/5, Epoch 404: Train Loss=0.7515, Train Acc=0.8229, Val Acc=0.4008, Test Acc=0.3781\n",
      "Fold 1/5, Epoch 405: Train Loss=0.7493, Train Acc=0.8229, Val Acc=0.4041, Test Acc=0.3794\n",
      "Fold 1/5, Epoch 406: Train Loss=0.7494, Train Acc=0.8223, Val Acc=0.4015, Test Acc=0.3784\n",
      "Fold 1/5, Epoch 407: Train Loss=0.7467, Train Acc=0.8236, Val Acc=0.4015, Test Acc=0.3768\n",
      "Fold 1/5, Epoch 408: Train Loss=0.7454, Train Acc=0.8246, Val Acc=0.4022, Test Acc=0.3793\n",
      "Fold 1/5, Epoch 409: Train Loss=0.7438, Train Acc=0.8227, Val Acc=0.4008, Test Acc=0.3777\n",
      "Fold 1/5, Epoch 410: Train Loss=0.7423, Train Acc=0.8234, Val Acc=0.4016, Test Acc=0.3777\n",
      "Fold 1/5, Epoch 411: Train Loss=0.7404, Train Acc=0.8251, Val Acc=0.3995, Test Acc=0.3760\n",
      "Fold 1/5, Epoch 412: Train Loss=0.7387, Train Acc=0.8254, Val Acc=0.3982, Test Acc=0.3776\n",
      "Fold 1/5, Epoch 413: Train Loss=0.7374, Train Acc=0.8256, Val Acc=0.4002, Test Acc=0.3758\n",
      "Fold 1/5, Epoch 414: Train Loss=0.7356, Train Acc=0.8266, Val Acc=0.4002, Test Acc=0.3756\n",
      "Fold 1/5, Epoch 415: Train Loss=0.7339, Train Acc=0.8279, Val Acc=0.3982, Test Acc=0.3757\n",
      "Fold 1/5, Epoch 416: Train Loss=0.7318, Train Acc=0.8276, Val Acc=0.4008, Test Acc=0.3767\n",
      "Fold 1/5, Epoch 417: Train Loss=0.7315, Train Acc=0.8270, Val Acc=0.4015, Test Acc=0.3748\n",
      "Fold 1/5, Epoch 418: Train Loss=0.7300, Train Acc=0.8287, Val Acc=0.3989, Test Acc=0.3768\n",
      "Fold 1/5, Epoch 419: Train Loss=0.7276, Train Acc=0.8296, Val Acc=0.3976, Test Acc=0.3784\n",
      "Fold 1/5, Epoch 420: Train Loss=0.7259, Train Acc=0.8301, Val Acc=0.3989, Test Acc=0.3760\n",
      "Fold 1/5, Epoch 421: Train Loss=0.7241, Train Acc=0.8286, Val Acc=0.3976, Test Acc=0.3777\n",
      "Fold 1/5, Epoch 422: Train Loss=0.7232, Train Acc=0.8286, Val Acc=0.3996, Test Acc=0.3748\n",
      "Fold 1/5, Epoch 423: Train Loss=0.7215, Train Acc=0.8323, Val Acc=0.3982, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 424: Train Loss=0.7195, Train Acc=0.8323, Val Acc=0.3996, Test Acc=0.3790\n",
      "Fold 1/5, Epoch 425: Train Loss=0.7189, Train Acc=0.8310, Val Acc=0.3982, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 426: Train Loss=0.7171, Train Acc=0.8337, Val Acc=0.3989, Test Acc=0.3773\n",
      "Fold 1/5, Epoch 427: Train Loss=0.7156, Train Acc=0.8339, Val Acc=0.3976, Test Acc=0.3759\n",
      "Fold 1/5, Epoch 428: Train Loss=0.7150, Train Acc=0.8337, Val Acc=0.3989, Test Acc=0.3751\n",
      "Fold 1/5, Epoch 429: Train Loss=0.7125, Train Acc=0.8360, Val Acc=0.3962, Test Acc=0.3770\n",
      "Fold 1/5, Epoch 430: Train Loss=0.7107, Train Acc=0.8335, Val Acc=0.3904, Test Acc=0.3757\n",
      "Fold 1/5, Epoch 431: Train Loss=0.7097, Train Acc=0.8348, Val Acc=0.3956, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 432: Train Loss=0.7075, Train Acc=0.8338, Val Acc=0.3963, Test Acc=0.3755\n",
      "Fold 1/5, Epoch 433: Train Loss=0.7069, Train Acc=0.8368, Val Acc=0.3949, Test Acc=0.3769\n",
      "Fold 1/5, Epoch 434: Train Loss=0.7050, Train Acc=0.8352, Val Acc=0.3956, Test Acc=0.3778\n",
      "Fold 1/5, Epoch 435: Train Loss=0.7030, Train Acc=0.8378, Val Acc=0.3970, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 436: Train Loss=0.7013, Train Acc=0.8363, Val Acc=0.3930, Test Acc=0.3764\n",
      "Fold 1/5, Epoch 437: Train Loss=0.7000, Train Acc=0.8366, Val Acc=0.3982, Test Acc=0.3769\n",
      "Fold 1/5, Epoch 438: Train Loss=0.6991, Train Acc=0.8376, Val Acc=0.3917, Test Acc=0.3755\n",
      "Fold 1/5, Epoch 439: Train Loss=0.6971, Train Acc=0.8396, Val Acc=0.3930, Test Acc=0.3788\n",
      "Fold 1/5, Epoch 440: Train Loss=0.6962, Train Acc=0.8385, Val Acc=0.3943, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 441: Train Loss=0.6947, Train Acc=0.8396, Val Acc=0.3917, Test Acc=0.3741\n",
      "Fold 1/5, Epoch 442: Train Loss=0.6936, Train Acc=0.8381, Val Acc=0.3943, Test Acc=0.3748\n",
      "Fold 1/5, Epoch 443: Train Loss=0.6917, Train Acc=0.8403, Val Acc=0.3949, Test Acc=0.3744\n",
      "Fold 1/5, Epoch 444: Train Loss=0.6902, Train Acc=0.8417, Val Acc=0.3950, Test Acc=0.3761\n",
      "Fold 1/5, Epoch 445: Train Loss=0.6884, Train Acc=0.8401, Val Acc=0.3943, Test Acc=0.3742\n",
      "Fold 1/5, Epoch 446: Train Loss=0.6879, Train Acc=0.8406, Val Acc=0.3930, Test Acc=0.3771\n",
      "Fold 1/5, Epoch 447: Train Loss=0.6860, Train Acc=0.8420, Val Acc=0.3930, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 448: Train Loss=0.6838, Train Acc=0.8432, Val Acc=0.3936, Test Acc=0.3771\n",
      "Fold 1/5, Epoch 449: Train Loss=0.6829, Train Acc=0.8423, Val Acc=0.3930, Test Acc=0.3755\n",
      "Fold 1/5, Epoch 450: Train Loss=0.6822, Train Acc=0.8435, Val Acc=0.3949, Test Acc=0.3749\n",
      "Fold 1/5, Epoch 451: Train Loss=0.6805, Train Acc=0.8435, Val Acc=0.3930, Test Acc=0.3755\n",
      "Fold 1/5, Epoch 452: Train Loss=0.6789, Train Acc=0.8439, Val Acc=0.3930, Test Acc=0.3771\n",
      "Fold 1/5, Epoch 453: Train Loss=0.6778, Train Acc=0.8437, Val Acc=0.3944, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 454: Train Loss=0.6755, Train Acc=0.8429, Val Acc=0.3904, Test Acc=0.3751\n",
      "Fold 1/5, Epoch 455: Train Loss=0.6745, Train Acc=0.8444, Val Acc=0.3923, Test Acc=0.3743\n",
      "Fold 1/5, Epoch 456: Train Loss=0.6731, Train Acc=0.8451, Val Acc=0.3923, Test Acc=0.3756\n",
      "Fold 1/5, Epoch 457: Train Loss=0.6717, Train Acc=0.8467, Val Acc=0.3904, Test Acc=0.3755\n",
      "Fold 1/5, Epoch 458: Train Loss=0.6708, Train Acc=0.8480, Val Acc=0.3904, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 459: Train Loss=0.6690, Train Acc=0.8481, Val Acc=0.3936, Test Acc=0.3758\n",
      "Fold 1/5, Epoch 460: Train Loss=0.6671, Train Acc=0.8478, Val Acc=0.3917, Test Acc=0.3745\n",
      "Fold 1/5, Epoch 461: Train Loss=0.6658, Train Acc=0.8491, Val Acc=0.3923, Test Acc=0.3749\n",
      "Fold 1/5, Epoch 462: Train Loss=0.6643, Train Acc=0.8496, Val Acc=0.3910, Test Acc=0.3756\n",
      "Fold 1/5, Epoch 463: Train Loss=0.6631, Train Acc=0.8470, Val Acc=0.3930, Test Acc=0.3745\n",
      "Fold 1/5, Epoch 464: Train Loss=0.6611, Train Acc=0.8496, Val Acc=0.3923, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 465: Train Loss=0.6607, Train Acc=0.8500, Val Acc=0.3910, Test Acc=0.3765\n",
      "Fold 1/5, Epoch 466: Train Loss=0.6592, Train Acc=0.8499, Val Acc=0.3910, Test Acc=0.3744\n",
      "Fold 1/5, Epoch 467: Train Loss=0.6573, Train Acc=0.8512, Val Acc=0.3917, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 468: Train Loss=0.6565, Train Acc=0.8515, Val Acc=0.3891, Test Acc=0.3738\n",
      "Fold 1/5, Epoch 469: Train Loss=0.6548, Train Acc=0.8513, Val Acc=0.3897, Test Acc=0.3752\n",
      "Fold 1/5, Epoch 470: Train Loss=0.6535, Train Acc=0.8506, Val Acc=0.3910, Test Acc=0.3757\n",
      "Fold 1/5, Epoch 471: Train Loss=0.6526, Train Acc=0.8517, Val Acc=0.3910, Test Acc=0.3733\n",
      "Fold 1/5, Epoch 472: Train Loss=0.6507, Train Acc=0.8520, Val Acc=0.3923, Test Acc=0.3728\n",
      "Fold 1/5, Epoch 473: Train Loss=0.6495, Train Acc=0.8515, Val Acc=0.3910, Test Acc=0.3732\n",
      "Fold 1/5, Epoch 474: Train Loss=0.6475, Train Acc=0.8540, Val Acc=0.3897, Test Acc=0.3730\n",
      "Fold 1/5, Epoch 475: Train Loss=0.6467, Train Acc=0.8536, Val Acc=0.3891, Test Acc=0.3733\n",
      "Fold 1/5, Epoch 476: Train Loss=0.6454, Train Acc=0.8553, Val Acc=0.3878, Test Acc=0.3728\n",
      "Fold 1/5, Epoch 477: Train Loss=0.6444, Train Acc=0.8535, Val Acc=0.3897, Test Acc=0.3728\n",
      "Fold 1/5, Epoch 478: Train Loss=0.6433, Train Acc=0.8540, Val Acc=0.3897, Test Acc=0.3722\n",
      "Fold 1/5, Epoch 479: Train Loss=0.6410, Train Acc=0.8529, Val Acc=0.3897, Test Acc=0.3719\n",
      "Fold 1/5, Epoch 480: Train Loss=0.6392, Train Acc=0.8534, Val Acc=0.3852, Test Acc=0.3717\n",
      "Fold 1/5, Epoch 481: Train Loss=0.6392, Train Acc=0.8556, Val Acc=0.3910, Test Acc=0.3724\n",
      "Fold 1/5, Epoch 482: Train Loss=0.6377, Train Acc=0.8543, Val Acc=0.3904, Test Acc=0.3729\n",
      "Fold 1/5, Epoch 483: Train Loss=0.6358, Train Acc=0.8564, Val Acc=0.3884, Test Acc=0.3742\n",
      "Fold 1/5, Epoch 484: Train Loss=0.6352, Train Acc=0.8549, Val Acc=0.3904, Test Acc=0.3725\n",
      "Fold 1/5, Epoch 485: Train Loss=0.6331, Train Acc=0.8570, Val Acc=0.3897, Test Acc=0.3725\n",
      "Fold 1/5, Epoch 486: Train Loss=0.6322, Train Acc=0.8595, Val Acc=0.3891, Test Acc=0.3724\n",
      "Fold 1/5, Epoch 487: Train Loss=0.6307, Train Acc=0.8579, Val Acc=0.3897, Test Acc=0.3727\n",
      "Fold 1/5, Epoch 488: Train Loss=0.6295, Train Acc=0.8578, Val Acc=0.3910, Test Acc=0.3728\n",
      "Fold 1/5, Epoch 489: Train Loss=0.6285, Train Acc=0.8589, Val Acc=0.3904, Test Acc=0.3719\n",
      "Fold 1/5, Epoch 490: Train Loss=0.6273, Train Acc=0.8584, Val Acc=0.3897, Test Acc=0.3715\n",
      "Fold 1/5, Epoch 491: Train Loss=0.6257, Train Acc=0.8588, Val Acc=0.3910, Test Acc=0.3718\n",
      "Fold 1/5, Epoch 492: Train Loss=0.6242, Train Acc=0.8588, Val Acc=0.3897, Test Acc=0.3712\n",
      "Fold 1/5, Epoch 493: Train Loss=0.6229, Train Acc=0.8590, Val Acc=0.3904, Test Acc=0.3721\n",
      "Fold 1/5, Epoch 494: Train Loss=0.6219, Train Acc=0.8606, Val Acc=0.3904, Test Acc=0.3716\n",
      "Fold 1/5, Epoch 495: Train Loss=0.6211, Train Acc=0.8607, Val Acc=0.3917, Test Acc=0.3719\n",
      "Fold 1/5, Epoch 496: Train Loss=0.6197, Train Acc=0.8606, Val Acc=0.3911, Test Acc=0.3708\n",
      "Fold 1/5, Epoch 497: Train Loss=0.6182, Train Acc=0.8607, Val Acc=0.3897, Test Acc=0.3708\n",
      "Fold 1/5, Epoch 498: Train Loss=0.6166, Train Acc=0.8615, Val Acc=0.3917, Test Acc=0.3725\n",
      "Fold 1/5, Epoch 499: Train Loss=0.6157, Train Acc=0.8612, Val Acc=0.3904, Test Acc=0.3719\n",
      "Fold 1/5, Epoch 500: Train Loss=0.6141, Train Acc=0.8607, Val Acc=0.3871, Test Acc=0.3719\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 2/5...\n",
      "Fold 2/5, Epoch 1: Train Loss=3.4147, Train Acc=0.1098, Val Acc=0.1280, Test Acc=0.1277\n",
      "Fold 2/5, Epoch 2: Train Loss=3.3060, Train Acc=0.1459, Val Acc=0.1398, Test Acc=0.1409\n",
      "Fold 2/5, Epoch 3: Train Loss=3.2295, Train Acc=0.1547, Val Acc=0.1483, Test Acc=0.1452\n",
      "Fold 2/5, Epoch 4: Train Loss=3.1647, Train Acc=0.1626, Val Acc=0.1548, Test Acc=0.1534\n",
      "Fold 2/5, Epoch 5: Train Loss=3.1073, Train Acc=0.1718, Val Acc=0.1614, Test Acc=0.1612\n",
      "Fold 2/5, Epoch 6: Train Loss=3.0556, Train Acc=0.1808, Val Acc=0.1639, Test Acc=0.1669\n",
      "Fold 2/5, Epoch 7: Train Loss=3.0082, Train Acc=0.1903, Val Acc=0.1771, Test Acc=0.1763\n",
      "Fold 2/5, Epoch 8: Train Loss=2.9631, Train Acc=0.2008, Val Acc=0.1902, Test Acc=0.1852\n",
      "Fold 2/5, Epoch 9: Train Loss=2.9196, Train Acc=0.2160, Val Acc=0.2052, Test Acc=0.2025\n",
      "Fold 2/5, Epoch 10: Train Loss=2.8772, Train Acc=0.2349, Val Acc=0.2176, Test Acc=0.2187\n",
      "Fold 2/5, Epoch 11: Train Loss=2.8350, Train Acc=0.2532, Val Acc=0.2333, Test Acc=0.2311\n",
      "Fold 2/5, Epoch 12: Train Loss=2.7930, Train Acc=0.2721, Val Acc=0.2450, Test Acc=0.2430\n",
      "Fold 2/5, Epoch 13: Train Loss=2.7513, Train Acc=0.2874, Val Acc=0.2619, Test Acc=0.2554\n",
      "Fold 2/5, Epoch 14: Train Loss=2.7098, Train Acc=0.2965, Val Acc=0.2665, Test Acc=0.2617\n",
      "Fold 2/5, Epoch 15: Train Loss=2.6693, Train Acc=0.3045, Val Acc=0.2763, Test Acc=0.2646\n",
      "Fold 2/5, Epoch 16: Train Loss=2.6291, Train Acc=0.3170, Val Acc=0.2907, Test Acc=0.2767\n",
      "Fold 2/5, Epoch 17: Train Loss=2.5904, Train Acc=0.3369, Val Acc=0.3154, Test Acc=0.2955\n",
      "Fold 2/5, Epoch 18: Train Loss=2.5524, Train Acc=0.3532, Val Acc=0.3207, Test Acc=0.3027\n",
      "Fold 2/5, Epoch 19: Train Loss=2.5163, Train Acc=0.3647, Val Acc=0.3285, Test Acc=0.3052\n",
      "Fold 2/5, Epoch 20: Train Loss=2.4820, Train Acc=0.3693, Val Acc=0.3305, Test Acc=0.3069\n",
      "Fold 2/5, Epoch 21: Train Loss=2.4491, Train Acc=0.3724, Val Acc=0.3298, Test Acc=0.3134\n",
      "Fold 2/5, Epoch 22: Train Loss=2.4184, Train Acc=0.3747, Val Acc=0.3370, Test Acc=0.3156\n",
      "Fold 2/5, Epoch 23: Train Loss=2.3893, Train Acc=0.3808, Val Acc=0.3344, Test Acc=0.3120\n",
      "Fold 2/5, Epoch 24: Train Loss=2.3621, Train Acc=0.3822, Val Acc=0.3363, Test Acc=0.3168\n",
      "Fold 2/5, Epoch 25: Train Loss=2.3363, Train Acc=0.3831, Val Acc=0.3377, Test Acc=0.3222\n",
      "Fold 2/5, Epoch 26: Train Loss=2.3125, Train Acc=0.3871, Val Acc=0.3403, Test Acc=0.3253\n",
      "Fold 2/5, Epoch 27: Train Loss=2.2899, Train Acc=0.3898, Val Acc=0.3423, Test Acc=0.3302\n",
      "Fold 2/5, Epoch 28: Train Loss=2.2684, Train Acc=0.3937, Val Acc=0.3475, Test Acc=0.3341\n",
      "Fold 2/5, Epoch 29: Train Loss=2.2477, Train Acc=0.3976, Val Acc=0.3501, Test Acc=0.3376\n",
      "Fold 2/5, Epoch 30: Train Loss=2.2286, Train Acc=0.4055, Val Acc=0.3547, Test Acc=0.3399\n",
      "Fold 2/5, Epoch 31: Train Loss=2.2101, Train Acc=0.4060, Val Acc=0.3547, Test Acc=0.3422\n",
      "Fold 2/5, Epoch 32: Train Loss=2.1928, Train Acc=0.4068, Val Acc=0.3560, Test Acc=0.3456\n",
      "Fold 2/5, Epoch 33: Train Loss=2.1760, Train Acc=0.4141, Val Acc=0.3606, Test Acc=0.3501\n",
      "Fold 2/5, Epoch 34: Train Loss=2.1603, Train Acc=0.4176, Val Acc=0.3619, Test Acc=0.3456\n",
      "Fold 2/5, Epoch 35: Train Loss=2.1447, Train Acc=0.4188, Val Acc=0.3580, Test Acc=0.3542\n",
      "Fold 2/5, Epoch 36: Train Loss=2.1301, Train Acc=0.4254, Val Acc=0.3573, Test Acc=0.3555\n",
      "Fold 2/5, Epoch 37: Train Loss=2.1161, Train Acc=0.4261, Val Acc=0.3625, Test Acc=0.3592\n",
      "Fold 2/5, Epoch 38: Train Loss=2.1022, Train Acc=0.4310, Val Acc=0.3658, Test Acc=0.3559\n",
      "Fold 2/5, Epoch 39: Train Loss=2.0894, Train Acc=0.4323, Val Acc=0.3645, Test Acc=0.3611\n",
      "Fold 2/5, Epoch 40: Train Loss=2.0768, Train Acc=0.4346, Val Acc=0.3678, Test Acc=0.3595\n",
      "Fold 2/5, Epoch 41: Train Loss=2.0639, Train Acc=0.4395, Val Acc=0.3678, Test Acc=0.3627\n",
      "Fold 2/5, Epoch 42: Train Loss=2.0524, Train Acc=0.4403, Val Acc=0.3697, Test Acc=0.3651\n",
      "Fold 2/5, Epoch 43: Train Loss=2.0407, Train Acc=0.4419, Val Acc=0.3665, Test Acc=0.3670\n",
      "Fold 2/5, Epoch 44: Train Loss=2.0293, Train Acc=0.4478, Val Acc=0.3625, Test Acc=0.3675\n",
      "Fold 2/5, Epoch 45: Train Loss=2.0185, Train Acc=0.4500, Val Acc=0.3677, Test Acc=0.3690\n",
      "Fold 2/5, Epoch 46: Train Loss=2.0076, Train Acc=0.4497, Val Acc=0.3638, Test Acc=0.3717\n",
      "Fold 2/5, Epoch 47: Train Loss=1.9969, Train Acc=0.4529, Val Acc=0.3737, Test Acc=0.3706\n",
      "Fold 2/5, Epoch 48: Train Loss=1.9869, Train Acc=0.4571, Val Acc=0.3737, Test Acc=0.3719\n",
      "Fold 2/5, Epoch 49: Train Loss=1.9775, Train Acc=0.4590, Val Acc=0.3763, Test Acc=0.3768\n",
      "Fold 2/5, Epoch 50: Train Loss=1.9674, Train Acc=0.4603, Val Acc=0.3769, Test Acc=0.3761\n",
      "Fold 2/5, Epoch 51: Train Loss=1.9582, Train Acc=0.4660, Val Acc=0.3776, Test Acc=0.3765\n",
      "Fold 2/5, Epoch 52: Train Loss=1.9485, Train Acc=0.4679, Val Acc=0.3776, Test Acc=0.3811\n",
      "Fold 2/5, Epoch 53: Train Loss=1.9396, Train Acc=0.4689, Val Acc=0.3809, Test Acc=0.3820\n",
      "Fold 2/5, Epoch 54: Train Loss=1.9314, Train Acc=0.4739, Val Acc=0.3795, Test Acc=0.3810\n",
      "Fold 2/5, Epoch 55: Train Loss=1.9223, Train Acc=0.4755, Val Acc=0.3835, Test Acc=0.3834\n",
      "Fold 2/5, Epoch 56: Train Loss=1.9137, Train Acc=0.4778, Val Acc=0.3842, Test Acc=0.3842\n",
      "Fold 2/5, Epoch 57: Train Loss=1.9050, Train Acc=0.4776, Val Acc=0.3900, Test Acc=0.3878\n",
      "Fold 2/5, Epoch 58: Train Loss=1.8973, Train Acc=0.4820, Val Acc=0.3927, Test Acc=0.3848\n",
      "Fold 2/5, Epoch 59: Train Loss=1.8891, Train Acc=0.4861, Val Acc=0.3894, Test Acc=0.3858\n",
      "Fold 2/5, Epoch 60: Train Loss=1.8810, Train Acc=0.4860, Val Acc=0.3926, Test Acc=0.3849\n",
      "Fold 2/5, Epoch 61: Train Loss=1.8730, Train Acc=0.4906, Val Acc=0.3940, Test Acc=0.3870\n",
      "Fold 2/5, Epoch 62: Train Loss=1.8652, Train Acc=0.4920, Val Acc=0.3926, Test Acc=0.3868\n",
      "Fold 2/5, Epoch 63: Train Loss=1.8581, Train Acc=0.4937, Val Acc=0.3933, Test Acc=0.3868\n",
      "Fold 2/5, Epoch 64: Train Loss=1.8505, Train Acc=0.4947, Val Acc=0.3959, Test Acc=0.3936\n",
      "Fold 2/5, Epoch 65: Train Loss=1.8426, Train Acc=0.4986, Val Acc=0.3979, Test Acc=0.3906\n",
      "Fold 2/5, Epoch 66: Train Loss=1.8353, Train Acc=0.5000, Val Acc=0.3965, Test Acc=0.3937\n",
      "Fold 2/5, Epoch 67: Train Loss=1.8285, Train Acc=0.5011, Val Acc=0.3985, Test Acc=0.3928\n",
      "Fold 2/5, Epoch 68: Train Loss=1.8215, Train Acc=0.5019, Val Acc=0.4018, Test Acc=0.3951\n",
      "Fold 2/5, Epoch 69: Train Loss=1.8143, Train Acc=0.5083, Val Acc=0.4058, Test Acc=0.3968\n",
      "Fold 2/5, Epoch 70: Train Loss=1.8076, Train Acc=0.5075, Val Acc=0.4051, Test Acc=0.3951\n",
      "Fold 2/5, Epoch 71: Train Loss=1.8006, Train Acc=0.5132, Val Acc=0.4025, Test Acc=0.3954\n",
      "Fold 2/5, Epoch 72: Train Loss=1.7936, Train Acc=0.5113, Val Acc=0.4091, Test Acc=0.3977\n",
      "Fold 2/5, Epoch 73: Train Loss=1.7871, Train Acc=0.5146, Val Acc=0.4077, Test Acc=0.3987\n",
      "Fold 2/5, Epoch 74: Train Loss=1.7805, Train Acc=0.5138, Val Acc=0.4117, Test Acc=0.4027\n",
      "Fold 2/5, Epoch 75: Train Loss=1.7742, Train Acc=0.5180, Val Acc=0.4117, Test Acc=0.3989\n",
      "Fold 2/5, Epoch 76: Train Loss=1.7678, Train Acc=0.5173, Val Acc=0.4104, Test Acc=0.3989\n",
      "Fold 2/5, Epoch 77: Train Loss=1.7607, Train Acc=0.5186, Val Acc=0.4118, Test Acc=0.4016\n",
      "Fold 2/5, Epoch 78: Train Loss=1.7548, Train Acc=0.5209, Val Acc=0.4104, Test Acc=0.3999\n",
      "Fold 2/5, Epoch 79: Train Loss=1.7483, Train Acc=0.5243, Val Acc=0.4137, Test Acc=0.4023\n",
      "Fold 2/5, Epoch 80: Train Loss=1.7420, Train Acc=0.5279, Val Acc=0.4111, Test Acc=0.4000\n",
      "Fold 2/5, Epoch 81: Train Loss=1.7354, Train Acc=0.5273, Val Acc=0.4150, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 82: Train Loss=1.7295, Train Acc=0.5279, Val Acc=0.4131, Test Acc=0.4026\n",
      "Fold 2/5, Epoch 83: Train Loss=1.7236, Train Acc=0.5296, Val Acc=0.4176, Test Acc=0.4066\n",
      "Fold 2/5, Epoch 84: Train Loss=1.7176, Train Acc=0.5313, Val Acc=0.4117, Test Acc=0.4043\n",
      "Fold 2/5, Epoch 85: Train Loss=1.7117, Train Acc=0.5351, Val Acc=0.4150, Test Acc=0.4054\n",
      "Fold 2/5, Epoch 86: Train Loss=1.7054, Train Acc=0.5359, Val Acc=0.4170, Test Acc=0.4043\n",
      "Fold 2/5, Epoch 87: Train Loss=1.6998, Train Acc=0.5337, Val Acc=0.4209, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 88: Train Loss=1.6940, Train Acc=0.5377, Val Acc=0.4202, Test Acc=0.4046\n",
      "Fold 2/5, Epoch 89: Train Loss=1.6881, Train Acc=0.5379, Val Acc=0.4150, Test Acc=0.4027\n",
      "Fold 2/5, Epoch 90: Train Loss=1.6821, Train Acc=0.5422, Val Acc=0.4157, Test Acc=0.4015\n",
      "Fold 2/5, Epoch 91: Train Loss=1.6768, Train Acc=0.5413, Val Acc=0.4235, Test Acc=0.4038\n",
      "Fold 2/5, Epoch 92: Train Loss=1.6709, Train Acc=0.5437, Val Acc=0.4222, Test Acc=0.4018\n",
      "Fold 2/5, Epoch 93: Train Loss=1.6649, Train Acc=0.5457, Val Acc=0.4222, Test Acc=0.4045\n",
      "Fold 2/5, Epoch 94: Train Loss=1.6596, Train Acc=0.5461, Val Acc=0.4170, Test Acc=0.4038\n",
      "Fold 2/5, Epoch 95: Train Loss=1.6547, Train Acc=0.5512, Val Acc=0.4235, Test Acc=0.4031\n",
      "Fold 2/5, Epoch 96: Train Loss=1.6481, Train Acc=0.5511, Val Acc=0.4183, Test Acc=0.3997\n",
      "Fold 2/5, Epoch 97: Train Loss=1.6425, Train Acc=0.5517, Val Acc=0.4248, Test Acc=0.4061\n",
      "Fold 2/5, Epoch 98: Train Loss=1.6375, Train Acc=0.5563, Val Acc=0.4215, Test Acc=0.4052\n",
      "Fold 2/5, Epoch 99: Train Loss=1.6321, Train Acc=0.5541, Val Acc=0.4209, Test Acc=0.4035\n",
      "Fold 2/5, Epoch 100: Train Loss=1.6267, Train Acc=0.5589, Val Acc=0.4196, Test Acc=0.4014\n",
      "Fold 2/5, Epoch 101: Train Loss=1.6222, Train Acc=0.5580, Val Acc=0.4190, Test Acc=0.4042\n",
      "Fold 2/5, Epoch 102: Train Loss=1.6163, Train Acc=0.5610, Val Acc=0.4202, Test Acc=0.4049\n",
      "Fold 2/5, Epoch 103: Train Loss=1.6113, Train Acc=0.5625, Val Acc=0.4202, Test Acc=0.4061\n",
      "Fold 2/5, Epoch 104: Train Loss=1.6058, Train Acc=0.5649, Val Acc=0.4170, Test Acc=0.4050\n",
      "Fold 2/5, Epoch 105: Train Loss=1.6009, Train Acc=0.5647, Val Acc=0.4209, Test Acc=0.4055\n",
      "Fold 2/5, Epoch 106: Train Loss=1.5957, Train Acc=0.5659, Val Acc=0.4189, Test Acc=0.4061\n",
      "Fold 2/5, Epoch 107: Train Loss=1.5908, Train Acc=0.5685, Val Acc=0.4196, Test Acc=0.4055\n",
      "Fold 2/5, Epoch 108: Train Loss=1.5855, Train Acc=0.5737, Val Acc=0.4183, Test Acc=0.4056\n",
      "Fold 2/5, Epoch 109: Train Loss=1.5806, Train Acc=0.5710, Val Acc=0.4202, Test Acc=0.4094\n",
      "Fold 2/5, Epoch 110: Train Loss=1.5759, Train Acc=0.5754, Val Acc=0.4176, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 111: Train Loss=1.5702, Train Acc=0.5737, Val Acc=0.4183, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 112: Train Loss=1.5651, Train Acc=0.5777, Val Acc=0.4176, Test Acc=0.4036\n",
      "Fold 2/5, Epoch 113: Train Loss=1.5604, Train Acc=0.5791, Val Acc=0.4202, Test Acc=0.4033\n",
      "Fold 2/5, Epoch 114: Train Loss=1.5558, Train Acc=0.5829, Val Acc=0.4170, Test Acc=0.4049\n",
      "Fold 2/5, Epoch 115: Train Loss=1.5509, Train Acc=0.5796, Val Acc=0.4202, Test Acc=0.4050\n",
      "Fold 2/5, Epoch 116: Train Loss=1.5458, Train Acc=0.5830, Val Acc=0.4215, Test Acc=0.4077\n",
      "Fold 2/5, Epoch 117: Train Loss=1.5409, Train Acc=0.5827, Val Acc=0.4202, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 118: Train Loss=1.5369, Train Acc=0.5870, Val Acc=0.4183, Test Acc=0.4041\n",
      "Fold 2/5, Epoch 119: Train Loss=1.5321, Train Acc=0.5847, Val Acc=0.4202, Test Acc=0.4071\n",
      "Fold 2/5, Epoch 120: Train Loss=1.5269, Train Acc=0.5909, Val Acc=0.4202, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 121: Train Loss=1.5224, Train Acc=0.5881, Val Acc=0.4202, Test Acc=0.4071\n",
      "Fold 2/5, Epoch 122: Train Loss=1.5182, Train Acc=0.5922, Val Acc=0.4209, Test Acc=0.4044\n",
      "Fold 2/5, Epoch 123: Train Loss=1.5134, Train Acc=0.5938, Val Acc=0.4182, Test Acc=0.4055\n",
      "Fold 2/5, Epoch 124: Train Loss=1.5089, Train Acc=0.5953, Val Acc=0.4182, Test Acc=0.4044\n",
      "Fold 2/5, Epoch 125: Train Loss=1.5042, Train Acc=0.5936, Val Acc=0.4196, Test Acc=0.4032\n",
      "Fold 2/5, Epoch 126: Train Loss=1.4993, Train Acc=0.5951, Val Acc=0.4208, Test Acc=0.4038\n",
      "Fold 2/5, Epoch 127: Train Loss=1.4951, Train Acc=0.5972, Val Acc=0.4182, Test Acc=0.4039\n",
      "Fold 2/5, Epoch 128: Train Loss=1.4907, Train Acc=0.5978, Val Acc=0.4215, Test Acc=0.4067\n",
      "Fold 2/5, Epoch 129: Train Loss=1.4861, Train Acc=0.5992, Val Acc=0.4202, Test Acc=0.4037\n",
      "Fold 2/5, Epoch 130: Train Loss=1.4814, Train Acc=0.6024, Val Acc=0.4222, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 131: Train Loss=1.4776, Train Acc=0.6010, Val Acc=0.4221, Test Acc=0.4070\n",
      "Fold 2/5, Epoch 132: Train Loss=1.4730, Train Acc=0.6042, Val Acc=0.4221, Test Acc=0.4045\n",
      "Fold 2/5, Epoch 133: Train Loss=1.4688, Train Acc=0.6067, Val Acc=0.4176, Test Acc=0.4028\n",
      "Fold 2/5, Epoch 134: Train Loss=1.4649, Train Acc=0.6065, Val Acc=0.4222, Test Acc=0.4065\n",
      "Fold 2/5, Epoch 135: Train Loss=1.4599, Train Acc=0.6092, Val Acc=0.4222, Test Acc=0.4088\n",
      "Fold 2/5, Epoch 136: Train Loss=1.4554, Train Acc=0.6113, Val Acc=0.4228, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 137: Train Loss=1.4521, Train Acc=0.6128, Val Acc=0.4241, Test Acc=0.4073\n",
      "Fold 2/5, Epoch 138: Train Loss=1.4472, Train Acc=0.6116, Val Acc=0.4221, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 139: Train Loss=1.4439, Train Acc=0.6132, Val Acc=0.4228, Test Acc=0.4076\n",
      "Fold 2/5, Epoch 140: Train Loss=1.4388, Train Acc=0.6126, Val Acc=0.4215, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 141: Train Loss=1.4349, Train Acc=0.6160, Val Acc=0.4195, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 142: Train Loss=1.4308, Train Acc=0.6184, Val Acc=0.4202, Test Acc=0.4075\n",
      "Fold 2/5, Epoch 143: Train Loss=1.4267, Train Acc=0.6164, Val Acc=0.4241, Test Acc=0.4075\n",
      "Fold 2/5, Epoch 144: Train Loss=1.4227, Train Acc=0.6190, Val Acc=0.4248, Test Acc=0.4087\n",
      "Fold 2/5, Epoch 145: Train Loss=1.4188, Train Acc=0.6203, Val Acc=0.4261, Test Acc=0.4057\n",
      "Fold 2/5, Epoch 146: Train Loss=1.4147, Train Acc=0.6181, Val Acc=0.4228, Test Acc=0.4068\n",
      "Fold 2/5, Epoch 147: Train Loss=1.4105, Train Acc=0.6221, Val Acc=0.4222, Test Acc=0.4083\n",
      "Fold 2/5, Epoch 148: Train Loss=1.4060, Train Acc=0.6228, Val Acc=0.4222, Test Acc=0.4079\n",
      "Fold 2/5, Epoch 149: Train Loss=1.4024, Train Acc=0.6241, Val Acc=0.4183, Test Acc=0.4057\n",
      "Fold 2/5, Epoch 150: Train Loss=1.3978, Train Acc=0.6227, Val Acc=0.4215, Test Acc=0.4079\n",
      "Fold 2/5, Epoch 151: Train Loss=1.3947, Train Acc=0.6269, Val Acc=0.4189, Test Acc=0.4066\n",
      "Fold 2/5, Epoch 152: Train Loss=1.3905, Train Acc=0.6265, Val Acc=0.4254, Test Acc=0.4076\n",
      "Fold 2/5, Epoch 153: Train Loss=1.3870, Train Acc=0.6284, Val Acc=0.4228, Test Acc=0.4077\n",
      "Fold 2/5, Epoch 154: Train Loss=1.3834, Train Acc=0.6291, Val Acc=0.4241, Test Acc=0.4078\n",
      "Fold 2/5, Epoch 155: Train Loss=1.3788, Train Acc=0.6294, Val Acc=0.4215, Test Acc=0.4058\n",
      "Fold 2/5, Epoch 156: Train Loss=1.3755, Train Acc=0.6312, Val Acc=0.4222, Test Acc=0.4091\n",
      "Fold 2/5, Epoch 157: Train Loss=1.3720, Train Acc=0.6313, Val Acc=0.4228, Test Acc=0.4071\n",
      "Fold 2/5, Epoch 158: Train Loss=1.3681, Train Acc=0.6348, Val Acc=0.4261, Test Acc=0.4071\n",
      "Fold 2/5, Epoch 159: Train Loss=1.3641, Train Acc=0.6342, Val Acc=0.4261, Test Acc=0.4057\n",
      "Fold 2/5, Epoch 160: Train Loss=1.3605, Train Acc=0.6375, Val Acc=0.4222, Test Acc=0.4032\n",
      "Fold 2/5, Epoch 161: Train Loss=1.3569, Train Acc=0.6370, Val Acc=0.4235, Test Acc=0.4058\n",
      "Fold 2/5, Epoch 162: Train Loss=1.3528, Train Acc=0.6393, Val Acc=0.4228, Test Acc=0.4029\n",
      "Fold 2/5, Epoch 163: Train Loss=1.3487, Train Acc=0.6360, Val Acc=0.4202, Test Acc=0.4083\n",
      "Fold 2/5, Epoch 164: Train Loss=1.3458, Train Acc=0.6422, Val Acc=0.4209, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 165: Train Loss=1.3417, Train Acc=0.6420, Val Acc=0.4241, Test Acc=0.4050\n",
      "Fold 2/5, Epoch 166: Train Loss=1.3379, Train Acc=0.6426, Val Acc=0.4242, Test Acc=0.4028\n",
      "Fold 2/5, Epoch 167: Train Loss=1.3349, Train Acc=0.6427, Val Acc=0.4235, Test Acc=0.4051\n",
      "Fold 2/5, Epoch 168: Train Loss=1.3312, Train Acc=0.6425, Val Acc=0.4228, Test Acc=0.4080\n",
      "Fold 2/5, Epoch 169: Train Loss=1.3278, Train Acc=0.6456, Val Acc=0.4222, Test Acc=0.4070\n",
      "Fold 2/5, Epoch 170: Train Loss=1.3234, Train Acc=0.6466, Val Acc=0.4255, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 171: Train Loss=1.3197, Train Acc=0.6498, Val Acc=0.4255, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 172: Train Loss=1.3165, Train Acc=0.6481, Val Acc=0.4228, Test Acc=0.4106\n",
      "Fold 2/5, Epoch 173: Train Loss=1.3132, Train Acc=0.6514, Val Acc=0.4222, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 174: Train Loss=1.3096, Train Acc=0.6478, Val Acc=0.4248, Test Acc=0.4068\n",
      "Fold 2/5, Epoch 175: Train Loss=1.3062, Train Acc=0.6508, Val Acc=0.4254, Test Acc=0.4090\n",
      "Fold 2/5, Epoch 176: Train Loss=1.3026, Train Acc=0.6554, Val Acc=0.4261, Test Acc=0.4039\n",
      "Fold 2/5, Epoch 177: Train Loss=1.2986, Train Acc=0.6571, Val Acc=0.4255, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 178: Train Loss=1.2963, Train Acc=0.6564, Val Acc=0.4261, Test Acc=0.4077\n",
      "Fold 2/5, Epoch 179: Train Loss=1.2924, Train Acc=0.6565, Val Acc=0.4255, Test Acc=0.4068\n",
      "Fold 2/5, Epoch 180: Train Loss=1.2888, Train Acc=0.6555, Val Acc=0.4281, Test Acc=0.4083\n",
      "Fold 2/5, Epoch 181: Train Loss=1.2854, Train Acc=0.6605, Val Acc=0.4222, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 182: Train Loss=1.2819, Train Acc=0.6600, Val Acc=0.4209, Test Acc=0.4058\n",
      "Fold 2/5, Epoch 183: Train Loss=1.2786, Train Acc=0.6620, Val Acc=0.4189, Test Acc=0.4023\n",
      "Fold 2/5, Epoch 184: Train Loss=1.2754, Train Acc=0.6602, Val Acc=0.4255, Test Acc=0.4075\n",
      "Fold 2/5, Epoch 185: Train Loss=1.2718, Train Acc=0.6609, Val Acc=0.4255, Test Acc=0.4082\n",
      "Fold 2/5, Epoch 186: Train Loss=1.2687, Train Acc=0.6637, Val Acc=0.4235, Test Acc=0.4067\n",
      "Fold 2/5, Epoch 187: Train Loss=1.2649, Train Acc=0.6644, Val Acc=0.4222, Test Acc=0.4073\n",
      "Fold 2/5, Epoch 188: Train Loss=1.2623, Train Acc=0.6663, Val Acc=0.4196, Test Acc=0.4063\n",
      "Fold 2/5, Epoch 189: Train Loss=1.2593, Train Acc=0.6678, Val Acc=0.4229, Test Acc=0.4072\n",
      "Fold 2/5, Epoch 190: Train Loss=1.2554, Train Acc=0.6658, Val Acc=0.4222, Test Acc=0.4107\n",
      "Fold 2/5, Epoch 191: Train Loss=1.2525, Train Acc=0.6708, Val Acc=0.4189, Test Acc=0.4075\n",
      "Fold 2/5, Epoch 192: Train Loss=1.2489, Train Acc=0.6683, Val Acc=0.4209, Test Acc=0.4083\n",
      "Fold 2/5, Epoch 193: Train Loss=1.2461, Train Acc=0.6690, Val Acc=0.4209, Test Acc=0.4068\n",
      "Fold 2/5, Epoch 194: Train Loss=1.2429, Train Acc=0.6725, Val Acc=0.4242, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 195: Train Loss=1.2389, Train Acc=0.6736, Val Acc=0.4209, Test Acc=0.4063\n",
      "Fold 2/5, Epoch 196: Train Loss=1.2364, Train Acc=0.6749, Val Acc=0.4222, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 197: Train Loss=1.2329, Train Acc=0.6735, Val Acc=0.4209, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 198: Train Loss=1.2298, Train Acc=0.6756, Val Acc=0.4183, Test Acc=0.4051\n",
      "Fold 2/5, Epoch 199: Train Loss=1.2269, Train Acc=0.6780, Val Acc=0.4190, Test Acc=0.4041\n",
      "Fold 2/5, Epoch 200: Train Loss=1.2239, Train Acc=0.6772, Val Acc=0.4189, Test Acc=0.4074\n",
      "Fold 2/5, Epoch 201: Train Loss=1.2200, Train Acc=0.6778, Val Acc=0.4203, Test Acc=0.4045\n",
      "Fold 2/5, Epoch 202: Train Loss=1.2175, Train Acc=0.6767, Val Acc=0.4170, Test Acc=0.4050\n",
      "Fold 2/5, Epoch 203: Train Loss=1.2142, Train Acc=0.6825, Val Acc=0.4170, Test Acc=0.4059\n",
      "Fold 2/5, Epoch 204: Train Loss=1.2111, Train Acc=0.6789, Val Acc=0.4170, Test Acc=0.4057\n",
      "Fold 2/5, Epoch 205: Train Loss=1.2081, Train Acc=0.6824, Val Acc=0.4150, Test Acc=0.4020\n",
      "Fold 2/5, Epoch 206: Train Loss=1.2045, Train Acc=0.6816, Val Acc=0.4222, Test Acc=0.4020\n",
      "Fold 2/5, Epoch 207: Train Loss=1.2015, Train Acc=0.6828, Val Acc=0.4170, Test Acc=0.4027\n",
      "Fold 2/5, Epoch 208: Train Loss=1.1993, Train Acc=0.6872, Val Acc=0.4195, Test Acc=0.4064\n",
      "Fold 2/5, Epoch 209: Train Loss=1.1962, Train Acc=0.6870, Val Acc=0.4150, Test Acc=0.3998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_568011/1026923569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVal_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_568011/513006242.py\u001b[0m in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(train_dataset, test_loader, k, num_epochs, batch_size, learning_rate, hidden_dim, device, shuffle)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             F.sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    145\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmaximize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "k = 5\n",
    "learning_rate = 0.1\n",
    "hidden_dim = 1024\n",
    "\n",
    "Model, Train_acc, Val_acc, Test_acc = k_fold_cross_validation(train_dataset, test_loader, k, num_epochs, batch_size, learning_rate, hidden_dim, device=device, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MoannaModel(\n",
       "   (fc1): Linear(in_features=1000, out_features=1024, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (dropout): Dropout(p=0, inplace=False)\n",
       "   (fc2): Linear(in_features=1024, out_features=33, bias=True)\n",
       " ),\n",
       " MoannaModel(\n",
       "   (fc1): Linear(in_features=1000, out_features=1024, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (dropout): Dropout(p=0, inplace=False)\n",
       "   (fc2): Linear(in_features=1024, out_features=33, bias=True)\n",
       " ),\n",
       " MoannaModel(\n",
       "   (fc1): Linear(in_features=1000, out_features=1024, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (dropout): Dropout(p=0, inplace=False)\n",
       "   (fc2): Linear(in_features=1024, out_features=33, bias=True)\n",
       " ),\n",
       " MoannaModel(\n",
       "   (fc1): Linear(in_features=1000, out_features=1024, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (dropout): Dropout(p=0, inplace=False)\n",
       "   (fc2): Linear(in_features=1024, out_features=33, bias=True)\n",
       " ),\n",
       " MoannaModel(\n",
       "   (fc1): Linear(in_features=1000, out_features=1024, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (dropout): Dropout(p=0, inplace=False)\n",
       "   (fc2): Linear(in_features=1024, out_features=33, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6626506716967243,\n",
       " 0.6604941111520058,\n",
       " 0.6615529823794627,\n",
       " 0.6649395012881855,\n",
       " 0.6593446643816709]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4417291666666667,\n",
       " 0.44380729166666666,\n",
       " 0.44641145833333334,\n",
       " 0.43004166666666666,\n",
       " 0.45952604166666666]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4059757032571912,\n",
       " 0.4191915186125212,\n",
       " 0.41896348879018613,\n",
       " 0.41932205742385786,\n",
       " 0.41997309909052455]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6618\n"
     ]
    }
   ],
   "source": [
    "TRAIN_acc = np.mean(Train_acc)\n",
    "print(f\"{TRAIN_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4443\n"
     ]
    }
   ],
   "source": [
    "VAL_acc = np.mean(Val_acc)\n",
    "print(f\"{VAL_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4167\n"
     ]
    }
   ],
   "source": [
    "TEST_acc = np.mean(Test_acc)\n",
    "print(f\"{TEST_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            test_acc += accuracy_score(torch.argmax(outputs, dim=1).cpu(), labels.cpu())\n",
    "\n",
    "        test_acc /= len(test_loader)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4060\n",
      "Test Accuracy: 0.4192\n",
      "Test Accuracy: 0.4190\n",
      "Test Accuracy: 0.4193\n",
      "Test Accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    test_model(Model[i], test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27, 13, 18, 19,  7,  1,  6, 27, 27,  4, 27, 13,  0,  4,  8, 19, 29, 13,\n",
      "         1, 21,  4, 27,  1, 10,  4, 14,  1, 18, 18, 18, 27,  8, 24, 21, 21,  1,\n",
      "        15, 24, 15,  0,  4,  4, 27,  4,  1, 21, 13, 27,  0, 27, 18, 29, 15, 27,\n",
      "        29, 27, 23, 25, 29, 29, 27,  7, 27, 27, 15, 25, 27,  7,  8, 14,  1, 14,\n",
      "        27, 27, 14, 27, 16, 14, 27, 27,  0,  8, 14, 27,  2, 21, 25, 24, 16, 13,\n",
      "        25, 16,  4, 19,  2,  7,  1, 16, 22,  8,  0, 27,  1, 27, 27,  1, 10, 27,\n",
      "        18, 27, 18,  1, 27, 27, 27,  4,  1,  4,  8, 27, 21, 29, 14, 18,  4, 16,\n",
      "        15, 15, 25, 27,  7,  7, 27,  1, 15, 13,  1,  8,  1,  1,  4,  1, 27, 27,\n",
      "        10, 24, 21,  2,  1, 15,  1,  8, 27, 19, 27, 14, 27,  7, 15,  1, 18, 16,\n",
      "        29, 24, 27, 14,  0, 25, 11,  1,  2,  1,  1,  6,  1,  1, 25, 15,  0, 21,\n",
      "        24,  4,  1, 29,  1,  0, 14, 15, 24, 25, 24,  2, 10, 25, 27, 29,  1,  1,\n",
      "         1, 27, 27, 19,  4, 18, 14,  8,  1, 10, 24, 29,  0, 25, 29, 15,  1, 24,\n",
      "        18, 16,  2,  2, 13, 15, 13, 16, 27,  8, 24,  4,  0, 29, 27,  2, 13, 14,\n",
      "         1, 27,  4, 24, 27,  2,  3,  1, 16, 15,  6, 27,  1,  7, 10,  4,  1, 15,\n",
      "         1, 14, 29,  4], device='cuda:0')\n",
      "tensor([ 7, 13,  1, 19,  7,  1,  6, 26, 21,  4, 20, 13,  0,  4,  8, 22, 30, 13,\n",
      "         1, 21,  4, 27,  1, 10,  4, 14,  1, 25, 16, 10, 22,  8, 24, 21, 21, 20,\n",
      "        15, 24, 15,  0, 22,  1, 21,  4,  1, 17, 13, 17,  0, 28, 18, 29, 15, 26,\n",
      "        29, 23, 23, 25, 29, 29, 25,  7, 27, 23, 15, 18, 27,  7, 16, 25,  1,  8,\n",
      "        14, 27, 14, 21, 16, 14, 27, 27,  0,  8, 14, 23,  2, 21, 25, 24, 16, 13,\n",
      "        25, 16,  4, 19,  2, 13,  1, 16, 18,  1,  0, 28,  1, 12, 27, 23,  0, 27,\n",
      "        18, 28,  6, 11, 26, 20, 28,  4,  1,  4,  8, 24, 23, 29, 14, 18,  4, 16,\n",
      "        15, 15, 18, 27,  7,  7, 20, 18,  7, 13, 13,  8,  1,  1,  4,  1, 31,  1,\n",
      "        11, 24, 10,  2,  1, 15, 18,  8, 20, 15,  9, 14, 31, 15, 15, 29,  1, 16,\n",
      "        29, 24, 17,  4,  0,  4, 14, 29,  2,  1,  0,  6,  1,  1,  5, 15,  0,  1,\n",
      "        24,  4,  1, 29, 18, 14, 14, 15, 24,  8, 24,  2, 10, 25, 23,  4,  1,  1,\n",
      "        23, 21, 28, 19,  4, 18,  8,  8, 21, 10, 24, 29,  0, 25, 29, 15, 18, 24,\n",
      "        18, 16,  2,  2, 13, 15, 13, 14,  8,  8, 24,  4,  0, 29, 21,  1,  7, 14,\n",
      "        10, 27,  4, 24, 27, 11,  3,  3, 16, 15,  6, 20, 14,  7,  2,  4,  2, 15,\n",
      "         1, 14, 29, 22], device='cuda:0')\n",
      "tensor([18, 29,  8,  8,  4, 18, 19, 13,  7, 10, 29, 18, 27,  8,  4,  1, 27,  1,\n",
      "        27, 24, 27, 27,  7, 13, 27, 27,  0,  1,  7, 29,  7,  6, 29, 14, 16, 21,\n",
      "        15, 25, 15,  1, 10, 29, 18, 27,  7,  7, 18,  1,  0, 18, 19,  2, 27, 18,\n",
      "        15, 16,  1,  1,  7,  0,  0,  1, 27, 13, 25, 27, 16,  0, 13,  2,  1, 19,\n",
      "         4, 13, 27, 21,  8, 25, 15,  1, 24,  2, 15,  1, 14, 15, 21, 21, 27, 29,\n",
      "        18, 27,  1,  1, 18, 23, 15, 10, 16, 23, 21,  8, 21,  8,  1, 27, 29, 25,\n",
      "        27, 29,  0, 16, 14,  8, 25, 14,  1, 19,  0, 14, 15, 21, 15, 16, 27,  7,\n",
      "        27, 21, 13, 27, 13, 21,  4, 23, 10,  0,  1,  7,  1, 11,  4, 27, 16,  1,\n",
      "        25, 18, 27,  1,  8,  0, 24,  1, 18, 18,  4, 25, 24, 18, 24, 15, 25, 25,\n",
      "        27, 16, 25, 27,  8,  1, 25, 16, 14, 10, 24, 13,  1, 25, 13,  8, 19, 27,\n",
      "         4, 29, 24, 18,  0,  1, 18, 16, 13,  8,  7, 13, 24,  1,  0, 14, 13, 25,\n",
      "         2, 19,  8, 14, 14, 15, 27, 21,  7, 29, 27,  1,  8, 15, 14,  2, 21, 18,\n",
      "         1,  1, 15,  7, 15, 27, 24, 15,  2, 25, 27, 18, 14, 13,  1, 25, 10,  7,\n",
      "         4,  1, 27, 21, 27, 15, 27,  7, 10,  7, 16, 13, 29,  7, 19, 27, 19,  7,\n",
      "         4, 10, 18, 25], device='cuda:0')\n",
      "tensor([23, 15,  8,  8,  4, 14, 19, 13, 10, 10, 29, 18,  9,  8,  4, 21, 27,  1,\n",
      "        27, 24, 27, 10,  7, 13, 28, 32,  0,  1,  7, 29,  0,  6, 29, 14, 16, 21,\n",
      "        13, 25,  1,  1,  8, 21, 18, 10,  6,  7, 18, 10,  0,  6, 15,  2, 31, 18,\n",
      "        29, 16,  1,  2, 32,  0,  0,  1, 17, 21, 25, 27, 16,  0, 13,  5,  7, 12,\n",
      "         4, 13, 26, 21,  7, 25, 19,  1, 24, 11, 14,  1, 14, 15, 21, 22, 15, 29,\n",
      "        29, 32,  1,  1, 18, 23, 15, 11, 16, 23, 32,  8, 10,  8,  1, 21, 29, 25,\n",
      "        27, 14,  8, 16, 14,  8, 25, 14, 25, 19,  0, 14, 15, 26, 15, 16, 27,  7,\n",
      "        26, 28, 13,  1, 20, 25,  4, 23, 10,  2,  1, 13,  1, 11,  4, 31, 16,  1,\n",
      "        25, 18, 19, 16,  2,  0, 24,  1,  7, 18, 15,  6, 24, 21, 24, 15,  6, 25,\n",
      "         9, 16, 25, 12,  8,  1, 25,  8, 14, 21, 24, 13,  1, 25, 13,  8, 19, 27,\n",
      "         4, 29,  7, 23,  0,  1,  8, 16, 13,  8,  7, 13, 24,  0,  0, 14, 13, 25,\n",
      "         2, 19, 15, 32, 14, 15, 28, 26,  8, 29, 27, 18, 16, 15, 23,  2, 24, 18,\n",
      "         9, 21, 15,  7, 15, 27, 24, 16, 29,  0, 27,  8,  9, 13,  1, 25, 10,  7,\n",
      "        25, 32, 27, 21, 23, 15,  8,  7, 23, 13, 16, 13, 30,  7, 19, 27, 19,  7,\n",
      "        22, 10, 18,  0], device='cuda:0')\n",
      "tensor([27,  1, 13, 18, 29,  7,  1, 29,  1,  1,  6, 14,  6, 14, 25,  1, 29, 27,\n",
      "         1, 29,  7, 27,  0, 15, 13, 27,  4, 21, 25, 13, 23, 27, 15, 27, 27,  7,\n",
      "        18,  7, 13, 18, 13, 27, 27,  8, 16, 15,  8, 29, 19,  1, 10,  7, 18, 27,\n",
      "        18,  4, 15, 16,  4, 13, 27,  1,  7,  8, 21, 27, 29, 18,  7,  1, 22, 25,\n",
      "        24, 19,  6, 24, 27, 18, 21,  0,  1, 16, 29,  1, 27,  7,  1, 15,  8,  1,\n",
      "        16, 10, 27, 27, 16, 13, 19, 14,  1, 29,  2, 13,  1, 14,  4, 21, 16, 18,\n",
      "        18,  1,  4, 24, 29, 21,  1, 19,  0,  8, 19, 29, 13, 18,  1,  1, 10, 27,\n",
      "         8,  8, 18, 18, 18,  4,  4,  8, 18,  8, 27, 15, 29, 15, 27,  0, 21, 10,\n",
      "         8,  7,  8,  1,  1,  7,  0, 24, 29, 27, 29, 10,  7, 27, 16, 15,  4, 27,\n",
      "         8,  1,  7,  1,  1, 25, 16,  1, 27, 27, 16, 29,  1, 24, 16, 16, 18, 13,\n",
      "         0, 15,  1, 13,  1,  8, 27, 13, 16, 27,  1, 13, 27,  0, 21,  0, 15,  1,\n",
      "        29, 27,  7, 24,  7, 18,  8, 27, 21, 27, 16,  1, 15,  1, 14,  1,  8,  0,\n",
      "        29, 13, 16,  6, 13, 21, 10, 18, 27,  4, 14,  8, 27, 25,  1,  1, 21, 29,\n",
      "        15, 29,  0, 25, 29, 14,  7, 27,  4, 16,  1,  4, 27,  0, 16,  1, 27,  7,\n",
      "         8, 25,  0,  8], device='cuda:0')\n",
      "tensor([21, 27,  7, 29, 29, 15, 25, 29,  1, 23,  6, 21,  6,  4,  0, 16, 29, 20,\n",
      "         1,  2, 25, 27,  0, 15, 13, 21,  4,  0, 25, 13,  7, 21, 15, 21, 27,  0,\n",
      "        18,  1, 13, 29, 13,  3, 21,  8, 16, 15,  8, 29, 19,  9, 10,  7,  1, 22,\n",
      "        14,  4, 18, 16, 21, 13,  9,  1,  7,  8, 21,  4, 29,  1,  1,  1, 22, 25,\n",
      "        24, 19,  6, 24, 27, 18, 21,  0,  1, 16, 29,  1, 20, 15,  1, 15,  8,  1,\n",
      "        16, 11, 26, 27, 16, 13, 19,  8, 11, 29,  2, 13,  1, 14, 22, 18, 16, 18,\n",
      "         1,  1,  4, 24, 29, 26,  1,  2,  0,  8, 19, 30, 13, 10,  1, 14,  8, 27,\n",
      "         8,  8, 19, 18, 18,  4, 22,  1, 21,  5,  9, 15, 29, 15,  9,  0, 14, 10,\n",
      "        19,  2,  8, 18, 11,  7,  8, 24, 29, 32, 29, 10, 23, 17, 16, 16,  4,  1,\n",
      "        29, 14, 24,  1,  1,  1, 16, 10,  1,  1, 24, 29,  1, 24, 16, 16, 18, 13,\n",
      "        16, 15,  1, 13, 26,  8, 21, 13, 16, 28,  8,  7, 13,  0, 26, 32, 16, 11,\n",
      "        30, 20,  9, 24, 13,  8,  8, 27, 21, 26, 16,  2, 15,  1, 14, 13, 18,  0,\n",
      "        29, 13, 16,  6, 13, 18, 23, 12, 27,  4, 14,  8, 23, 25, 11, 13, 11, 29,\n",
      "        15,  1,  0, 25, 29, 25, 23,  1,  4, 16, 14,  4, 11,  0, 16,  1, 20, 32,\n",
      "         8,  0, 14,  2], device='cuda:0')\n",
      "tensor([ 1, 22, 29, 15, 13,  1, 25, 29, 21,  1, 10,  4,  8,  4,  0, 24, 19, 29,\n",
      "        27, 15,  1, 27, 29,  1, 27, 27,  1, 13, 15,  2,  4, 21, 15, 13, 10,  1,\n",
      "        29,  8, 27, 13, 18,  1, 24,  1, 21, 16, 27, 21, 15,  8, 14,  7,  1,  0,\n",
      "        16,  1,  8, 13, 29,  4,  4, 15,  0, 13,  1, 15, 10, 16, 15, 21,  1, 18,\n",
      "        15,  1,  8, 18,  1,  8,  7,  1, 27,  1, 14,  6, 29,  1, 13,  0, 27, 27,\n",
      "         1, 15,  0, 21, 27, 14,  4, 27,  1,  7, 10, 21, 25,  1,  1, 18, 27,  8,\n",
      "        18, 25, 27, 10, 24,  7,  0,  7, 24, 27, 21, 14,  4, 10, 21, 15, 10, 18,\n",
      "        16, 13, 18, 14,  1, 14, 13, 14,  1,  2, 25,  8,  1,  1, 29,  1, 27, 19,\n",
      "        27, 25, 21,  1, 25, 13, 13,  1, 29, 13, 15, 27,  4, 10, 18, 27, 15,  1,\n",
      "        27, 18,  1,  0, 24, 25, 27,  4,  1, 21, 29,  4, 15, 15,  1, 13, 18, 21,\n",
      "        27,  1, 27, 27, 14,  7, 27, 27, 29, 29, 16,  4,  8,  1,  4, 27, 24, 18,\n",
      "         1, 16, 19, 14, 27, 29, 15, 29,  1,  1, 16,  1, 27, 10, 10, 18, 15,  1,\n",
      "        27,  8,  1, 24,  1,  8,  7, 27, 24,  1, 21, 16, 16, 16, 25,  0,  7, 10,\n",
      "         1, 27,  1, 10, 21, 25, 21, 18,  1, 18,  1, 13, 27,  1,  8, 16,  8,  7,\n",
      "        24,  1, 14, 24], device='cuda:0')\n",
      "tensor([ 1, 22, 29, 15, 13,  1, 25, 29, 23, 21, 10,  4, 16,  4,  0, 24, 19, 29,\n",
      "        20, 15,  1, 27, 29,  1, 27, 27, 18, 13, 15, 15,  4, 21, 15, 13, 10, 21,\n",
      "        29, 18, 27, 13, 17, 11, 24, 17, 21, 15, 25, 17, 15,  8, 14,  7,  3,  0,\n",
      "        16,  3,  8, 13, 29,  4,  4, 15,  0, 13,  1, 15, 14, 16, 15, 21, 25, 18,\n",
      "        15,  1,  8,  4, 21,  8,  7,  1, 20,  1, 14,  6, 29,  1, 13,  0, 17, 28,\n",
      "         1, 16,  0, 21, 12, 25,  4, 10, 11,  7, 10, 13, 25,  8, 15,  6, 21,  8,\n",
      "        18, 25, 31, 25, 24,  7,  0,  7, 24, 21, 14, 32,  4, 24, 20, 15,  7,  7,\n",
      "         0, 14, 18, 14, 10, 14, 13, 14,  1,  2, 25, 13,  1, 18, 29,  1, 27, 19,\n",
      "        27, 25, 11,  7, 25,  6, 13,  1, 29, 13, 15,  4,  4, 11, 18, 17, 15,  2,\n",
      "        20, 18, 13,  4, 24, 25, 23, 22,  1, 21, 30,  4, 15, 15, 28, 13, 18,  8,\n",
      "        20,  1, 21,  1, 14, 21, 21, 20, 29, 29, 16,  4,  8,  2,  4, 11, 24, 27,\n",
      "         7, 16, 19, 14,  9,  6, 15, 29,  6,  7, 16, 11, 27, 10, 24, 23, 15, 14,\n",
      "        26,  8,  1, 24,  8,  5,  7, 20, 24,  1,  0, 15, 16, 16, 25,  0,  7, 10,\n",
      "         1, 28,  1, 10, 19, 25,  5, 18,  1, 18,  1, 13,  9,  1,  5, 16,  8,  7,\n",
      "        24,  1, 11, 24], device='cuda:0')\n",
      "tensor([29, 27, 24, 27, 27,  8,  1, 18,  0, 27, 21, 19,  0, 21,  1,  4, 16,  1,\n",
      "        18,  7,  2, 24, 14, 27, 27,  2, 16,  1, 10,  4, 25, 18,  1, 19, 24, 27,\n",
      "         4, 10, 18,  1, 29,  1,  7, 27, 29, 27, 21, 29, 29, 18, 25, 25,  7, 29,\n",
      "        24,  7,  4, 25, 29, 27,  4, 27, 27, 24, 21, 27, 15,  6, 21, 18, 16, 18,\n",
      "        18, 15, 14,  1, 29,  0,  4, 13,  7,  1,  4, 27, 14, 24,  1, 27, 16, 18,\n",
      "        24,  2, 27,  1, 16, 16, 14,  7, 16, 29, 27, 11, 14, 18,  1, 19,  6, 13,\n",
      "        21, 25,  7,  2, 18, 16,  1, 27, 16, 19, 15, 21, 13, 13, 27,  1, 21, 27,\n",
      "        29, 18, 18, 21,  4, 21, 16, 24,  0,  1, 21,  4, 27, 18, 11, 10,  1, 27,\n",
      "         1, 27, 15, 21, 25, 11,  8, 27, 27,  7, 14, 15, 14,  8, 21,  0, 21,  4,\n",
      "         1,  6, 16,  7,  1, 14, 27,  7, 21, 24, 15, 16, 27, 10, 21, 21,  2, 10,\n",
      "        15, 25,  1,  1, 24,  0, 19,  7, 21, 27, 25,  7, 10, 13, 24, 29, 10,  0,\n",
      "        10, 21, 29, 27, 27, 11, 27, 14, 18,  7,  0,  1, 29, 27, 27,  1, 27, 13,\n",
      "        27,  1, 25, 21, 21, 10, 14,  1,  1,  1,  4, 27, 29, 24, 27, 18,  0,  1,\n",
      "        25,  1,  1,  4,  2,  2, 13,  4, 13, 10, 18, 16, 27,  1, 29, 21, 19, 22,\n",
      "         2,  8,  1, 16], device='cuda:0')\n",
      "tensor([29, 21, 24, 27, 27,  8,  1,  1,  0,  1, 21, 19,  0, 26,  1,  4, 16,  1,\n",
      "        18, 13,  2, 24, 14, 10, 11, 11, 16, 29, 20,  4, 25,  1,  1, 19, 24, 19,\n",
      "         4, 24, 19,  7,  2, 11, 15, 20, 29, 27, 23, 29, 29, 27, 25, 25,  7, 29,\n",
      "        24, 13,  4, 25, 29, 27, 22, 20, 27, 24, 21,  1, 15,  6, 24, 18, 16, 28,\n",
      "        18, 15, 14,  1, 29,  0, 22, 13,  7,  1,  4, 31, 14, 24, 14,  0,  0, 25,\n",
      "        24,  2, 31, 27, 16, 16, 14,  7,  8,  1, 21, 11, 14, 18,  1, 22,  6, 13,\n",
      "        25, 25,  7,  2,  1, 16,  1, 27, 16, 19, 15, 18, 13, 13, 27,  0, 23, 28,\n",
      "        29, 23, 18, 15,  2,  7, 16, 24,  0,  1, 10,  4, 27, 23, 11, 11,  1,  4,\n",
      "         1, 27, 15, 14, 25,  2,  8, 20, 28,  7, 14, 15, 24,  8, 21,  0, 31,  4,\n",
      "         8,  6, 16,  7,  1, 14, 27,  7, 21, 16,  1, 16, 26, 10, 17,  1, 11, 10,\n",
      "        15, 25,  7,  1, 24,  0, 19, 24, 20, 27,  0,  7, 11, 13, 24, 29, 10,  0,\n",
      "        10, 23, 29, 28, 21, 11, 24, 32, 18,  7,  0,  1, 29, 28, 27, 23, 20, 13,\n",
      "        32, 18, 25, 12, 23, 10, 14,  1,  1, 11,  4, 27, 29, 24, 27, 18,  0,  1,\n",
      "        25, 14,  1, 23,  2,  2, 13, 15, 13, 10, 18, 16,  1,  1, 29,  4, 19, 22,\n",
      "        29,  6,  1, 15], device='cuda:0')\n",
      "tensor([10,  8,  1, 27, 24, 10, 21, 15,  1, 15,  1, 15, 14,  0, 27, 15, 10, 13,\n",
      "         7, 21, 15,  8,  2,  4, 13,  1, 27, 29, 29, 18, 21, 11, 24, 27, 11,  1,\n",
      "         7, 19, 19, 27, 14, 10, 21,  3, 18, 15, 13, 15,  1, 15,  1, 21,  2,  8,\n",
      "        10, 18, 24, 27, 29,  1,  8,  1, 27, 13,  1,  4, 15, 16, 21,  1, 29,  6,\n",
      "        15,  1, 10, 24,  0,  1, 10, 13, 24, 27, 19, 10,  8, 14, 24, 21, 13,  2,\n",
      "         4, 16, 10, 13, 27,  8,  1,  1,  4, 19,  0,  2, 13, 21,  8, 14,  1, 25,\n",
      "        29, 13,  1, 29,  6, 18, 29, 10, 27, 10, 10,  7,  2, 27,  1, 27,  4, 21,\n",
      "        27,  4,  1, 14, 10,  1, 27, 15, 29, 18,  6, 27, 27,  8, 11, 25, 24, 19,\n",
      "         2,  1, 14, 16, 24,  1, 16,  0, 29, 21, 21, 13, 27, 16, 25,  1, 18, 27,\n",
      "        14, 13, 16, 24,  0,  4,  1,  8, 13, 14,  0,  1, 25, 24, 27, 21, 18, 27,\n",
      "        29,  2, 27, 27, 27, 29,  1,  4, 21, 21,  2,  8, 24, 15, 27, 27,  7,  1,\n",
      "         1, 24,  1, 27,  7, 13, 24,  0, 21, 13, 21, 15, 27, 25,  1, 15, 29,  8,\n",
      "        27, 25, 18, 15, 21, 29, 18,  1,  7, 14, 10, 21,  4, 21, 27, 24,  1, 21,\n",
      "        15, 16, 29,  0, 10,  4, 10,  1, 21,  8, 10,  1,  1, 16,  1, 21, 29, 27,\n",
      "        29, 27, 27, 15], device='cuda:0')\n",
      "tensor([10,  8,  1, 22, 24, 10, 15, 15,  1, 15,  1, 15, 14,  0, 15, 15, 10, 13,\n",
      "         7, 21, 15,  8,  2,  4, 13, 23, 27, 29, 29, 18, 21, 11, 24, 27, 11,  1,\n",
      "         7, 19, 28, 27,  0, 10, 18,  3, 30, 15, 13,  7, 24, 15,  1, 21,  8,  8,\n",
      "        11, 23, 24, 20, 30,  2,  8, 11,  3, 13,  2,  4, 15, 16, 19,  1, 29,  6,\n",
      "         5,  1, 10, 24,  0,  1, 17, 13, 24, 21, 19,  1, 23, 25, 24,  1, 13,  2,\n",
      "         4, 16, 10, 23, 27,  8, 21, 15,  4, 19,  0,  2, 13, 19,  8, 14,  1, 25,\n",
      "        29, 13,  1, 29,  6, 18, 29, 15,  1, 10, 25,  7,  2, 27,  1,  7,  4,  1,\n",
      "         9,  4,  1, 32, 11,  1, 20, 15, 29, 18,  6, 25, 21,  8, 11, 25, 24, 15,\n",
      "        21,  1, 32, 16, 24,  1, 16,  0, 29,  8,  7, 13, 20, 16, 25,  1, 17,  9,\n",
      "        14,  3, 15, 24,  0,  4,  1,  8, 13, 25,  5, 11, 25, 24, 27, 21, 23, 27,\n",
      "        29,  2, 20, 12, 31, 29,  1, 29, 14, 11,  2, 25, 24, 15, 20, 26,  7,  2,\n",
      "        27, 24,  1, 20, 23, 13, 24,  0, 21, 13, 13, 15, 27, 25,  1, 24, 29,  8,\n",
      "         9, 25, 18, 15, 26, 30, 21,  1,  7, 14, 10,  0,  4, 27,  1, 24,  1, 26,\n",
      "        15, 16, 29,  0,  2,  4, 10, 26, 21,  0, 11, 11,  1, 16, 11, 21, 29, 27,\n",
      "        29, 27, 23, 15], device='cuda:0')\n",
      "tensor([15,  4,  1, 18, 27, 25, 10,  1,  4, 29, 16,  4,  1, 27, 18, 16, 21, 10,\n",
      "         2,  7, 24, 16, 24,  1, 16, 27, 29, 15, 18, 15,  1, 24, 29,  1, 16, 25,\n",
      "         1,  1, 18, 29,  8,  8, 29,  0,  1, 21,  2,  0, 16, 24, 27, 10,  4,  1,\n",
      "         1, 29, 27, 27, 25,  1,  1, 29, 19, 21,  7, 15,  4,  4, 10, 21,  4,  1,\n",
      "        14, 27, 15, 16, 27, 24, 10, 16, 27, 25, 27, 18, 15,  0, 29,  1, 27, 13,\n",
      "         1, 18, 15,  1,  1, 10, 10,  2, 27, 27, 18, 25,  1,  1, 27,  8, 21, 24,\n",
      "        16,  1,  1,  7, 24, 27,  8, 10, 18,  1,  6, 13, 27,  0,  1, 25,  1,  4,\n",
      "        15, 16, 21, 15, 29,  0, 18, 29, 25,  1,  1, 24, 25,  2,  1,  4, 16,  7,\n",
      "        10, 29, 27, 19, 25,  1,  1,  1, 10, 10, 16, 21, 27,  4,  1, 21, 27, 13,\n",
      "         1, 24,  0,  0, 27, 27, 24,  4, 29, 27, 27, 13, 21, 13,  1, 21, 13, 15,\n",
      "         1, 24, 16, 27,  1,  1, 15, 10,  7,  1, 16,  8,  1, 29, 16, 18,  1, 29,\n",
      "        27,  7, 27, 10, 23, 15, 27, 25, 13,  4, 14,  7, 29, 24,  8, 14, 13, 10,\n",
      "        29, 15,  8, 27, 14,  1, 14,  1, 21, 24,  0,  4, 27,  1, 25,  1, 27, 27,\n",
      "        10, 10, 11, 21,  1, 24, 15,  6, 27,  7, 14,  2,  8,  1, 25, 18,  1,  1,\n",
      "         1,  6, 14, 27], device='cuda:0')\n",
      "tensor([15, 22,  1, 29, 26, 25, 29,  1,  4, 29, 16,  4,  1, 28, 18, 16, 21, 26,\n",
      "         2,  7, 24, 16, 24,  1, 16, 31, 29, 15, 18, 15,  1, 24, 29,  8, 16, 25,\n",
      "        23,  1,  8, 29,  8,  8, 29,  0, 14, 21,  2,  0, 16, 24, 27,  8,  4,  6,\n",
      "         1, 29, 31, 27,  2,  1, 25, 29, 19, 21,  7, 15,  4,  4, 10,  2, 22,  4,\n",
      "        14, 27, 15, 16,  1, 24, 10, 16, 21, 25, 27, 18, 15,  0, 29,  1, 12, 13,\n",
      "        21, 29, 15,  2,  1, 10, 10,  5, 20, 21,  1, 25, 29, 21, 21,  8, 14, 24,\n",
      "        16,  1, 18,  7, 24, 31,  8, 10, 18,  1,  6, 13, 28,  0,  1, 25,  1,  4,\n",
      "         4,  1,  2, 15, 29,  0,  1, 29, 25, 18, 32, 24, 25, 15,  1,  4, 16,  7,\n",
      "        31, 29, 27, 19, 25,  1, 11, 27, 10, 11, 16, 24, 23,  4,  1,  2, 12, 13,\n",
      "         1, 24,  0,  0, 21, 32, 24,  4, 29, 27, 21, 13, 17, 13,  1, 21, 13, 14,\n",
      "         1, 15, 16, 21, 21,  1, 15, 10, 14,  1, 16,  8,  1, 29, 16, 18,  1, 29,\n",
      "        28, 21, 20, 10, 23, 15,  1, 25, 13,  4, 14,  7, 29, 24,  8, 14, 13, 10,\n",
      "        29, 14,  8, 27, 14, 11, 14,  1, 22, 24,  0, 14,  3,  1, 25,  9, 21, 12,\n",
      "        10, 17,  1, 21,  2, 24, 15,  6, 11, 15, 14,  2,  8,  0, 25, 18,  1,  1,\n",
      "         1, 25, 14, 31], device='cuda:0')\n",
      "tensor([ 1,  1,  2,  1,  4, 13, 18, 25, 21, 24,  7, 27, 14, 27, 10,  1, 27, 18,\n",
      "         0, 18, 16, 13,  2, 29,  0, 27, 15, 15, 16,  4,  1, 15, 27, 21,  1, 22,\n",
      "        25,  1,  8, 21, 15, 13, 21, 24, 14, 27, 27, 24, 10, 27,  7,  1,  4, 27,\n",
      "         0, 18, 25,  1, 29, 19, 16, 27, 21, 27, 24, 22, 18, 15,  2,  4, 18, 21,\n",
      "        19,  0, 24, 25,  8,  4,  0, 13, 29, 29, 16, 19, 22, 27, 21,  4, 24,  1,\n",
      "         0, 27, 21,  1,  8, 24, 27,  2,  7, 16, 15, 21, 27, 25, 14, 15, 21,  2,\n",
      "        27, 18, 21, 27, 21,  1, 27, 27, 18, 27, 21,  1, 18,  1, 18,  7, 27, 19,\n",
      "        21, 27, 27,  4, 15, 24, 24, 15,  0,  0, 27,  4, 19, 15, 27, 24, 25, 14,\n",
      "        27, 27, 18, 10, 24, 16,  8,  1, 21, 14, 10, 29,  1, 29,  1, 24,  1,  1,\n",
      "         4, 27,  1,  8, 29, 24, 15, 16, 27, 27, 25, 13, 27, 10, 13,  1, 27,  4,\n",
      "        18,  1, 18,  1, 14,  1, 19, 13, 22, 27,  1,  4, 19,  1, 13, 19,  1, 13,\n",
      "        22,  1, 13,  1,  1, 13, 27,  7,  1,  8, 22,  2,  1,  1, 27, 24,  1,  1,\n",
      "         1, 18,  1, 21,  0, 13, 24, 21, 29, 27,  6, 27,  1,  4,  4, 21,  1,  1,\n",
      "        18,  1, 10, 10,  7,  1,  1,  8, 16, 29,  8, 27, 23, 11, 14, 10,  1, 21,\n",
      "         4, 22, 16, 18], device='cuda:0')\n",
      "tensor([ 2,  1, 29,  7,  4, 13,  6, 25, 10, 24,  7, 20, 14, 17, 11, 25,  1, 17,\n",
      "         2, 12, 16, 13,  2, 29,  0, 27, 15, 15, 16,  4,  1, 15,  9, 15,  1, 22,\n",
      "        25,  1,  8,  7, 15, 13, 26, 24, 14, 28, 27, 24, 10, 27,  7,  3,  4, 21,\n",
      "         0,  1, 25,  1, 29, 19, 16, 23, 23, 31, 24, 22, 27, 15,  2, 23, 13, 21,\n",
      "        19,  0, 24,  7,  8,  4,  0, 13, 29, 29, 16, 19, 22, 11, 21, 22, 24,  1,\n",
      "         0, 26, 21,  1,  8, 24, 11,  2,  7, 16, 15, 10, 26, 25, 14, 15, 16,  2,\n",
      "        27, 25, 22,  7, 27,  7, 31, 27,  8, 28, 21,  1,  6,  1, 18,  7, 26, 19,\n",
      "        27, 27,  8,  4,  8, 24, 24, 16,  0,  0,  7,  4, 12, 15,  0, 24, 25, 14,\n",
      "        26, 18,  6,  7, 18, 16,  0,  9, 21, 14, 14,  7,  7, 29,  8, 24, 18,  1,\n",
      "        22, 10,  1,  8, 29, 24, 15,  1, 21, 27,  0, 21, 27, 10, 13, 23, 27, 22,\n",
      "        32,  1,  8, 18, 14,  1, 19, 13, 22, 27, 11,  4, 19,  1, 13, 12, 15, 13,\n",
      "        22,  1, 13,  1, 18,  7, 27,  7, 25, 14, 22,  4,  1, 19, 11, 24,  0, 21,\n",
      "         1, 18,  1, 23,  0, 13, 24,  7, 29, 28,  6, 31,  1, 22,  4, 21, 11,  1,\n",
      "        21, 11, 17, 23,  7,  1,  1,  8, 16, 29,  8, 27, 23, 11, 23, 10,  3, 10,\n",
      "         4, 22, 16, 18], device='cuda:0')\n",
      "tensor([21, 21, 27, 18, 21, 21, 22,  1, 16, 10, 16, 27, 27, 16, 24, 13, 24,  7,\n",
      "        25, 21,  0,  7, 19,  8,  4,  1, 29, 27, 19, 27, 25,  0, 13, 27, 27, 10,\n",
      "         1,  1, 18, 25,  8, 10,  4, 18,  1, 18, 15, 29, 19,  0,  1, 27,  0, 14,\n",
      "        27, 21, 24, 10,  2, 24, 24, 16, 13, 29, 27, 13,  0,  4,  8, 24, 15, 21,\n",
      "         1,  1,  1,  1,  7,  1, 21, 16, 27, 22, 25,  1,  1, 24, 27, 24, 24, 15,\n",
      "         1, 18, 18,  0,  8, 27, 14, 24, 18, 10,  4, 27, 18, 24, 18,  1, 15,  8,\n",
      "        25, 10, 18, 15,  1, 13,  0, 25, 13,  4, 16, 27,  1, 27,  7, 19, 25, 27,\n",
      "         8, 24, 18,  1,  6,  1,  1,  8, 19, 18, 25, 13, 27, 10, 25, 21,  4, 27,\n",
      "         1,  1, 25, 27, 13, 21,  7, 27,  4, 29, 14, 14,  4, 29,  8, 15, 10, 25,\n",
      "         8, 18,  1, 21, 21, 16,  1,  1,  8, 19,  1, 13, 27, 18, 29, 27, 27,  1,\n",
      "         8, 29,  8, 25, 27,  0,  1,  1, 16,  4,  1, 27, 23,  4, 15,  4, 29,  4,\n",
      "         1, 27, 25, 29, 11, 25, 27, 18, 29, 10,  1, 27, 16,  4, 18, 21,  1, 24,\n",
      "        18,  2,  1,  1, 14, 21, 18, 29, 19, 27, 27, 27, 13, 14, 16,  1, 27,  6,\n",
      "         2, 24, 16, 27, 27,  1, 27, 21, 27, 24, 24, 25, 27,  0, 21, 27, 18, 13,\n",
      "         8,  4, 27, 24], device='cuda:0')\n",
      "tensor([16, 21, 20, 18, 21, 23, 22,  3,  8, 11, 16, 23, 20,  8, 24, 13, 24,  7,\n",
      "        25, 26,  0,  7, 29,  8,  4,  1, 29,  1, 19, 32, 24,  0, 13,  9, 27, 10,\n",
      "         1,  1,  6, 25,  8, 10,  4,  8, 29, 18, 15, 29, 19,  0,  0, 21, 14, 14,\n",
      "        21, 26, 24, 10,  2, 24, 24, 16, 13, 30, 21, 13,  0,  4,  8, 24, 15, 21,\n",
      "         1, 17,  1, 18, 13,  1, 23, 16, 27, 22,  0,  2,  1, 24,  9, 24, 24, 15,\n",
      "        21, 18,  1,  0,  8, 21, 14, 24, 15, 10, 22, 26, 18, 24, 18, 21, 15,  8,\n",
      "         0,  2,  8, 15,  1, 13,  0, 25, 13, 21, 16, 29, 14, 27,  7, 15, 25, 27,\n",
      "         8, 23, 30, 17,  6, 14, 28,  8, 14, 19, 25,  7, 19,  2, 25,  1,  6, 27,\n",
      "        10,  7, 25, 28, 13, 15,  7, 20,  4, 30, 14,  3,  4, 29, 16, 15, 10, 25,\n",
      "         8, 18,  8, 21, 21, 16,  2,  1,  8, 26, 18, 13, 20, 18, 29, 23, 13, 19,\n",
      "         8, 10,  8,  8, 21,  0,  1,  6, 16,  4, 14, 21, 23,  4,  1,  4, 29,  5,\n",
      "        18, 27, 25, 29, 10, 25, 31,  7, 21, 10,  2,  1, 16, 22, 18, 21,  1, 24,\n",
      "         1,  2, 21,  7, 14, 27, 18, 29, 19, 20, 27, 27, 13, 14, 16, 11, 25,  6,\n",
      "        23, 24, 16,  4, 13,  1, 12,  7, 12, 24, 24, 25, 20,  3, 21, 20,  1, 13,\n",
      "        14, 10, 28, 24], device='cuda:0')\n",
      "tensor([ 8, 10,  8, 13,  7, 13, 27, 14,  1, 18, 27, 14,  4,  2,  4, 16,  0, 13,\n",
      "        13, 25, 29, 27, 25, 13,  1, 27, 18, 27,  2,  8, 27, 13, 10, 27, 24, 10,\n",
      "         7, 15,  7, 25, 27, 27, 10,  4, 24, 13,  6,  8,  0, 13, 14, 24, 13, 18,\n",
      "        21, 10, 10, 18,  1, 27,  8, 27,  1, 10,  8,  1,  8,  4, 27, 21, 16,  1,\n",
      "        16,  7, 27, 27, 25, 13,  1,  1, 16,  2,  1,  1, 10,  4,  1, 15, 25, 18,\n",
      "        13, 13, 27, 23, 27,  4, 16,  8, 27,  4, 25, 27, 18, 27, 27, 25, 16, 13,\n",
      "         8, 18, 10, 27,  0, 19, 27, 25,  0,  1, 27, 27,  1,  1,  8, 13,  6,  8,\n",
      "        22,  8, 27,  1,  1, 25, 15,  7, 16,  7,  2,  1,  7, 29, 13, 27, 27, 27,\n",
      "        13, 27, 25, 14,  4,  0, 24, 22, 27, 21, 27, 27, 25, 24,  4, 25, 15, 14,\n",
      "        27, 18, 19,  4, 19,  1, 27, 27,  1, 15, 15, 27, 27, 21, 29,  1,  1, 16,\n",
      "        13, 13,  1, 27,  7, 15,  6, 21, 18, 13,  1,  7, 27, 21,  8, 25,  7, 24,\n",
      "         8, 15, 13,  0, 21, 29, 21, 21, 10, 27,  0,  8, 27, 27, 18,  1,  0, 29,\n",
      "        18, 10,  4, 29,  1, 15,  8,  8,  1, 10,  0, 24, 27, 27, 21,  8,  8,  1,\n",
      "        19,  1, 10, 16, 18, 21, 22,  1,  7, 27, 16, 27, 15,  4, 27,  1,  6,  1,\n",
      "         0, 14, 14, 27], device='cuda:0')\n",
      "tensor([ 8, 10,  8, 13, 13, 13, 20, 14,  1, 29, 26, 14,  4,  2, 22, 16,  6,  7,\n",
      "        13, 15, 29, 21, 25, 13, 26, 28,  8, 26,  2,  8, 20,  7, 10, 27, 24, 10,\n",
      "         7, 15,  9, 15, 31, 31, 10, 22, 24, 13,  6,  8,  5, 13, 14, 24, 13,  1,\n",
      "         8,  6,  1,  6,  1, 28, 16, 27, 23, 11,  8, 11, 21, 21, 27,  0, 15,  1,\n",
      "        16,  7, 27, 12, 25, 13, 14,  1, 16,  1,  1,  1, 11,  4,  2, 15, 25,  8,\n",
      "        13, 13, 28, 23, 21,  4, 16,  5, 27,  2, 25, 27, 13, 24, 28, 25, 16, 13,\n",
      "        29, 19, 17, 31, 18, 19, 27, 25,  0,  1, 31, 31, 29,  1,  8, 13,  6,  8,\n",
      "        22,  8, 10,  1,  1, 25, 15,  7, 16,  7, 16, 10,  7, 29, 13, 31, 27, 20,\n",
      "        13, 27, 25, 19,  4,  1, 24, 22, 10, 24, 20, 21, 25, 24, 25, 25, 15,  0,\n",
      "        20, 23,  2, 22,  0, 29, 13, 28,  1, 15, 15, 27, 26, 23, 29,  1,  1, 16,\n",
      "        13, 13, 11, 27,  7, 16,  6,  1, 13, 13, 29,  7, 24, 26,  8, 25,  1, 24,\n",
      "         8, 15, 13,  0, 11, 29, 10, 13, 11, 19,  0,  8, 12, 26,  1,  1,  0, 29,\n",
      "         1,  3, 18, 29,  1, 15,  8,  8,  1, 10,  2, 24, 22, 20, 21,  8,  8,  1,\n",
      "        26,  1, 14, 16, 18, 21, 22, 21,  7, 27, 16, 11, 15, 31, 12,  8,  6, 26,\n",
      "         0, 14, 14, 27], device='cuda:0')\n",
      "tensor([ 1, 27, 27, 19, 29, 16,  1, 16,  1, 18, 27, 10,  4, 27, 18, 27, 24, 16,\n",
      "         8, 24, 27, 27,  1,  4, 27, 18,  2, 10,  1, 25, 19, 27,  8, 18, 24,  0,\n",
      "        27,  2, 24, 27,  0, 18, 10, 16, 27, 18,  1,  8,  1,  2,  7, 14,  1, 21,\n",
      "        27, 21,  2,  4, 13, 25,  8, 27, 14, 27, 18,  8,  7, 27, 25,  1,  6, 11,\n",
      "        27, 10, 27, 18, 21, 27,  0,  1, 14, 29, 15,  1, 27, 18, 21,  1, 29,  2,\n",
      "        27, 27,  1, 13, 27, 25,  1, 27,  1, 27,  1, 10,  8, 25, 27, 21,  1, 25,\n",
      "        27, 10, 18,  4,  0, 19, 18,  1,  4, 25, 10, 27,  4, 27, 27, 29, 21,  1,\n",
      "        18, 24, 27, 16, 27, 18,  8, 25,  0,  1, 21, 16, 18, 13,  1, 13,  8,  4,\n",
      "        15,  0, 19, 18,  1, 13, 13, 21,  8, 27, 21,  4, 14, 25, 14, 21, 10, 18,\n",
      "        27,  7,  4, 27, 13, 16, 27,  1,  8, 21,  8, 10, 27, 14,  1, 10, 13,  1,\n",
      "        13,  8,  8, 24,  2, 27, 15,  1,  7, 24, 13,  4,  0, 21, 15,  0, 16, 14,\n",
      "        27, 14,  1, 21, 15, 15,  7, 13, 10, 16, 13, 27, 16,  0, 29, 27,  0,  1,\n",
      "        27,  2, 21, 13, 27, 18,  2,  1, 18, 16,  0, 14, 27, 27, 29, 25,  1,  1,\n",
      "        13, 16, 18, 14, 13, 27, 24, 25, 25, 19,  8, 27,  1, 18,  1, 16,  2, 18,\n",
      "        27, 27,  1, 13], device='cuda:0')\n",
      "tensor([ 1, 27, 20, 19, 29, 16,  1, 16,  2, 25,  1, 17,  4, 27,  8, 27, 24, 16,\n",
      "         8, 24, 20,  3,  1,  4, 19, 18, 25, 10,  1, 25, 19, 20, 25, 18, 24,  0,\n",
      "         1,  2, 24,  9,  0, 18, 10, 16, 25, 18, 18,  8,  1,  2,  7,  0, 18, 25,\n",
      "        20, 11,  2,  4, 13, 25,  2, 11, 25, 11, 18,  0,  7,  1,  0,  1,  6, 11,\n",
      "        27, 21, 27, 18, 23, 27,  0,  1, 14,  7, 15, 11, 27,  1, 23,  1, 30,  2,\n",
      "        21, 26,  1,  3, 20, 10,  1, 27,  8, 22, 21, 10, 25, 25, 20, 10,  1, 25,\n",
      "        27, 10,  1,  4,  0, 19, 21,  1, 25, 25, 10, 10, 22, 27, 27,  1, 26, 21,\n",
      "        18, 24, 29, 16, 26, 18,  8,  6,  0, 11, 21, 16, 18, 13,  1,  7, 14, 22,\n",
      "        15,  0, 19, 16, 10,  7, 13, 21,  8, 27, 26,  4, 14,  6,  0, 21, 24, 18,\n",
      "        20,  7,  4, 32, 13, 16, 21,  1,  8, 23,  8, 28,  8, 11,  1, 28, 13,  1,\n",
      "        13,  8,  8, 24,  2, 27, 15,  1,  7, 24, 13,  4,  0,  1, 15,  0, 16, 14,\n",
      "        27, 14,  1,  8, 15, 15,  2, 13, 10, 16, 13, 27, 16,  0,  8, 12,  0,  1,\n",
      "        11, 25, 10, 13, 28,  2,  2, 27, 18, 16,  0, 14, 12, 27, 29, 25, 29,  1,\n",
      "        13, 16, 18, 14, 13, 13, 24, 15, 25,  3,  8, 24,  1, 29,  1, 16,  2,  0,\n",
      "        23, 26,  1, 13], device='cuda:0')\n",
      "tensor([ 4, 21, 25, 15, 15, 10, 15,  1,  1, 13, 27, 10, 24, 29, 10, 27, 18, 29,\n",
      "         8, 14, 13, 29, 25,  2, 29, 21, 24, 25, 25,  8, 27, 16, 18, 13,  7, 24,\n",
      "         2, 27,  1,  1,  1, 24,  8,  1, 24, 27, 27,  1,  0, 14, 25, 18, 18, 24,\n",
      "        13, 13,  4, 27, 16, 13, 10, 16, 29, 13, 27,  4, 18, 13,  1,  4,  7,  1,\n",
      "        15,  8,  2,  2,  1, 27, 24, 13, 15,  1,  1,  8, 15, 24,  0, 22, 27,  8,\n",
      "         1, 18, 16, 15, 10, 27, 10, 29,  1, 18, 18, 10, 27, 15,  2, 27,  4,  8,\n",
      "         1, 24, 24, 14, 13, 16, 16, 10,  1, 27,  0, 27, 14, 18,  1, 10, 18,  0,\n",
      "        10, 29,  2, 14, 18,  1,  8,  8, 27,  8,  1, 15, 27, 15, 16, 10,  0,  1,\n",
      "         1, 27,  4, 25, 10, 18, 13,  8, 15,  1, 21,  4, 27, 29, 24,  7, 14,  1,\n",
      "         0, 27, 25,  1, 29, 16,  8, 18,  8, 24, 25, 14, 27, 29, 29,  8, 13, 21,\n",
      "         4, 27, 27,  1, 21, 21, 27, 24,  1, 24, 14, 15, 10, 16,  8, 27, 29, 27,\n",
      "        16, 15, 10,  1, 27, 29, 16,  1,  1, 27, 18, 27, 29,  4,  1, 13, 14, 13,\n",
      "        25, 16,  7,  1, 24,  1, 27, 15, 15, 24, 16, 10, 18, 15, 24, 21,  2,  0,\n",
      "        19, 13, 27, 16,  1, 27,  0,  8, 10, 27,  0, 16, 27,  4, 13, 15,  0, 13,\n",
      "        21, 16, 27, 15], device='cuda:0')\n",
      "tensor([15, 11,  4, 15, 15, 10, 15,  1, 17, 13, 12, 11, 24,  4, 10, 27,  8, 29,\n",
      "         8, 14,  3, 29, 25,  2, 29, 21, 18, 25, 25,  8, 26, 16, 11, 12,  7, 24,\n",
      "        10, 28,  7,  1,  1, 24,  8, 25, 24, 27, 20, 11,  0,  4, 25,  7, 18, 24,\n",
      "        13, 13,  4, 26, 16, 13, 10, 16, 18, 13,  1, 18, 18, 13, 27, 22,  7,  1,\n",
      "        15,  8,  8,  2,  1, 27, 24, 23, 15, 18,  1,  8, 15, 24,  0, 22, 26,  8,\n",
      "         1, 25, 16, 15, 10, 21, 11, 29,  1,  1, 18, 14, 21, 15,  2, 27,  4,  8,\n",
      "        10, 24, 24, 11, 13, 16, 25, 10,  1, 21,  0, 21,  0, 23,  7, 10, 13,  0,\n",
      "        18,  8,  2,  6,  9, 29,  8,  8, 28,  8,  1, 15, 20, 15, 16, 10,  0, 11,\n",
      "         1, 20, 22, 32, 10,  1, 13,  1, 15, 18, 21, 23, 26, 29, 24, 21, 11,  1,\n",
      "         0, 27, 25, 18, 29, 16, 25, 19,  8, 24, 25, 14, 27, 29, 29,  8, 13, 21,\n",
      "        22, 17, 32, 29,  4,  2, 11, 24,  2, 24, 14, 15, 15, 16,  8,  1, 30, 17,\n",
      "        16, 15, 10,  1, 20, 29, 16,  1,  1, 11, 18, 20, 29,  4,  4, 13, 14, 13,\n",
      "        25, 16,  7,  1, 24, 21, 27, 19,  5, 24, 16, 17, 14, 15, 24, 21,  2,  0,\n",
      "        19, 13, 27, 16,  1, 28,  0, 10, 10, 28,  0, 16, 12,  4, 13, 15,  0, 13,\n",
      "        13, 15, 26, 15], device='cuda:0')\n",
      "tensor([29, 16, 13, 27,  0, 29,  4, 10, 24, 27, 29,  4, 18,  4, 18, 18, 24,  4,\n",
      "         4, 11, 21, 24,  7, 27, 21, 27,  1, 13, 19,  0, 19, 15, 29, 27, 14, 27,\n",
      "        18,  1, 13, 25, 15, 27,  0, 27, 18, 24, 16,  8,  1,  1,  4, 21, 10,  4,\n",
      "         1, 10, 13, 21, 21, 27,  1,  2, 29, 27,  4, 29,  1, 15, 15,  7,  1, 29,\n",
      "         1,  8,  8, 15,  7, 13, 27, 24, 21, 25,  1, 10,  4,  1, 10, 27, 21, 19,\n",
      "         0, 15,  0, 18,  4, 24,  8, 13,  4, 27,  8, 13, 27, 27,  4,  1, 21, 29,\n",
      "         1,  4,  1,  1,  1, 15, 18, 21, 24, 10,  8,  0, 27, 27, 15, 15, 10,  2,\n",
      "        24,  1, 18, 29, 27,  1,  7, 10, 21, 15, 27, 15, 22,  1, 24, 27, 27,  1,\n",
      "        27, 16,  8, 27, 13, 13, 22, 16,  1,  1, 10,  1, 13,  0, 15, 27, 10, 27,\n",
      "         1, 14,  2, 27, 27, 15,  1, 21, 21, 21, 13, 13, 27, 13,  1,  1, 15, 27,\n",
      "         2, 15, 21,  1, 24, 25,  1, 24,  1,  4, 24,  0, 21,  4, 29, 29, 15, 19,\n",
      "        14, 24, 25, 27, 21, 27, 25, 21,  1, 15, 22, 10, 14,  1, 18, 15, 10,  7,\n",
      "         7, 16, 27,  7,  1, 10,  7, 11,  4,  8, 21,  8, 13,  8, 18,  7,  1, 10,\n",
      "        13,  1,  4, 25, 22, 29, 29, 18,  1,  0, 27,  0, 10,  0,  8, 27, 16, 13,\n",
      "        27, 13, 27, 27], device='cuda:0')\n",
      "tensor([29, 16, 13, 27,  0, 29,  4, 18, 24, 27, 29,  4, 18, 22, 15, 18, 24,  4,\n",
      "         4, 11,  7, 23,  7, 21,  1, 27,  1, 13, 22,  0, 27, 15, 29, 13,  8, 21,\n",
      "         1, 23, 13, 14, 15, 27,  0, 11,  1, 24, 16,  0,  1,  1,  4, 21, 10,  4,\n",
      "         2, 10, 13,  7,  8, 26,  1,  2, 29, 12,  4, 29, 15,  8, 15, 24, 27,  7,\n",
      "         1,  8, 16,  7, 10, 13, 18, 24, 23, 25,  1, 10,  4,  8, 10, 27, 15, 19,\n",
      "         0, 15,  0,  1,  2, 24,  8, 13,  4, 27,  8,  8, 27, 28,  4,  4,  8, 29,\n",
      "         1,  1, 25,  1,  1, 15, 18, 21, 24, 14,  8,  0,  2, 27, 15, 15,  3, 21,\n",
      "        24, 32, 18, 30, 13,  1,  7, 10, 19, 15, 20, 15, 22,  9, 24, 27, 12,  2,\n",
      "        13, 16,  1, 24, 13, 13, 22, 16, 29, 21, 10,  1, 13,  0, 15, 32, 10, 27,\n",
      "         1, 28, 25, 17, 27, 15,  1, 21,  8, 21, 13, 13, 26, 13,  1, 18, 15, 27,\n",
      "         4, 15,  5, 25, 24, 25,  1, 24,  1,  4, 11,  0,  7,  4, 29,  7, 15, 19,\n",
      "         5,  0, 14, 20, 25,  1,  4, 21,  1, 16, 22, 21, 14, 11, 18, 15,  1,  7,\n",
      "         1,  1, 27,  7,  1, 10,  0,  0,  4,  8, 23,  8, 13,  8, 18, 13,  1, 11,\n",
      "        13, 21,  4, 25, 22, 29, 29, 23, 26,  0, 26,  0, 10,  0,  8,  1, 16, 13,\n",
      "        28, 13, 21, 28], device='cuda:0')\n",
      "tensor([ 0, 21, 15,  4, 24,  8,  1,  8, 10, 14,  1, 16, 15, 24, 21, 29, 27, 14,\n",
      "        10, 21,  1,  4, 24,  1,  4, 14,  1, 21, 29, 16,  6, 27, 18, 24,  2,  7,\n",
      "        27, 25, 21, 27, 29, 27,  2, 24, 16, 15, 27, 27,  1,  4, 27, 27,  1, 10,\n",
      "        16,  8,  2,  1, 18,  1, 25, 27, 27,  4,  1, 18,  2, 15, 16, 24, 27,  1,\n",
      "        27, 24, 13, 24,  1, 14,  8, 29,  0, 18, 27,  2, 27,  2,  4, 25,  4, 15,\n",
      "         2,  0, 10, 18, 13, 21, 29, 21, 24, 23, 29, 15,  1, 14,  0,  4, 23, 19,\n",
      "        25, 10, 16, 15, 15, 10,  7, 25, 27, 16,  0, 15, 16, 18, 27, 15, 18, 27,\n",
      "        29, 18, 15, 24, 14,  7, 18, 15, 18,  8,  8, 27, 29, 15, 25, 25, 14,  4,\n",
      "        27, 16,  8, 16, 27,  1, 29, 18, 10, 29, 29,  8,  1, 10, 29, 16, 15,  2,\n",
      "         7,  1, 27, 29,  2,  4, 29,  7, 29, 27, 13, 15, 27,  2, 24, 27,  0,  1,\n",
      "         0, 18,  4, 29, 13, 27,  8, 25,  8, 27, 27,  1, 13, 15,  8,  6,  1, 27,\n",
      "        14, 27,  7, 13, 25,  8, 13,  0, 13, 15, 27,  4, 27, 27, 27,  2, 27,  1,\n",
      "        25, 27, 13, 16, 29, 18, 10, 18, 19, 10, 19,  7, 25,  8, 27, 29, 10, 10,\n",
      "        25, 13, 25,  1, 21,  1, 25,  1, 15, 27, 27, 25, 27, 27,  1, 24, 21, 18,\n",
      "        15, 25, 18, 13], device='cuda:0')\n",
      "tensor([ 0, 30, 15, 22, 24,  8,  1,  8, 11, 14, 14, 24, 15, 24, 31, 29, 12, 14,\n",
      "        10, 21, 27,  4, 24,  1,  4, 14,  1, 21, 29, 16,  6, 27, 21, 24,  6,  7,\n",
      "        12, 25, 11,  8, 29, 27,  2, 24,  8, 15, 27, 12, 18,  4, 23, 20,  1, 10,\n",
      "        16,  8, 11,  1, 18,  1, 25, 12,  9,  4,  1, 18,  2, 15, 16, 24, 20,  2,\n",
      "        15, 24, 13, 24,  1, 14,  1, 29,  0, 14, 21,  2, 26,  2,  4, 25,  4, 15,\n",
      "         2,  0, 11, 18, 13, 21, 29,  5, 24, 23, 29, 15,  1,  1,  0,  4, 23, 26,\n",
      "        25, 11, 16,  4, 15,  1, 13, 17,  9, 16,  0, 15, 18, 18, 21, 15,  6, 20,\n",
      "        29,  0, 15, 24, 14,  7,  8, 15,  8,  8,  8, 15, 29, 15, 25, 25, 14,  4,\n",
      "        23, 16,  8, 16, 21,  2, 25, 18,  1, 29, 29,  8,  1, 24, 29, 16, 15,  2,\n",
      "         7,  1, 27, 29,  2,  4, 29,  7, 29,  1, 13, 15, 27,  2, 24, 21,  0,  1,\n",
      "         0, 21, 29, 29, 13, 11,  8, 25,  6, 27, 27,  1, 13, 15,  8,  1,  1, 20,\n",
      "        14, 12, 13, 13,  6,  8, 13,  0, 13, 18, 20, 24, 21, 10, 27, 21, 27,  1,\n",
      "        25, 12, 13, 16,  7, 18, 11, 21, 19, 10, 19,  7, 25,  2, 32, 29, 11, 10,\n",
      "        25, 13, 25,  1, 21,  1, 25, 17, 15, 23, 21, 25, 26, 27, 18, 24, 21,  0,\n",
      "        15, 25, 14, 13], device='cuda:0')\n",
      "tensor([ 1,  1, 13, 10, 21, 19,  7,  1, 27, 29,  1, 29,  0, 16, 27, 21, 27, 10,\n",
      "        27,  1,  1, 21, 27, 10, 10, 15, 14, 10, 29, 19,  4,  1, 21, 10,  7,  8,\n",
      "         4, 13,  1,  1,  2,  7, 15, 13,  1, 11, 29,  1, 15,  0, 24, 16,  8, 27,\n",
      "        27, 16, 18, 21,  2, 22, 13,  0,  8, 29, 27,  1, 13, 27,  4, 27, 19,  7,\n",
      "         1, 29, 25,  8, 13, 10, 10, 24, 16, 21,  2, 24,  8,  7, 25, 21, 13, 15,\n",
      "        10,  4, 27, 27,  2, 27,  1, 27,  1,  8, 27,  6,  4, 16, 22,  1,  4, 21,\n",
      "        11,  8, 27, 22, 19, 10, 15,  1,  1,  8, 21,  1, 27,  4, 16, 25, 21, 21,\n",
      "         2,  4, 16, 21,  6,  4, 14, 29, 15,  1, 29, 29, 21, 18, 23, 27,  4,  1,\n",
      "        21, 10, 18,  1, 21, 18, 14, 19, 13, 22, 13, 13,  8, 24, 13,  4,  2, 10,\n",
      "        29,  1, 18, 25,  7, 16, 19,  7, 10, 14,  1,  1, 27,  0, 22,  1,  4, 10,\n",
      "        27, 27,  0, 21, 24,  1, 11, 14, 14, 19,  1, 27,  4, 29, 22,  1,  2, 18,\n",
      "        27, 21, 16, 29, 10, 21, 21, 13,  2, 25, 27, 14, 27, 27, 27, 13,  4,  8,\n",
      "         8,  1,  4, 15, 13,  1, 16,  0,  7,  8,  1, 24, 15, 27,  1, 15, 29,  1,\n",
      "        29, 10, 21, 14, 27,  2, 18, 18, 24, 27, 24,  4, 27, 24, 21, 29, 10,  8,\n",
      "        24, 19, 21, 21], device='cuda:0')\n",
      "tensor([ 1,  2, 13, 25, 21, 15, 21,  1, 26, 29,  1, 29,  0, 16, 10, 21, 27, 24,\n",
      "        27, 30,  5, 23, 20, 10, 10, 15, 14, 10, 29, 30,  4, 17, 14, 10, 25, 16,\n",
      "        22, 13, 22,  1,  2,  7, 15, 13, 21, 11,  0, 11, 15,  0, 24, 16,  8, 14,\n",
      "         1, 16,  0, 21,  2, 22, 13,  0,  8, 29,  1, 10, 13, 27,  4, 11, 19, 15,\n",
      "         0, 29, 25,  8, 13, 10, 11, 14, 16, 31,  6, 24, 25,  1, 26,  5, 13, 15,\n",
      "         1,  4, 27, 27, 12, 20, 21, 20,  1,  6, 10,  6,  4, 16, 22,  1,  4,  3,\n",
      "        11,  8, 28, 22, 15, 11, 15,  1, 18,  8, 11, 11, 20,  4, 16, 25, 21, 21,\n",
      "         8,  4, 16,  2,  6,  4, 14, 29, 15,  5,  0, 29, 21, 32, 23, 27,  4, 25,\n",
      "        23, 10, 18,  8, 10, 18, 21, 10, 13, 22, 13, 13,  8, 24, 13,  2,  2, 11,\n",
      "        29, 23, 18, 25,  7, 16, 19,  7, 10, 14,  1,  1, 13,  8, 22, 18, 25, 11,\n",
      "        27, 21,  0,  8, 24,  8, 11,  4, 13, 19,  9, 32, 22, 29,  4,  1,  2,  6,\n",
      "        27, 23, 16, 29, 11, 21, 14, 13,  2, 25, 20,  0, 28, 27, 20, 13,  4,  2,\n",
      "         8,  1,  4, 15, 13,  1, 16,  0,  7,  0,  1, 24, 15, 12,  1, 15, 29,  1,\n",
      "        25, 10, 21, 14, 20,  2, 18, 18, 24,  1, 24,  4, 21, 24,  7, 29, 10,  8,\n",
      "        24, 19, 32,  7], device='cuda:0')\n",
      "tensor([18,  7, 27, 22,  1,  2, 18, 27, 15, 13,  8,  8,  1,  1, 24, 21,  7,  8,\n",
      "        27, 29, 21,  4,  7, 27, 27, 13, 18, 21, 10,  1, 13, 16,  7, 27, 27, 27,\n",
      "        29, 18,  7,  1, 27,  4, 21, 18, 14,  1, 27, 15, 24,  0, 13,  8, 29,  1,\n",
      "        27, 15, 18, 18,  8,  4,  0,  2, 24, 21, 27,  1, 27, 13,  6, 25, 13, 15,\n",
      "        27,  6, 10, 15, 27, 16, 14, 22,  0, 16, 27,  7,  1, 18,  1, 21, 13,  1,\n",
      "         7, 25, 29, 16, 21, 18,  4,  0,  4, 25,  1,  1, 21, 21,  4, 21, 18, 29,\n",
      "        21, 21, 10,  1, 16, 10, 24,  7,  7, 27, 27,  1, 21,  8, 29, 10, 10,  1,\n",
      "        18, 19,  4, 19, 27, 18, 21,  1, 16,  1, 29, 21,  1, 15, 10,  1, 29, 18,\n",
      "        27, 29,  1, 18,  8,  1,  1, 18, 27,  7, 27,  4, 13,  1, 18, 27,  1, 24,\n",
      "        10,  4, 27, 18, 21, 27, 25, 19, 27, 13, 21, 16, 16, 15, 16, 10,  7,  2,\n",
      "        29, 24, 18,  8, 25, 29, 27, 27, 18, 10, 25,  0, 21,  1, 29, 18,  1, 10,\n",
      "        24, 27, 18,  7, 16, 24, 10, 25, 27,  8, 14,  6, 16, 25,  4, 25,  1,  8,\n",
      "         0,  4, 21, 27, 10,  1,  1, 11, 24, 24,  1, 15, 10, 18,  1, 18, 15,  2,\n",
      "         2, 10,  4, 25, 16, 14, 11, 24, 10, 13,  1, 15, 15,  8, 15, 21, 21,  4,\n",
      "         1, 21,  7, 27], device='cuda:0')\n",
      "tensor([18,  7, 21, 22,  1, 14, 18,  6, 15, 13, 18,  1, 17,  7, 24,  8, 13,  8,\n",
      "        23, 29, 11,  4,  7, 20,  1, 13, 18,  0, 14, 11, 13, 16, 14, 27, 27, 27,\n",
      "        25, 18, 13, 11, 27,  4, 21, 23, 14, 10, 28, 15,  5,  0, 13,  8, 29,  2,\n",
      "        27, 15, 18,  1,  8,  4,  0,  2, 24, 21,  1, 18,  9, 13,  6,  6, 13, 15,\n",
      "        31,  6, 10, 15, 27, 16, 14, 22, 18, 16, 27,  7,  1, 18,  2, 19, 13, 21,\n",
      "        13, 25, 29, 16, 21, 18,  4,  0, 21, 25, 11,  1, 14, 21, 25, 21, 18, 29,\n",
      "         1, 15, 10, 10, 16, 18, 24,  7,  7, 21,  9,  1, 23, 29,  9, 10, 21, 30,\n",
      "        18, 24,  4, 19, 32,  1,  7, 11, 25, 11, 29,  8, 11, 15, 10,  1, 29, 12,\n",
      "        26, 29,  1, 24,  8,  2,  1,  1, 27,  7, 12, 22, 13,  1, 18, 28,  1, 24,\n",
      "        10,  4, 20,  9,  1, 21, 22,  4, 27, 13, 32, 16, 16, 15,  8, 11,  7,  2,\n",
      "         1, 23, 18,  8, 25, 29,  8, 22, 28, 10,  0,  0, 27,  1, 29, 18,  1, 15,\n",
      "        24, 27, 30, 21, 16, 24, 10, 25, 19,  8,  0,  6, 16, 25,  4, 15,  2,  8,\n",
      "         0,  4, 21, 11, 10, 10,  1, 11, 24,  5, 25, 15, 11,  1,  1, 23, 15,  2,\n",
      "         2, 10,  4, 25, 16, 14, 11, 24, 20, 13,  1, 15, 15,  8, 15, 13, 21,  4,\n",
      "         1, 23, 23, 28], device='cuda:0')\n",
      "tensor([ 0, 27,  0, 27, 21,  1, 21, 29, 25, 13,  1, 27,  2, 10,  7,  4, 25, 18,\n",
      "         1, 27,  1, 21, 27, 21, 16, 29,  8, 18, 27, 27, 27, 16,  6, 27, 27, 21,\n",
      "        18,  4,  7, 25, 27, 14, 25, 13, 16, 27, 10, 27, 16, 21, 27, 29,  1, 24,\n",
      "         7,  1, 21,  1, 10,  7,  0,  8, 16, 29, 29, 18, 15,  1, 16,  1,  1, 10,\n",
      "         1, 27, 14, 13, 19, 14, 18,  1, 27, 24, 27,  1, 21, 21, 27, 27, 27, 21,\n",
      "        27, 27, 27,  4,  1, 27,  7, 13, 18,  1,  4, 25, 15,  1, 27,  2, 16, 13,\n",
      "        25, 29, 18, 21,  8, 10, 27, 10,  1, 10, 15, 23, 27, 24, 10, 27, 10,  1,\n",
      "         1, 27, 25, 27,  1, 13, 19, 13,  4, 27, 25,  7,  1, 10, 24, 27, 27,  7,\n",
      "         1,  0,  4,  1,  1,  0, 18, 21,  1, 10, 27,  8, 10,  7, 27,  4, 29,  0,\n",
      "         1, 18,  1, 21, 14, 25, 27,  4, 15, 24, 27, 16, 27, 13, 24, 21, 16,  7,\n",
      "         1, 15, 27, 25, 29, 18, 21,  1, 29, 21, 25, 22, 27, 16,  4,  8, 14, 24,\n",
      "        27, 15, 24, 29, 27,  1,  1, 15,  4, 27, 15, 14, 25, 14, 27, 29, 16, 13,\n",
      "        21, 19, 27,  8, 18,  8, 14, 27,  1, 27, 18, 18, 22,  1, 27,  7, 24, 14,\n",
      "         1,  8, 18,  4, 16, 13, 11,  4, 27,  1,  8,  8,  4, 10, 16, 16,  7, 27,\n",
      "        21,  1, 13, 15], device='cuda:0')\n",
      "tensor([29, 27,  0, 12, 23, 26, 21, 29, 25, 13,  7, 26,  2, 11, 23,  4, 25, 18,\n",
      "        23, 28,  1,  1, 12,  1, 16, 29,  8, 29, 27, 32, 27,  6,  6, 20, 20,  7,\n",
      "        18,  4,  7, 25, 20, 23, 25, 13, 16, 27, 19,  1, 16, 21, 27, 29,  1, 24,\n",
      "         7,  8, 21,  9, 23,  2,  2,  8, 16, 29, 29, 23, 15,  1, 16, 11, 18, 10,\n",
      "        23, 27,  8, 13,  2, 14, 18,  1, 10, 24, 28, 23,  0,  2, 28, 20,  0, 21,\n",
      "        20, 27, 12,  4, 15, 27, 18, 13, 18,  1,  4, 25, 15, 21, 27,  2, 16, 13,\n",
      "        25, 29,  8, 31,  8, 11, 11, 10,  1, 10, 15, 23, 27, 24, 11, 10, 10,  1,\n",
      "        13, 27, 15, 22,  1, 13, 19, 13, 29, 27, 25,  7, 23, 23, 24,  4, 27,  7,\n",
      "         1, 29,  4,  1, 21,  0, 18,  4,  5, 10, 27,  8, 10, 10, 27,  4, 29,  0,\n",
      "         1, 29,  1,  1,  5, 25, 27, 22, 15, 24, 27, 16, 27, 13, 24, 21, 16,  4,\n",
      "        25, 15, 27, 25, 29,  1,  3,  1, 29, 21, 25, 22, 21, 16, 19, 11, 14, 24,\n",
      "         9, 15, 24,  1, 27,  1, 27,  3,  4, 31, 15, 14, 25, 14, 12, 29, 16, 13,\n",
      "        23, 26, 20, 23, 18,  8, 14, 27, 25, 26, 18, 19, 22,  1, 20,  7, 24, 32,\n",
      "         1,  8, 18,  4, 16, 13, 23,  4, 20,  1,  8,  8,  4, 10, 16, 16, 21, 32,\n",
      "        21,  1, 13, 15], device='cuda:0')\n",
      "tensor([13,  1, 13, 21, 19,  8, 21, 25, 10,  8, 18, 16, 14,  8, 16, 25, 10,  4,\n",
      "         2, 13, 27, 25, 27, 21, 29, 27, 10,  1, 21,  1, 16, 18, 18, 29,  8, 27,\n",
      "         2,  1,  1, 16, 10, 16,  1, 15, 27,  1, 24, 13,  8,  0, 27, 15, 29, 18,\n",
      "         1, 24, 22, 27, 25,  7, 25, 27, 29,  1,  1,  8,  0,  7, 23,  4, 27,  1,\n",
      "         1, 22,  7,  1, 25,  1, 27, 10,  4, 15,  1,  1,  2,  1, 10, 21,  1,  7,\n",
      "        27, 27,  0, 18, 25,  2, 18,  1, 24, 27, 29, 18,  4, 15,  1, 18, 10, 19,\n",
      "         6, 25, 21, 27,  1,  0,  0,  4, 14, 29, 24,  8, 21, 27, 27, 15,  1, 21,\n",
      "        24,  4, 29, 18, 27,  7, 24, 27, 27,  6,  1, 27,  1, 27, 27, 29, 21,  1,\n",
      "         8, 14, 29, 13,  1, 19,  8,  4, 19, 24,  7, 24, 16,  8, 27,  0, 27,  1,\n",
      "        27, 21, 27, 16, 19, 18,  1, 25,  1, 27, 24, 16,  7, 27, 24,  7, 25, 21,\n",
      "        10, 21, 27,  2,  7,  0,  0,  1,  1, 27, 13, 27, 21,  2,  8, 24,  1, 13,\n",
      "         1, 10,  2, 13,  8, 21, 15, 10, 27, 27,  7, 22,  1, 27, 15, 25, 10, 24,\n",
      "        27, 25, 21, 27, 29,  4,  1,  1, 25, 22,  8, 21, 27, 25, 24,  0, 11,  1,\n",
      "        10, 14, 29, 13, 10, 16,  0, 14,  1, 27, 27, 14, 10, 27, 13, 16, 27, 18,\n",
      "        15, 24,  2,  1], device='cuda:0')\n",
      "tensor([13,  0, 13, 31, 26,  4, 21, 25, 11,  2,  6, 16, 14, 25, 16, 25, 10,  4,\n",
      "        29, 13,  1, 25, 27, 21, 29, 27, 10,  1, 26, 17, 16, 15, 21,  4,  8, 27,\n",
      "         2,  0,  1, 16,  7,  8,  1,  2, 26,  1, 24, 13,  8,  0, 27, 15, 29, 30,\n",
      "         7, 24, 22, 21, 25,  7, 25, 27, 29,  1,  1,  8,  0, 13, 23,  4, 31,  5,\n",
      "         2, 22,  7,  0, 25,  1, 27, 10, 22, 15,  2,  4,  4, 23, 17, 21, 23, 15,\n",
      "        28, 21,  0, 18, 25,  2, 18, 23, 24,  1, 29, 11,  4, 15, 13,  8, 11, 27,\n",
      "         6, 25, 25, 23, 23,  0,  0,  4, 14, 29, 24,  2, 21, 28, 27, 15, 13, 21,\n",
      "        24,  4, 29,  8, 20,  7, 24, 12, 26,  6,  2, 26,  1, 28, 12, 29, 21, 21,\n",
      "         8,  2, 29, 13, 15, 19,  8, 22, 19, 24,  7, 24, 16,  8, 11,  0, 27,  2,\n",
      "        27, 21, 28, 16, 19, 23,  1, 25,  2, 24, 24, 16, 13, 27, 18, 15, 25, 23,\n",
      "        10, 21, 17,  2,  7,  0,  0,  1,  1, 21,  7, 27,  2,  2,  8, 24,  1, 13,\n",
      "         7, 10,  2, 13,  8, 17, 15, 10,  8, 27,  7, 22,  1,  9, 15,  5, 10, 24,\n",
      "        20, 25, 21, 26, 29,  4,  1,  1, 25, 22,  0,  7, 20, 14, 24,  0, 11, 19,\n",
      "         2, 25, 30, 13, 11, 24,  0,  0, 14, 21,  0, 29,  2, 23, 13, 16, 27, 18,\n",
      "        15, 24,  2, 30], device='cuda:0')\n",
      "tensor([25, 25, 16, 13, 21, 16, 16,  1, 24,  0, 27,  1,  1, 27, 27, 18, 25, 25,\n",
      "        16,  1, 14, 16,  1, 27,  7,  2, 27, 13,  1, 21, 10, 27, 27,  0,  4,  1,\n",
      "        13,  0,  6, 16, 27, 29, 16, 25, 24,  4, 25, 18, 27, 18,  8, 27, 27,  8,\n",
      "         1,  0,  1, 27,  2, 24, 27,  1, 21, 18, 24,  8, 18,  2,  2,  0, 18, 29,\n",
      "         7, 27, 16, 27, 27, 25,  1, 10, 29, 10,  7, 16, 18, 18,  0, 15, 15,  0,\n",
      "        21, 16, 16, 18, 18, 10,  1, 14, 13, 24,  0, 21, 15, 19,  1, 27,  7, 15,\n",
      "         2, 21, 13, 27,  1, 27,  7, 29, 27, 27, 16,  8, 25, 18, 24,  8,  0,  8,\n",
      "         8, 19,  8, 13,  0,  0, 13,  1, 19, 13, 27,  0,  1, 13, 14, 25,  1, 18,\n",
      "        21, 19, 10, 27, 29,  1, 29,  0, 15,  1,  1,  4, 27, 21, 10,  8,  7, 21,\n",
      "        16, 18,  8, 18, 27,  2,  4, 10, 16, 19, 13, 15, 15, 18,  8, 15,  8, 24,\n",
      "         1,  4, 18,  1,  4, 18,  1,  7,  1, 15, 29, 27, 15,  1,  4, 16, 27,  7,\n",
      "         7, 29,  4,  8, 27,  0,  4, 27, 13,  1, 19,  8, 19,  0, 10, 27,  0,  7,\n",
      "         8, 24,  0, 14, 13, 14, 29, 15, 21, 27,  7, 21,  1, 27,  1,  4,  1, 14,\n",
      "        27, 21, 27, 24,  1,  1,  7, 18, 27,  4, 27, 29, 18, 10, 10, 16,  1,  1,\n",
      "         2, 10, 29, 27], device='cuda:0')\n",
      "tensor([ 6, 25, 16, 10, 21, 16, 16, 30, 24,  0,  8,  1, 10, 27, 12, 10, 25, 15,\n",
      "        16, 25, 14, 16,  8, 12,  7,  2, 12, 13,  1, 21, 20, 20,  9,  0,  4, 11,\n",
      "        13,  0,  5, 16, 11, 22, 16, 25, 24,  4, 17, 19, 27,  0,  8, 20, 28,  9,\n",
      "        29,  0, 14, 28,  2, 24, 31,  1, 23, 14, 24,  8, 23,  2, 29,  2, 23, 29,\n",
      "         7, 12, 16, 31, 21, 25, 11, 11, 29, 10, 15, 14, 18, 29,  0, 15, 15, 14,\n",
      "        27, 16, 15, 18,  8, 10,  1, 29, 13, 10,  0,  8, 15, 19,  2, 27,  7, 15,\n",
      "         2, 21,  3,  9,  1, 12, 13, 10, 27, 27, 15,  8,  6, 23, 24, 14,  2,  1,\n",
      "         8, 22, 14, 13,  0,  8, 19,  1, 26,  7, 17,  3, 18, 13, 14, 25,  1, 19,\n",
      "        24, 19, 10,  1, 23, 19, 27,  0, 15, 10,  1,  4, 28, 17, 11,  1, 21, 21,\n",
      "        16, 21,  8, 15, 26,  2,  4, 12, 16, 14, 13, 15, 15,  1,  8, 15,  8, 24,\n",
      "         1,  4, 18,  1, 22,  8,  1,  7, 11, 15, 29, 20,  8,  1,  4, 16, 20,  7,\n",
      "         7, 29,  4, 13, 20,  0,  4, 28, 13,  1, 18,  8,  3,  0, 14, 21,  0,  7,\n",
      "        24, 24,  0, 14, 23, 15, 29, 15, 21, 28,  7, 24,  1, 27, 29, 22, 10, 14,\n",
      "        31, 31, 27, 24,  1, 11,  7,  6, 24, 22, 27, 29,  7, 10, 10, 16,  1,  1,\n",
      "         2, 23, 25, 28], device='cuda:0')\n",
      "tensor([25, 29,  1, 27, 10, 21, 10,  7, 16, 19,  4, 14, 27,  1, 27,  8, 24, 18,\n",
      "        13, 27, 27, 25, 18,  0, 24, 19, 15, 18, 15, 19, 10, 21,  7, 19, 21, 18,\n",
      "        23, 16, 27, 24,  4,  7, 19,  8, 27,  1,  7, 16,  1, 13,  8, 27,  1, 14,\n",
      "        10, 10,  8, 14, 25, 24,  1,  2, 14, 21, 27, 27, 10,  4, 18, 27,  1,  8,\n",
      "        27, 29,  4, 11, 24, 25, 24,  7, 25,  7, 29,  1, 10, 19, 21,  8, 25, 27,\n",
      "        21, 14, 25, 18, 10, 18, 25, 15, 24, 16, 19,  7, 14, 16, 27,  7, 21,  1,\n",
      "         8,  1, 16, 14, 21, 16,  7, 27, 24,  4, 18, 15, 29, 19, 13,  1, 25, 10,\n",
      "         1, 14,  0,  1,  4, 27,  1, 14,  1, 18,  1, 29, 13, 27, 21,  1, 21, 16,\n",
      "        27,  0,  8, 29, 24,  2, 10, 21, 24, 25, 27,  4, 29, 25,  1,  2,  2, 14,\n",
      "        10,  8,  0,  1,  1, 27, 10, 29, 27,  8, 24, 27, 10, 27, 21,  8,  4, 15,\n",
      "         0,  4, 27,  7, 29, 15, 29, 27, 15, 14, 29,  1,  6,  1,  8, 21,  6,  4,\n",
      "        29, 14, 29,  8, 13,  1, 13, 13, 29, 21,  1, 27,  1, 15, 24, 27, 13, 16,\n",
      "        16, 18, 14,  4,  4, 18,  7, 14, 27, 14, 15, 18, 15,  6,  2,  7,  0, 27,\n",
      "         1, 13,  0, 24, 27, 14, 15,  4,  0, 18,  0, 24,  1, 27, 16,  1, 24,  8,\n",
      "        13, 25, 27, 15], device='cuda:0')\n",
      "tensor([25, 29,  1, 20, 11, 28, 10, 13, 16, 25,  4, 14, 27,  1, 27,  8, 24, 18,\n",
      "        13, 20, 27, 25, 18,  6, 24, 18, 16, 18, 15, 19, 24, 17,  7,  3, 21, 18,\n",
      "         7, 16, 27, 24,  4,  7,  2, 16, 21,  8,  7, 16,  1, 13,  8, 27,  1, 14,\n",
      "        10, 10,  8,  0,  8, 24,  1,  1, 14, 19, 27, 28, 11,  4, 16, 12,  1,  8,\n",
      "        27, 29,  4, 11, 24, 25, 24,  7, 25, 15, 29, 21, 14, 19, 31,  8, 25, 27,\n",
      "        13, 14,  6, 18,  1,  6, 25, 15,  7, 16, 19,  7, 29, 16, 28,  7,  1, 17,\n",
      "        25, 23, 16, 14,  1, 16,  7, 27, 24,  4, 18, 15, 29, 19, 13,  1,  6,  3,\n",
      "         1, 24, 18,  1,  4, 19,  1, 14, 11, 23, 26, 29, 13, 20,  1,  1, 30, 16,\n",
      "        10, 14,  8, 29, 24,  2, 10, 25, 24, 25, 27,  4, 29,  0,  1,  2,  0, 14,\n",
      "         7,  8,  0, 11,  1, 27, 17, 14, 19,  8, 24,  2, 11, 27, 21,  2,  4, 15,\n",
      "         0,  4, 27,  7, 29, 15, 29, 23, 15, 32,  7,  1, 16,  1,  8, 15,  6,  4,\n",
      "        29, 14, 29,  8, 13,  1, 13, 13, 29, 21, 21, 27, 11, 15, 24, 27, 13, 16,\n",
      "        16, 18, 14,  4, 22, 18, 13, 14, 27, 11, 15, 23, 15, 32,  7,  7,  0, 21,\n",
      "         1, 13,  0, 24, 27, 14, 15,  4,  0,  0,  0, 24, 15, 27,  8,  1, 24,  6,\n",
      "        13, 23, 27, 15], device='cuda:0')\n",
      "tensor([16,  1, 24, 27, 27,  1, 24, 16, 21, 16,  1, 29, 27,  1, 27, 29,  1, 21,\n",
      "         4, 27, 18, 27, 13, 27, 27,  1, 13,  1,  4, 27, 29, 18, 10,  8, 21,  0,\n",
      "        18,  0, 18,  4, 27, 27, 29,  1, 10,  1,  0, 16, 14,  1, 14, 14, 16, 27,\n",
      "        18, 27,  1, 18,  7, 21, 10, 18,  8, 24, 18, 14, 27, 24,  1,  2,  1, 19,\n",
      "        27, 18,  1, 27,  1, 29, 14, 16, 18, 29,  1, 10, 27, 18, 16, 10,  4,  4,\n",
      "        18, 10, 10, 10, 14,  4, 10, 15,  1,  1, 16, 18, 15, 18, 29, 27, 21, 27,\n",
      "        22,  1, 18, 25, 24, 19,  1,  4,  1, 25, 27,  1, 15, 13, 13, 29, 24,  1,\n",
      "        24, 27,  7, 18,  8,  7, 24, 29, 21, 15, 14, 21, 16, 16,  1, 27, 16,  1,\n",
      "        18, 10,  4,  1, 11, 10,  8, 19, 25, 27,  1,  1, 18, 29, 18, 16,  1,  8,\n",
      "         4, 13,  0, 27, 11, 13, 21, 29,  1, 10, 27, 25,  4,  8,  1, 19,  1, 15,\n",
      "         1,  1, 21, 15,  8,  4, 15,  1, 15,  8, 29, 27,  8, 27,  8, 23,  1,  1,\n",
      "         8, 15, 27, 25, 10, 27, 14,  8, 27, 22,  1, 27, 10,  8,  8,  7, 24,  7,\n",
      "        27, 27, 27, 27, 24, 29, 18,  7, 24, 27,  8, 27, 27,  1, 18, 29,  2, 15,\n",
      "         1,  1, 27, 29,  1, 24, 13, 29,  0, 24, 15, 24, 24, 29, 24,  8,  1, 21,\n",
      "        15, 27,  1, 15], device='cuda:0')\n",
      "tensor([16,  1, 24, 12, 28,  1, 24, 16, 18, 16, 21, 29, 27,  1, 28, 29,  1, 18,\n",
      "        11,  6,  7, 12, 14, 32, 20,  1, 13, 17,  4, 20, 29, 18,  1,  6,  2,  0,\n",
      "        30,  0, 21, 22, 27, 21, 29,  1, 11,  1,  0, 16, 14,  1, 14,  2, 16, 28,\n",
      "        16, 26,  8, 18,  7, 21, 10, 18,  8, 24,  7,  1, 20, 24,  1,  2, 16, 26,\n",
      "        15,  8,  1, 27,  1, 29, 14, 16,  0, 25,  1, 10, 27, 23, 16, 10,  4,  4,\n",
      "        18, 15,  1, 10, 15,  4, 10, 15,  1,  1, 16, 18, 15, 18, 29, 27, 20, 28,\n",
      "        22, 17, 19, 25, 24, 29,  1, 22,  1, 25, 27,  1, 15, 13, 13,  4, 24,  7,\n",
      "        24, 12,  7, 18,  0,  7, 14,  0, 21, 10,  4, 24,  8, 16,  1, 27, 16,  0,\n",
      "        18, 10,  4,  1, 11, 10,  8, 19, 25, 20,  1,  1,  1, 29,  6, 16,  8,  8,\n",
      "         4, 13,  0, 27, 11, 13, 21, 29, 10, 10, 22, 25,  4, 15,  1,  0,  1, 15,\n",
      "         1,  1, 21,  6,  8,  4, 15,  1, 15, 18, 29,  9,  6, 27,  8, 23,  0, 21,\n",
      "         8, 15, 12,  0, 10, 27, 18,  8, 23, 22, 27, 20, 10, 23,  6,  7, 24, 13,\n",
      "        24, 21, 21, 19,  5, 29, 18, 13, 24, 20,  6, 20, 13,  1, 18, 29,  2, 15,\n",
      "        18,  1, 21, 30,  1, 24, 13, 29,  0, 24, 15, 24, 24, 29, 24,  8,  1, 11,\n",
      "        15, 21, 14, 15], device='cuda:0')\n",
      "tensor([ 7, 13,  4,  4,  6, 18, 10, 27, 27, 10,  8,  1, 24, 15,  6, 25,  4, 27,\n",
      "        18,  1, 18, 14,  1, 27, 21, 25,  1, 14,  8,  2, 14, 18,  1, 18, 25, 10,\n",
      "        16, 27, 27, 25,  7,  0, 18, 27, 13, 29,  1, 10, 21,  1,  7, 13, 10, 21,\n",
      "        24, 21, 29, 18,  6,  1,  4, 24,  7, 21, 15, 27, 16,  1,  1,  1, 29, 21,\n",
      "        13,  7,  4,  4, 18,  2, 21, 21,  7, 27, 24, 15,  1, 24, 27, 21, 29, 18,\n",
      "         4, 27, 13, 13, 27,  1, 18,  0, 15, 24, 21, 27,  1,  7,  8, 21,  1,  1,\n",
      "         4, 25, 13, 13,  1,  7, 18, 18, 18,  8,  4,  1, 29, 14, 16, 24, 27, 21,\n",
      "        14, 27, 29, 13, 27,  7,  7, 27, 27, 15,  7,  0, 25,  7,  2, 21, 24, 27,\n",
      "        13,  0, 29,  8, 16, 13, 16,  0, 25, 10, 18,  1, 27, 27, 16, 27, 29,  7,\n",
      "        27,  7, 13, 27, 27, 13, 21,  8, 13, 27, 14, 16, 18, 27, 27, 27, 22,  0,\n",
      "        16, 27, 10, 16,  1, 13, 16, 27,  1, 13, 13,  8,  8, 16,  8, 21,  1, 24,\n",
      "        21, 21, 27, 27,  1, 10, 15,  2, 19, 13, 21, 10, 16, 10, 27, 27, 16,  1,\n",
      "         8, 21, 21, 15,  0,  4, 27, 10, 16, 24, 16, 21, 18, 22, 14, 27, 16, 18,\n",
      "        15, 14, 21, 15, 22, 18, 27,  0,  8, 14, 25,  8, 21, 18, 16, 24, 27,  1,\n",
      "        27, 10, 25,  1], device='cuda:0')\n",
      "tensor([ 7, 13,  4,  4,  6,  0, 32, 28, 21, 10,  8, 11, 24, 15,  6, 25, 25, 28,\n",
      "        18,  1,  1, 18, 21, 31,  8, 15,  1, 10, 10, 11,  0, 18,  1,  1, 32, 23,\n",
      "        16, 27, 27,  4, 18,  0, 18, 12, 13, 29,  6, 10, 13, 21,  7, 13,  3, 21,\n",
      "        24, 32, 29, 18,  6,  1,  2, 24,  7, 10, 15, 27, 16,  1, 11, 21, 29, 21,\n",
      "        13, 13,  4,  4, 25,  2, 32, 22,  7, 20, 24, 18, 11, 24,  9,  8, 29, 18,\n",
      "         4, 21, 13, 13, 27,  1, 32,  0, 15, 24, 29, 13,  1,  7,  8, 19,  1,  1,\n",
      "         4, 25, 13, 13,  1,  7, 18, 18, 18,  8,  6,  1, 29, 14, 16, 24, 27,  7,\n",
      "        14, 27, 29, 13, 28, 18, 13,  1, 17, 15,  9,  0, 25, 15,  2, 21, 24, 32,\n",
      "        13,  0, 30,  3, 16, 13, 16,  0, 25, 11, 18,  1, 11, 26, 16, 27, 29, 13,\n",
      "        20, 15, 13, 12, 10, 13,  3,  8, 13,  1, 14, 16, 29, 12, 31,  9, 22, 29,\n",
      "        16, 12, 11, 16, 10, 12, 16, 28,  8, 13, 13,  8,  8, 16,  8, 25, 29, 24,\n",
      "        21, 32, 17, 21, 11, 17, 15, 29, 19, 13, 21, 21, 16, 11, 28, 21, 16,  1,\n",
      "         8, 21, 21, 15,  0, 22, 10, 10, 16, 24, 16, 27, 18, 22, 25, 25, 16, 14,\n",
      "        15,  0, 13, 15, 22,  1,  0, 23,  8, 27, 14,  8, 17, 21, 16, 24, 26, 14,\n",
      "        27, 10, 25, 25], device='cuda:0')\n",
      "tensor([21, 16,  1, 24, 18, 15, 27,  2, 29, 27, 29, 16, 27, 29, 25, 21, 25, 16,\n",
      "        25, 14, 25, 27, 19,  7, 19, 25, 16,  0, 14,  4,  2, 29, 18,  0, 18, 18,\n",
      "         2, 27, 13, 10, 27, 10, 25, 18,  2, 27,  0, 15, 27, 27, 24, 24,  1, 10,\n",
      "        18, 21,  1, 18,  7, 10, 10,  1,  6,  1, 27, 18,  7, 15,  8,  4, 18, 21,\n",
      "        27, 10, 15, 27, 27, 14,  8,  1, 14, 18, 25,  1, 29, 14, 18,  1, 27, 16,\n",
      "        27,  7, 15, 14,  8, 16,  1, 29, 24, 10, 21, 25,  4,  7, 27, 27, 27, 29,\n",
      "        27, 10, 29, 13, 21, 18, 27, 29,  8,  1, 24, 11, 16,  1, 27, 10, 25, 27,\n",
      "        27, 16,  8,  1, 16,  7, 16, 10,  4, 27,  1,  1,  8, 13, 15,  2, 21,  1,\n",
      "        27,  1,  8, 21,  8,  6,  1, 10, 27, 27,  0,  1, 15, 24,  1, 29, 15, 16,\n",
      "        19,  4,  4, 15, 15, 25, 27, 14,  4, 15, 29, 27, 16,  7, 16, 14, 29,  4,\n",
      "        10,  7, 15, 18,  8,  1,  1, 29,  7, 21, 18, 27,  7, 27, 16, 14, 18,  0,\n",
      "        21, 29,  0,  1, 27,  0, 15, 25, 13, 13, 25, 16,  4, 21,  7, 14, 25, 27,\n",
      "        27, 16,  8, 21, 24, 24, 13, 18,  0, 16, 27, 21, 18, 13, 18,  1, 14, 10,\n",
      "        18,  1, 16, 27, 21, 18, 19, 25,  0, 29,  4, 23, 21, 27, 27, 18, 27,  2,\n",
      "        19, 29,  8, 27], device='cuda:0')\n",
      "tensor([11, 16, 28, 24, 18, 21, 27,  2, 29, 17, 29, 16, 27, 29, 25, 21, 25, 16,\n",
      "        21, 14, 25, 27, 19,  7, 19, 25,  8,  0, 14, 22,  0, 25,  9,  0, 30,  8,\n",
      "        23, 27, 13, 10, 12, 10, 25, 18,  2, 28,  0, 15, 12, 27,  4, 24,  1, 11,\n",
      "        25, 26,  8, 21,  2, 10, 10,  1,  6, 27, 14, 23,  7, 15, 29,  4, 18, 21,\n",
      "        20,  3, 15, 12, 21, 14,  2,  1, 14,  4, 25,  8, 29, 14, 18,  1, 26, 16,\n",
      "        31,  7, 15, 14,  8, 16,  1, 29, 24, 10,  7, 25, 11,  8, 20,  1, 10, 29,\n",
      "        27, 14, 29, 13,  6, 18, 26, 29,  6, 29, 24, 11, 16,  1, 20, 21,  6,  7,\n",
      "        12, 16, 18,  1, 16,  7, 16, 23, 22, 27,  1,  1,  8, 13, 15,  1, 21, 16,\n",
      "        28, 11,  8, 21,  8,  0,  2, 11, 29, 21,  0,  1, 15, 24, 29, 29, 15, 16,\n",
      "        19, 25,  4, 15, 15, 25, 26, 14,  4, 15, 30, 21, 15, 26, 16, 14, 29,  4,\n",
      "        10,  7, 15, 18,  8, 11, 21, 29, 21, 11, 21, 20,  7, 28, 16, 14,  1,  0,\n",
      "        27, 29,  0,  1, 27,  2, 15, 25, 13, 21, 25, 16,  4, 23, 25, 14, 25,  1,\n",
      "        21, 16,  6,  4, 24, 24, 13,  1,  0, 16, 27, 21,  8, 13,  1, 10, 32, 10,\n",
      "        14,  1, 16, 27, 21, 18, 19, 25,  0, 29,  4, 23, 23, 27, 14, 30, 26,  2,\n",
      "        19, 29,  8, 20], device='cuda:0')\n",
      "tensor([27, 25, 21, 15, 23,  1,  1, 25,  8, 24, 27, 25, 19,  1, 10, 18,  1,  1,\n",
      "        13,  0,  1, 19, 15, 15, 24, 18, 27, 21,  0, 27, 13,  1,  1,  1,  4,  1,\n",
      "         6, 14, 25,  7,  1, 27, 11, 27,  8, 18,  4,  1, 10, 21, 18, 23, 27, 15,\n",
      "         7, 29, 27, 24, 27,  7,  1,  1, 10, 27, 19,  2,  8,  0, 15, 21, 29, 21,\n",
      "        19, 25, 27, 15,  1, 27, 16, 27, 27, 18, 19, 18,  4, 18, 16,  1,  1, 19,\n",
      "         1,  0,  1,  7, 25, 25, 27,  0, 13, 19, 27, 10, 19,  0,  2, 25, 24, 27,\n",
      "        18,  1, 27,  1,  8, 27, 25,  1,  1,  1, 24, 21,  1,  1, 24,  1, 18, 21,\n",
      "        29,  4, 15, 16,  0,  1, 13,  1, 25, 15, 16,  7, 13, 27,  0, 24, 27,  2,\n",
      "        29, 16, 29, 25, 15,  1, 22,  1,  4, 21, 25, 15,  8, 16, 15, 13, 27, 10,\n",
      "        29, 29, 25, 10,  8,  4, 13, 19,  8,  2, 29,  8, 30, 29,  7, 21,  8, 29,\n",
      "        21, 27, 14, 21,  7, 10, 18,  4,  1, 27,  7, 27,  1, 21, 27,  1,  4, 16,\n",
      "        24, 14, 16, 21, 25, 21,  4,  1,  7,  0, 16, 25,  4, 27,  1, 27,  7,  1,\n",
      "         1, 29, 27, 27, 16, 14, 29, 27, 13,  7,  4,  1, 13, 10, 18,  1, 21,  1,\n",
      "        27, 27, 27, 27, 29,  1, 21, 13, 16, 27,  7, 16,  1, 18,  0,  1, 15,  4,\n",
      "        14,  7, 22, 27], device='cuda:0')\n",
      "tensor([16, 25,  0, 15, 23,  1,  1, 25, 16, 24, 31, 25, 19, 21, 17, 18, 29, 14,\n",
      "        13,  0,  1, 18,  6, 15, 24, 22, 28,  1,  0,  1, 13, 18, 14,  1,  4,  1,\n",
      "         6, 14, 25,  7,  1, 15, 11, 28,  8, 11,  4,  1, 10, 13, 12, 23, 19, 15,\n",
      "         1, 29, 31, 24, 32,  7,  1, 29, 10, 31, 30,  2,  8,  0, 15, 24, 29, 18,\n",
      "        19,  8, 12, 15,  1, 21, 16, 27, 24, 18, 19, 18,  4,  6, 16,  1,  1, 25,\n",
      "        21, 29, 25,  7, 25, 25, 20,  0, 13, 19, 27, 10, 15,  0,  2, 25, 24, 20,\n",
      "        29,  1, 20,  6,  8, 23, 25,  1,  6,  1, 24, 31,  1,  1, 24,  1, 18, 10,\n",
      "        29,  4, 15, 16,  0,  1, 13, 10, 14, 15, 16,  7, 13, 27,  0, 24,  1,  1,\n",
      "        29, 16, 29, 25, 15,  1, 22,  1,  4,  5,  6, 15,  8, 16, 15, 13,  1, 14,\n",
      "        29, 29, 25, 10,  8,  4, 24, 19,  8,  8, 29,  8, 30, 29,  7,  1,  8, 29,\n",
      "        21, 20, 14, 25,  7, 10, 21, 22, 23, 27,  7, 11,  1, 21, 26,  1,  4, 15,\n",
      "        24, 14, 16, 19, 25, 20,  4,  1, 23,  0, 16, 25,  4, 23, 21, 19,  7,  4,\n",
      "         1, 29,  9, 27, 16, 17, 29, 21, 13,  7,  4,  1, 13, 21,  6, 23, 21,  4,\n",
      "        23, 27, 32, 12,  1,  1, 21, 13, 16, 16, 15, 16, 21,  6,  2,  1, 15, 22,\n",
      "        14, 13, 22, 23], device='cuda:0')\n",
      "tensor([22, 16,  4,  1, 10,  1, 14, 27, 16, 13, 15, 15, 21,  0, 21,  1, 16,  4,\n",
      "        22, 24,  8, 18, 10, 21,  7, 27, 25,  1,  1, 15, 18, 27, 18,  1, 10, 27,\n",
      "         0, 14,  8, 18, 19,  1,  1, 27, 15, 25, 27,  8, 11, 27,  8, 18, 15, 21,\n",
      "         1,  1, 15,  4, 24,  7, 14, 21,  0,  2, 24,  1,  2, 10, 18, 25, 27, 13,\n",
      "        27,  4, 16,  1, 18,  4, 19, 14, 15, 18, 27, 27,  4, 24,  7, 21, 13, 27,\n",
      "         1,  1, 19, 27,  1, 21,  8, 21, 16,  0,  0,  4,  2,  0, 10, 27, 24,  1,\n",
      "         4, 16,  7, 18,  4, 25, 25, 27, 13,  2, 27,  1, 10, 18, 24,  0, 10,  2,\n",
      "        15, 27, 21,  1, 27, 14, 27, 16, 29, 27,  1,  1, 18, 14, 21, 29, 27,  4,\n",
      "         6, 14,  8,  8, 14, 18, 10, 10, 18,  1, 29, 16,  1, 10,  7, 21, 14, 21,\n",
      "        13, 27, 13, 27,  1, 27,  1, 16,  1, 27, 19, 25,  1, 13, 29, 25,  7, 29,\n",
      "         2, 29,  8, 14,  7, 13, 27,  7, 27,  1,  8, 13, 25,  8, 29,  1,  0,  4,\n",
      "        27,  1, 15, 27,  1,  1, 27,  1, 29, 27, 19, 29, 25,  0, 15,  7, 29,  8,\n",
      "         1,  8, 27, 24,  0, 14,  8, 25, 21, 13, 19,  0,  2, 15, 24, 18,  1, 13,\n",
      "        24, 21, 24,  7, 27, 10,  1, 10, 29, 18, 27,  2,  1, 21, 21,  8, 24,  1,\n",
      "        18, 16,  4, 13], device='cuda:0')\n",
      "tensor([32, 15,  4,  1, 10, 11, 14, 28, 16,  7, 15, 15, 31,  0, 27,  1, 16, 14,\n",
      "        19, 24,  8, 18, 10, 21,  7, 27, 25,  1,  1, 15, 18, 27, 14, 11,  2, 21,\n",
      "        16, 14, 24, 18, 19, 29,  1, 21,  8,  6, 27,  0, 11, 21,  8, 18, 15, 19,\n",
      "         1,  1, 15,  4, 24,  1, 21, 32,  0,  2, 24,  1,  2, 17, 18,  6, 12, 13,\n",
      "         2,  4, 16,  1, 17,  4, 30,  6, 15, 18, 27, 21,  4, 24, 18, 25, 13, 27,\n",
      "         6,  7, 19, 27,  1, 21, 21, 24, 16,  0,  0,  4,  2,  0, 10, 27, 24,  1,\n",
      "        22, 16,  7, 23, 15, 25,  4,  4, 21,  2, 28,  7, 10, 18, 24,  0, 10,  8,\n",
      "         5, 12,  4,  1, 27, 25, 28, 16, 29, 19,  1, 25, 18, 14,  7, 29, 12,  4,\n",
      "         6, 10,  8,  8, 14, 18, 21, 13,  1,  0, 29, 16,  9, 10,  7, 14, 14, 21,\n",
      "        13, 12, 13, 31,  1, 27, 23, 16,  1, 15, 26, 25,  1,  1, 29,  1,  1, 29,\n",
      "         2, 30,  7, 14,  7, 12, 20,  7, 20,  1,  8, 13, 23,  6, 29,  0,  0,  4,\n",
      "        20, 11, 15, 15, 11,  1, 21,  1, 29, 27, 19, 30, 25,  0, 15,  1, 29,  8,\n",
      "        29,  8, 20, 21,  0, 14,  8, 25, 18, 13, 19,  1,  2, 15, 24, 19,  1,  7,\n",
      "        24,  2, 24, 21, 27, 10,  1, 10, 29, 18, 12,  2,  1, 24, 21,  8, 24,  1,\n",
      "        32, 16, 22, 13], device='cuda:0')\n",
      "tensor([18,  1, 18, 25,  2, 27,  7, 15, 27, 16, 29,  4, 18, 18,  1, 27, 10, 16,\n",
      "        13,  4, 27,  8, 10, 29,  1, 21, 14, 10, 10,  1,  6, 15, 25, 14, 27, 27,\n",
      "        13,  1, 21,  1, 14,  0, 29, 27, 27, 25, 24, 22,  7, 24,  8, 18, 27,  8,\n",
      "        27, 29,  1, 27, 15,  4, 19,  1,  1, 18, 25,  8, 10, 25, 21, 18,  8, 15,\n",
      "         4, 27,  0,  8, 10,  1, 14,  1,  4,  1, 25, 24, 27, 29, 25,  1, 21, 16,\n",
      "         1, 21, 25,  8,  8, 13, 13, 18, 10, 16, 16, 13, 10, 27, 13,  1, 16,  4,\n",
      "         8, 18, 27, 14, 21,  4, 29, 27, 29,  1, 15, 27, 16, 16,  1,  1, 14,  7,\n",
      "        10, 18, 24,  1,  1, 27,  4,  7, 19, 15, 15, 25, 18, 29,  0, 21, 27, 21,\n",
      "         1,  0, 25,  4, 27,  1, 24, 16, 16,  0,  4,  0, 10, 10, 24, 29,  0, 24,\n",
      "        29, 10, 27, 13,  1, 14, 18, 10,  4, 14, 10,  8, 13,  1, 10,  7,  4, 14,\n",
      "        18, 13, 25, 10, 18, 16, 22, 18, 21, 27, 29,  1,  0,  8,  0, 25, 21, 16,\n",
      "         0, 15, 21, 18, 27,  4,  4, 14, 18, 10, 25,  0, 18,  8,  7,  1, 30, 25,\n",
      "        21, 27,  7, 13, 29, 18,  8, 15,  1, 16, 10, 15, 16,  1,  1, 27, 27, 19,\n",
      "         7,  2, 18, 13,  4, 27, 24,  1, 16, 15, 29, 29, 25,  7,  4,  4, 14, 27,\n",
      "        29, 18, 13, 16], device='cuda:0')\n",
      "tensor([ 8,  1, 18,  4,  2, 27, 21, 15, 18, 15, 29, 10,  8, 18,  1, 12, 10, 16,\n",
      "        13,  4, 27,  8, 10, 29,  1, 21, 14,  1, 10,  8,  8, 15, 19, 14, 27, 27,\n",
      "        13, 29,  3, 21, 18,  0, 29, 12, 32, 25, 24, 22, 13, 24,  0, 18, 28,  8,\n",
      "         8, 29,  1, 28, 15,  4, 12,  1,  1,  1, 25, 13,  1, 25, 20, 23, 30, 15,\n",
      "         4, 26,  0,  8, 10,  1, 11, 14, 22,  1, 14, 24, 19, 29,  6,  1, 32, 16,\n",
      "         1, 23, 25,  8,  8, 13, 18, 18, 10, 16, 16, 13, 10, 31, 13,  1, 16,  4,\n",
      "         8,  1, 27, 14, 18,  4, 29, 27, 29,  1, 15, 27, 16, 16,  1, 10, 14, 25,\n",
      "        10, 18, 24,  1,  2, 14, 18,  7, 19, 15, 15,  6,  7, 30,  0, 10, 27, 23,\n",
      "         1,  0, 25,  4, 12,  1, 24,  6, 16,  0,  4,  0, 10, 10, 24, 29,  0, 24,\n",
      "        29, 23, 19, 13,  1, 14,  8, 11,  4, 14, 10,  8, 13,  1, 14, 18, 22, 14,\n",
      "        18, 13, 25,  2, 23, 16, 22, 12, 21, 20, 29, 21,  0,  8,  0, 29,  0, 16,\n",
      "         0, 15, 26, 18, 19,  4,  4, 14, 18, 10, 25,  0, 25, 14,  7,  1, 30, 25,\n",
      "        21, 26,  7, 13, 29, 18,  8, 15, 10,  8,  2, 14, 16, 18,  1, 27, 27, 26,\n",
      "         7,  2, 25, 13,  4, 12, 24,  1, 16, 15, 29, 29, 25, 15,  4, 22, 29, 24,\n",
      "        29, 18, 13, 16], device='cuda:0')\n",
      "tensor([18, 27, 13, 27,  7, 16,  4, 16, 25, 27,  0,  1, 21, 13,  8, 21, 16, 27,\n",
      "        25,  1,  1, 21, 13, 22, 23,  4, 10, 16, 25, 29,  0, 16,  8,  8, 16,  1,\n",
      "        14,  1, 24, 21, 16,  8,  4, 16, 27, 27,  8,  7, 23,  4, 18,  8, 15, 14,\n",
      "        13,  1, 27,  7,  8,  1, 24,  1,  6, 13, 18,  8, 24, 10, 29,  2,  1, 14,\n",
      "        27,  1,  0, 23,  0, 16, 27,  1, 10, 29, 25, 29,  4, 29, 27, 15,  7,  1,\n",
      "        10,  1,  1,  8, 18,  1, 29,  4, 24, 10,  1, 14, 15, 15, 24,  1, 15, 27,\n",
      "        16, 18,  4,  2,  8, 29, 29, 27, 15, 27, 19,  7, 27,  8,  6,  1, 16, 15,\n",
      "        25, 27, 21, 18, 27, 13, 27,  8, 29, 10, 21, 27,  0, 29, 24, 21,  4,  7,\n",
      "        27, 18,  1,  6,  7, 18,  2,  6, 29, 18,  4,  0,  2, 10, 29, 25, 13,  7,\n",
      "        27,  8, 27, 19,  1, 25, 15, 10,  1, 18, 24, 18,  1,  4,  8, 15,  1, 21,\n",
      "        27,  8, 21, 15,  1, 27, 10, 15, 16,  1, 13, 10, 13, 10,  4,  1,  7, 14,\n",
      "         4,  2, 10,  0,  1, 25,  1,  0, 18, 27, 29, 18,  1, 24, 27, 29, 10,  1,\n",
      "         8,  0, 27, 24,  7, 14,  2,  8,  1,  8, 27,  8, 13,  1, 10, 27, 10,  1,\n",
      "        16, 21,  7, 27, 14, 14, 16, 27, 21, 13,  1,  7,  8, 16, 18, 27, 27, 27,\n",
      "        27, 14,  1,  1], device='cuda:0')\n",
      "tensor([30, 27, 13, 12,  7, 16,  4, 16,  4, 23,  0, 18, 29, 13,  8, 21, 16, 26,\n",
      "        14, 13,  1, 24, 13,  8, 23,  4, 11, 16,  7, 29,  3, 16,  8,  8, 16,  1,\n",
      "        14,  7, 24, 23, 16,  8,  4, 16, 21, 27,  8, 21, 23,  4,  8, 25, 15, 14,\n",
      "        13, 21, 12,  7,  8, 27, 24, 19,  6, 13, 18,  8, 24, 17, 29,  2,  1, 14,\n",
      "        27,  1,  2, 13,  0, 16, 31,  1, 10, 30, 25, 29,  4, 29, 26, 15,  7,  6,\n",
      "        10, 13,  2, 23, 18,  1, 29,  4, 24, 10, 21, 14, 15, 15, 24,  1, 15, 32,\n",
      "        16, 14,  4,  7, 18, 29, 29, 21, 15, 27, 16,  9, 20,  6,  6,  1, 16, 15,\n",
      "        25, 27, 23, 21, 20, 13, 27,  8, 29, 10, 19, 12,  0, 29, 24,  1,  2,  7,\n",
      "        20, 18,  1,  6, 21,  1,  2,  6, 29, 29,  4,  0,  2, 10, 29, 25,  7,  7,\n",
      "        27,  6, 11, 19, 15, 25, 15, 10,  1, 18, 32, 12,  1,  4,  8, 16,  0, 27,\n",
      "        26,  8,  1, 15,  2, 10, 10, 15, 16,  1, 13, 17, 13, 10,  4,  1, 10,  7,\n",
      "         3,  2, 10,  0,  1, 25, 11,  8, 18, 12, 29, 19, 28, 24, 15, 29, 12,  1,\n",
      "        15,  0, 32, 24,  7, 25,  2,  8, 21,  8, 24,  8, 13,  1, 14, 12, 10, 26,\n",
      "        16, 27,  7, 12, 30, 14,  8, 22,  7, 13, 21,  7,  6, 16, 18, 23, 27, 12,\n",
      "        13, 14,  1,  2], device='cuda:0')\n",
      "tensor([22,  1,  1, 27, 18, 21,  4,  4, 16,  0, 13,  0,  4, 16, 15,  1, 21, 16,\n",
      "        27, 16, 27, 29, 15, 13,  8, 27, 14, 27,  4, 24,  0, 25,  1, 16,  4, 10,\n",
      "        10,  4,  4, 27,  8, 21,  4,  2,  8, 24, 18, 15, 27,  1, 21, 14,  4, 13,\n",
      "         8, 27, 21,  1, 21, 29,  1, 27,  7, 18,  8, 27,  1, 25, 21,  0,  1,  1,\n",
      "         1, 27,  7, 16,  0,  8, 27, 21, 27, 14,  0, 21,  8, 21, 14, 29, 27,  1,\n",
      "        15,  4,  0,  8,  4, 18,  2, 10, 27, 25, 29,  1,  1, 10, 14, 24, 29, 27,\n",
      "         8, 29, 27, 13,  1, 21, 19,  0], device='cuda:0')\n",
      "tensor([22,  1,  1, 22, 15, 31,  4,  4, 16, 23, 13,  0, 21, 16, 15,  1, 21, 16,\n",
      "        32, 16, 21, 29,  4,  7,  8, 12, 14, 21, 22, 24, 10, 25,  1, 16,  1, 10,\n",
      "        10,  4, 27, 20,  0, 18,  4,  2,  8, 24, 14, 15, 31, 14,  2, 10,  4, 13,\n",
      "         5, 21,  2,  1, 21, 29,  2, 21,  7, 15,  8, 27,  1, 25, 10,  0,  1,  1,\n",
      "         1, 15,  7, 16,  0, 19, 27, 32, 28, 14,  0, 21,  8, 23, 14, 29, 27, 11,\n",
      "        15,  4,  0,  8,  4, 18,  2, 10, 20, 25, 29,  1, 18, 21, 14, 24, 29, 19,\n",
      "         8, 29, 14, 13,  1, 26, 19, 18], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    outputs = Model[1](inputs)\n",
    "    print(torch.argmax(outputs, dim=1))\n",
    "    print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
